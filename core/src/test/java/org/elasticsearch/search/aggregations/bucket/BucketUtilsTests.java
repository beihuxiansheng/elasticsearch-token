begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to Elasticsearch under one or more contributor  * license agreements. See the NOTICE file distributed with  * this work for additional information regarding copyright  * ownership. Elasticsearch licenses this file to you under  * the Apache License, Version 2.0 (the "License"); you may  * not use this file except in compliance with the License.  * You may obtain a copy of the License at  *  *    http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing,  * software distributed under the License is distributed on an  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY  * KIND, either express or implied.  See the License for the  * specific language governing permissions and limitations  * under the License.  */
end_comment

begin_package
DECL|package|org.elasticsearch.search.aggregations.bucket
package|package
name|org
operator|.
name|elasticsearch
operator|.
name|search
operator|.
name|aggregations
operator|.
name|bucket
package|;
end_package

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|test
operator|.
name|ESTestCase
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|hamcrest
operator|.
name|Matchers
operator|.
name|greaterThanOrEqualTo
import|;
end_import

begin_class
DECL|class|BucketUtilsTests
specifier|public
class|class
name|BucketUtilsTests
extends|extends
name|ESTestCase
block|{
DECL|method|testBadInput
specifier|public
name|void
name|testBadInput
parameter_list|()
block|{
name|IllegalArgumentException
name|e
init|=
name|expectThrows
argument_list|(
name|IllegalArgumentException
operator|.
name|class
argument_list|,
parameter_list|()
lambda|->
name|BucketUtils
operator|.
name|suggestShardSideQueueSize
argument_list|(
literal|0
argument_list|,
literal|10
argument_list|)
argument_list|)
decl_stmt|;
name|assertEquals
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
literal|"size must be positive, got 0"
argument_list|)
expr_stmt|;
name|e
operator|=
name|expectThrows
argument_list|(
name|IllegalArgumentException
operator|.
name|class
argument_list|,
parameter_list|()
lambda|->
name|BucketUtils
operator|.
name|suggestShardSideQueueSize
argument_list|(
literal|10
argument_list|,
literal|0
argument_list|)
argument_list|)
expr_stmt|;
name|assertEquals
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
literal|"number of shards must be positive, got 0"
argument_list|)
expr_stmt|;
block|}
DECL|method|testOptimizesSingleShard
specifier|public
name|void
name|testOptimizesSingleShard
parameter_list|()
block|{
for|for
control|(
name|int
name|iter
init|=
literal|0
init|;
name|iter
operator|<
literal|10
condition|;
operator|++
name|iter
control|)
block|{
specifier|final
name|int
name|size
init|=
name|randomIntBetween
argument_list|(
literal|1
argument_list|,
name|Integer
operator|.
name|MAX_VALUE
argument_list|)
decl_stmt|;
name|assertEquals
argument_list|(
name|size
argument_list|,
name|BucketUtils
operator|.
name|suggestShardSideQueueSize
argument_list|(
name|size
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|testOverFlow
specifier|public
name|void
name|testOverFlow
parameter_list|()
block|{
for|for
control|(
name|int
name|iter
init|=
literal|0
init|;
name|iter
operator|<
literal|10
condition|;
operator|++
name|iter
control|)
block|{
specifier|final
name|int
name|size
init|=
name|Integer
operator|.
name|MAX_VALUE
operator|-
name|randomInt
argument_list|(
literal|10
argument_list|)
decl_stmt|;
specifier|final
name|int
name|numberOfShards
init|=
name|randomIntBetween
argument_list|(
literal|1
argument_list|,
literal|10
argument_list|)
decl_stmt|;
specifier|final
name|int
name|shardSize
init|=
name|BucketUtils
operator|.
name|suggestShardSideQueueSize
argument_list|(
name|size
argument_list|,
name|numberOfShards
argument_list|)
decl_stmt|;
name|assertThat
argument_list|(
name|shardSize
argument_list|,
name|greaterThanOrEqualTo
argument_list|(
name|shardSize
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|testShardSizeIsGreaterThanGlobalSize
specifier|public
name|void
name|testShardSizeIsGreaterThanGlobalSize
parameter_list|()
block|{
for|for
control|(
name|int
name|iter
init|=
literal|0
init|;
name|iter
operator|<
literal|10
condition|;
operator|++
name|iter
control|)
block|{
specifier|final
name|int
name|size
init|=
name|randomIntBetween
argument_list|(
literal|1
argument_list|,
name|Integer
operator|.
name|MAX_VALUE
argument_list|)
decl_stmt|;
specifier|final
name|int
name|numberOfShards
init|=
name|randomIntBetween
argument_list|(
literal|1
argument_list|,
literal|10
argument_list|)
decl_stmt|;
specifier|final
name|int
name|shardSize
init|=
name|BucketUtils
operator|.
name|suggestShardSideQueueSize
argument_list|(
name|size
argument_list|,
name|numberOfShards
argument_list|)
decl_stmt|;
name|assertThat
argument_list|(
name|shardSize
argument_list|,
name|greaterThanOrEqualTo
argument_list|(
name|size
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|/*// You may use the code below to evaluate the impact of the BucketUtils.suggestShardSideQueueSize     // heuristic     public static void main(String[] args) {         final int numberOfUniqueTerms = 10000;         final int totalNumberOfTerms = 1000000;         final int numberOfShards = 10;         final double skew = 2; // parameter of the zipf distribution         final int size = 100;          double totalWeight = 0;         for (int rank = 1; rank<= numberOfUniqueTerms; ++rank) {             totalWeight += weight(rank, skew);         }          int[] terms = new int[totalNumberOfTerms];         int len = 0;          final int[] actualTopFreqs = new int[size];         for (int rank = 1; len< totalNumberOfTerms; ++rank) {             int freq = (int) (weight(rank, skew) / totalWeight * totalNumberOfTerms);             freq = Math.max(freq, 1);             Arrays.fill(terms, len, Math.min(len + freq, totalNumberOfTerms), rank - 1);             len += freq;             if (rank<= size) {                 actualTopFreqs[rank-1] = freq;             }         }          final int maxTerm = terms[terms.length - 1] + 1;          // shuffle terms         Random r = new Random(0);         for (int i = terms.length - 1; i> 0; --i) {             final int swapWith = r.nextInt(i);             int tmp = terms[i];             terms[i] = terms[swapWith];             terms[swapWith] = tmp;         }         // distribute into shards like routing would         int[][] shards = new int[numberOfShards][];         int upTo = 0;         for (int i = 0; i< numberOfShards; ++i) {             shards[i] = Arrays.copyOfRange(terms, upTo, upTo + (terms.length - upTo) / (numberOfShards - i));             upTo += shards[i].length;         }          final int[][] topShards = new int[numberOfShards][];         final int shardSize = BucketUtils.suggestShardSideQueueSize(size, numberOfShards);         for (int shard = 0; shard< numberOfShards; ++shard) {             final int[] data = shards[shard];             final int[] freqs = new int[maxTerm];             for (int d : data) {                 freqs[d]++;             }             int[] termIds = new int[maxTerm];             for (int i = 0; i< maxTerm; ++i) {                 termIds[i] = i;             }             new InPlaceMergeSorter() {                  @Override                 protected void swap(int i, int j) {                     int tmp = termIds[i];                     termIds[i] = termIds[j];                     termIds[j] = tmp;                     tmp = freqs[i];                     freqs[i] = freqs[j];                     freqs[j] = tmp;                 }                  @Override                 protected int compare(int i, int j) {                     return freqs[j] - freqs[i];                 }             }.sort(0, maxTerm);              Arrays.fill(freqs, shardSize, freqs.length, 0);             new InPlaceMergeSorter() {                  @Override                 protected void swap(int i, int j) {                     int tmp = termIds[i];                     termIds[i] = termIds[j];                     termIds[j] = tmp;                     tmp = freqs[i];                     freqs[i] = freqs[j];                     freqs[j] = tmp;                 }                  @Override                 protected int compare(int i, int j) {                     return termIds[i] - termIds[j];                 }             }.sort(0, maxTerm);              topShards[shard] = freqs;         }          final int[] computedTopFreqs = new int[size];         for (int[] freqs : topShards) {             for (int i = 0; i< size; ++i) {                 computedTopFreqs[i] += freqs[i];             }         }         int numErrors = 0;         int totalFreq = 0;         for (int i = 0; i< size; ++i) {             numErrors += Math.abs(computedTopFreqs[i] - actualTopFreqs[i]);             totalFreq += actualTopFreqs[i];         }         System.out.println("Number of unique terms: " + maxTerm);         System.out.println("Global freqs of top terms: " + Arrays.toString(actualTopFreqs));         System.out.println("Computed freqs of top terms: " + Arrays.toString(computedTopFreqs));         System.out.println("Number of errors: " + numErrors + "/" + totalFreq);     }      private static double weight(int rank, double skew) {         return 1d / Math.pow(rank, skew);     }*/
block|}
end_class

end_unit

