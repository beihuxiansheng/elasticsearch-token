begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to Elasticsearch under one or more contributor  * license agreements. See the NOTICE file distributed with  * this work for additional information regarding copyright  * ownership. Elasticsearch licenses this file to you under  * the Apache License, Version 2.0 (the "License"); you may  * not use this file except in compliance with the License.  * You may obtain a copy of the License at  *  *    http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing,  * software distributed under the License is distributed on an  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY  * KIND, either express or implied.  See the License for the  * specific language governing permissions and limitations  * under the License.  */
end_comment

begin_package
DECL|package|org.elasticsearch.index.analysis
package|package
name|org
operator|.
name|elasticsearch
operator|.
name|index
operator|.
name|analysis
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|CannedTokenStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|Token
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|analysis
operator|.
name|TokenStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|settings
operator|.
name|Settings
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|index
operator|.
name|Index
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|index
operator|.
name|IndexSettings
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|test
operator|.
name|ESTokenStreamTestCase
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|test
operator|.
name|IndexSettingsModule
import|;
end_import

begin_class
DECL|class|FlattenGraphTokenFilterFactoryTests
specifier|public
class|class
name|FlattenGraphTokenFilterFactoryTests
extends|extends
name|ESTokenStreamTestCase
block|{
DECL|method|testBasic
specifier|public
name|void
name|testBasic
parameter_list|()
throws|throws
name|IOException
block|{
name|Index
name|index
init|=
operator|new
name|Index
argument_list|(
literal|"test"
argument_list|,
literal|"_na_"
argument_list|)
decl_stmt|;
name|String
name|name
init|=
literal|"ngr"
decl_stmt|;
name|Settings
name|indexSettings
init|=
name|newAnalysisSettingsBuilder
argument_list|()
operator|.
name|build
argument_list|()
decl_stmt|;
name|IndexSettings
name|indexProperties
init|=
name|IndexSettingsModule
operator|.
name|newIndexSettings
argument_list|(
name|index
argument_list|,
name|indexSettings
argument_list|)
decl_stmt|;
name|Settings
name|settings
init|=
name|newAnalysisSettingsBuilder
argument_list|()
operator|.
name|build
argument_list|()
decl_stmt|;
comment|// "wow that's funny" and "what the fudge" are separate side paths, in parallel with "wtf", on input:
name|TokenStream
name|in
init|=
operator|new
name|CannedTokenStream
argument_list|(
literal|0
argument_list|,
literal|12
argument_list|,
operator|new
name|Token
index|[]
block|{
name|token
argument_list|(
literal|"wtf"
argument_list|,
literal|1
argument_list|,
literal|5
argument_list|,
literal|0
argument_list|,
literal|3
argument_list|)
block|,
name|token
argument_list|(
literal|"what"
argument_list|,
literal|0
argument_list|,
literal|1
argument_list|,
literal|0
argument_list|,
literal|3
argument_list|)
block|,
name|token
argument_list|(
literal|"wow"
argument_list|,
literal|0
argument_list|,
literal|3
argument_list|,
literal|0
argument_list|,
literal|3
argument_list|)
block|,
name|token
argument_list|(
literal|"the"
argument_list|,
literal|1
argument_list|,
literal|1
argument_list|,
literal|0
argument_list|,
literal|3
argument_list|)
block|,
name|token
argument_list|(
literal|"fudge"
argument_list|,
literal|1
argument_list|,
literal|3
argument_list|,
literal|0
argument_list|,
literal|3
argument_list|)
block|,
name|token
argument_list|(
literal|"that's"
argument_list|,
literal|1
argument_list|,
literal|1
argument_list|,
literal|0
argument_list|,
literal|3
argument_list|)
block|,
name|token
argument_list|(
literal|"funny"
argument_list|,
literal|1
argument_list|,
literal|1
argument_list|,
literal|0
argument_list|,
literal|3
argument_list|)
block|,
name|token
argument_list|(
literal|"happened"
argument_list|,
literal|1
argument_list|,
literal|1
argument_list|,
literal|4
argument_list|,
literal|12
argument_list|)
block|}
argument_list|)
decl_stmt|;
name|TokenStream
name|tokens
init|=
operator|new
name|FlattenGraphTokenFilterFactory
argument_list|(
name|indexProperties
argument_list|,
literal|null
argument_list|,
name|name
argument_list|,
name|settings
argument_list|)
operator|.
name|create
argument_list|(
name|in
argument_list|)
decl_stmt|;
comment|// ... but on output, it's flattened to wtf/what/wow that's/the fudge/funny happened:
name|assertTokenStreamContents
argument_list|(
name|tokens
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"wtf"
block|,
literal|"what"
block|,
literal|"wow"
block|,
literal|"the"
block|,
literal|"that's"
block|,
literal|"fudge"
block|,
literal|"funny"
block|,
literal|"happened"
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|0
block|,
literal|0
block|,
literal|0
block|,
literal|0
block|,
literal|0
block|,
literal|0
block|,
literal|0
block|,
literal|4
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|3
block|,
literal|3
block|,
literal|3
block|,
literal|3
block|,
literal|3
block|,
literal|3
block|,
literal|3
block|,
literal|12
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|1
block|,
literal|0
block|,
literal|0
block|,
literal|1
block|,
literal|0
block|,
literal|1
block|,
literal|0
block|,
literal|1
block|}
argument_list|,
operator|new
name|int
index|[]
block|{
literal|3
block|,
literal|1
block|,
literal|1
block|,
literal|1
block|,
literal|1
block|,
literal|1
block|,
literal|1
block|,
literal|1
block|}
argument_list|,
literal|12
argument_list|)
expr_stmt|;
block|}
DECL|method|token
specifier|private
specifier|static
name|Token
name|token
parameter_list|(
name|String
name|term
parameter_list|,
name|int
name|posInc
parameter_list|,
name|int
name|posLength
parameter_list|,
name|int
name|startOffset
parameter_list|,
name|int
name|endOffset
parameter_list|)
block|{
specifier|final
name|Token
name|t
init|=
operator|new
name|Token
argument_list|(
name|term
argument_list|,
name|startOffset
argument_list|,
name|endOffset
argument_list|)
decl_stmt|;
name|t
operator|.
name|setPositionIncrement
argument_list|(
name|posInc
argument_list|)
expr_stmt|;
name|t
operator|.
name|setPositionLength
argument_list|(
name|posLength
argument_list|)
expr_stmt|;
return|return
name|t
return|;
block|}
block|}
end_class

end_unit

