begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to Elasticsearch under one or more contributor  * license agreements. See the NOTICE file distributed with  * this work for additional information regarding copyright  * ownership. Elasticsearch licenses this file to you under  * the Apache License, Version 2.0 (the "License"); you may  * not use this file except in compliance with the License.  * You may obtain a copy of the License at  *  *    http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing,  * software distributed under the License is distributed on an  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY  * KIND, either express or implied.  See the License for the  * specific language governing permissions and limitations  * under the License.  */
end_comment

begin_package
DECL|package|org.elasticsearch.cluster.routing.allocation.decider
package|package
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|routing
operator|.
name|allocation
operator|.
name|decider
package|;
end_package

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|com
operator|.
name|carrotsearch
operator|.
name|hppc
operator|.
name|cursors
operator|.
name|ObjectCursor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|ClusterInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|DiskUsage
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|metadata
operator|.
name|IndexMetaData
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|routing
operator|.
name|IndexShardRoutingTable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|routing
operator|.
name|RecoverySource
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|routing
operator|.
name|RoutingNode
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|routing
operator|.
name|ShardRouting
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|routing
operator|.
name|ShardRoutingState
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|routing
operator|.
name|allocation
operator|.
name|DiskThresholdSettings
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|routing
operator|.
name|allocation
operator|.
name|RoutingAllocation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|Strings
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|collect
operator|.
name|ImmutableOpenMap
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|settings
operator|.
name|ClusterSettings
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|settings
operator|.
name|Settings
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|unit
operator|.
name|ByteSizeValue
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|index
operator|.
name|Index
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|index
operator|.
name|shard
operator|.
name|ShardId
import|;
end_import

begin_comment
comment|/**  * The {@link DiskThresholdDecider} checks that the node a shard is potentially  * being allocated to has enough disk space.  *  * It has three configurable settings, all of which can be changed dynamically:  *  *<code>cluster.routing.allocation.disk.watermark.low</code> is the low disk  * watermark. New shards will not allocated to a node with usage higher than this,  * although this watermark may be passed by allocating a shard. It defaults to  * 0.85 (85.0%).  *  *<code>cluster.routing.allocation.disk.watermark.high</code> is the high disk  * watermark. If a node has usage higher than this, shards are not allowed to  * remain on the node. In addition, if allocating a shard to a node causes the  * node to pass this watermark, it will not be allowed. It defaults to  * 0.90 (90.0%).  *  * Both watermark settings are expressed in terms of used disk percentage, or  * exact byte values for free space (like "500mb")  *  *<code>cluster.routing.allocation.disk.threshold_enabled</code> is used to  * enable or disable this decider. It defaults to false (disabled).  */
end_comment

begin_class
DECL|class|DiskThresholdDecider
specifier|public
class|class
name|DiskThresholdDecider
extends|extends
name|AllocationDecider
block|{
DECL|field|NAME
specifier|public
specifier|static
specifier|final
name|String
name|NAME
init|=
literal|"disk_threshold"
decl_stmt|;
DECL|field|diskThresholdSettings
specifier|private
specifier|final
name|DiskThresholdSettings
name|diskThresholdSettings
decl_stmt|;
DECL|method|DiskThresholdDecider
specifier|public
name|DiskThresholdDecider
parameter_list|(
name|Settings
name|settings
parameter_list|,
name|ClusterSettings
name|clusterSettings
parameter_list|)
block|{
name|super
argument_list|(
name|settings
argument_list|)
expr_stmt|;
name|this
operator|.
name|diskThresholdSettings
operator|=
operator|new
name|DiskThresholdSettings
argument_list|(
name|settings
argument_list|,
name|clusterSettings
argument_list|)
expr_stmt|;
block|}
comment|/**      * Returns the size of all shards that are currently being relocated to      * the node, but may not be finished transferring yet.      *      * If subtractShardsMovingAway is true then the size of shards moving away is subtracted from the total size of all shards      */
DECL|method|sizeOfRelocatingShards
specifier|static
name|long
name|sizeOfRelocatingShards
parameter_list|(
name|RoutingNode
name|node
parameter_list|,
name|RoutingAllocation
name|allocation
parameter_list|,
name|boolean
name|subtractShardsMovingAway
parameter_list|,
name|String
name|dataPath
parameter_list|)
block|{
name|ClusterInfo
name|clusterInfo
init|=
name|allocation
operator|.
name|clusterInfo
argument_list|()
decl_stmt|;
name|long
name|totalSize
init|=
literal|0
decl_stmt|;
for|for
control|(
name|ShardRouting
name|routing
range|:
name|node
operator|.
name|shardsWithState
argument_list|(
name|ShardRoutingState
operator|.
name|RELOCATING
argument_list|,
name|ShardRoutingState
operator|.
name|INITIALIZING
argument_list|)
control|)
block|{
name|String
name|actualPath
init|=
name|clusterInfo
operator|.
name|getDataPath
argument_list|(
name|routing
argument_list|)
decl_stmt|;
if|if
condition|(
name|dataPath
operator|.
name|equals
argument_list|(
name|actualPath
argument_list|)
condition|)
block|{
if|if
condition|(
name|routing
operator|.
name|initializing
argument_list|()
operator|&&
name|routing
operator|.
name|relocatingNodeId
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|totalSize
operator|+=
name|getExpectedShardSize
argument_list|(
name|routing
argument_list|,
name|allocation
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|subtractShardsMovingAway
operator|&&
name|routing
operator|.
name|relocating
argument_list|()
condition|)
block|{
name|totalSize
operator|-=
name|getExpectedShardSize
argument_list|(
name|routing
argument_list|,
name|allocation
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|totalSize
return|;
block|}
annotation|@
name|Override
DECL|method|canAllocate
specifier|public
name|Decision
name|canAllocate
parameter_list|(
name|ShardRouting
name|shardRouting
parameter_list|,
name|RoutingNode
name|node
parameter_list|,
name|RoutingAllocation
name|allocation
parameter_list|)
block|{
name|ClusterInfo
name|clusterInfo
init|=
name|allocation
operator|.
name|clusterInfo
argument_list|()
decl_stmt|;
name|ImmutableOpenMap
argument_list|<
name|String
argument_list|,
name|DiskUsage
argument_list|>
name|usages
init|=
name|clusterInfo
operator|.
name|getNodeMostAvailableDiskUsages
argument_list|()
decl_stmt|;
specifier|final
name|Decision
name|decision
init|=
name|earlyTerminate
argument_list|(
name|allocation
argument_list|,
name|usages
argument_list|)
decl_stmt|;
if|if
condition|(
name|decision
operator|!=
literal|null
condition|)
block|{
return|return
name|decision
return|;
block|}
specifier|final
name|double
name|usedDiskThresholdLow
init|=
literal|100.0
operator|-
name|diskThresholdSettings
operator|.
name|getFreeDiskThresholdLow
argument_list|()
decl_stmt|;
specifier|final
name|double
name|usedDiskThresholdHigh
init|=
literal|100.0
operator|-
name|diskThresholdSettings
operator|.
name|getFreeDiskThresholdHigh
argument_list|()
decl_stmt|;
comment|// subtractLeavingShards is passed as false here, because they still use disk space, and therefore should we should be extra careful
comment|// and take the size into account
name|DiskUsage
name|usage
init|=
name|getDiskUsage
argument_list|(
name|node
argument_list|,
name|allocation
argument_list|,
name|usages
argument_list|,
literal|false
argument_list|)
decl_stmt|;
comment|// First, check that the node currently over the low watermark
name|double
name|freeDiskPercentage
init|=
name|usage
operator|.
name|getFreeDiskAsPercentage
argument_list|()
decl_stmt|;
comment|// Cache the used disk percentage for displaying disk percentages consistent with documentation
name|double
name|usedDiskPercentage
init|=
name|usage
operator|.
name|getUsedDiskAsPercentage
argument_list|()
decl_stmt|;
name|long
name|freeBytes
init|=
name|usage
operator|.
name|getFreeBytes
argument_list|()
decl_stmt|;
if|if
condition|(
name|logger
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|trace
argument_list|(
literal|"node [{}] has {}% used disk"
argument_list|,
name|node
operator|.
name|nodeId
argument_list|()
argument_list|,
name|usedDiskPercentage
argument_list|)
expr_stmt|;
block|}
comment|// flag that determines whether the low threshold checks below can be skipped. We use this for a primary shard that is freshly
comment|// allocated and empty.
name|boolean
name|skipLowTresholdChecks
init|=
name|shardRouting
operator|.
name|primary
argument_list|()
operator|&&
name|shardRouting
operator|.
name|active
argument_list|()
operator|==
literal|false
operator|&&
name|shardRouting
operator|.
name|recoverySource
argument_list|()
operator|.
name|getType
argument_list|()
operator|==
name|RecoverySource
operator|.
name|Type
operator|.
name|EMPTY_STORE
decl_stmt|;
comment|// checks for exact byte comparisons
if|if
condition|(
name|freeBytes
operator|<
name|diskThresholdSettings
operator|.
name|getFreeBytesThresholdLow
argument_list|()
operator|.
name|bytes
argument_list|()
condition|)
block|{
if|if
condition|(
name|skipLowTresholdChecks
operator|==
literal|false
condition|)
block|{
if|if
condition|(
name|logger
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"less than the required {} free bytes threshold ({} bytes free) on node {}, preventing allocation"
argument_list|,
name|diskThresholdSettings
operator|.
name|getFreeBytesThresholdLow
argument_list|()
argument_list|,
name|freeBytes
argument_list|,
name|node
operator|.
name|nodeId
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|allocation
operator|.
name|decision
argument_list|(
name|Decision
operator|.
name|NO
argument_list|,
name|NAME
argument_list|,
literal|"the node is above the low watermark and has less than required [%s] free, free: [%s]"
argument_list|,
name|diskThresholdSettings
operator|.
name|getFreeBytesThresholdLow
argument_list|()
argument_list|,
operator|new
name|ByteSizeValue
argument_list|(
name|freeBytes
argument_list|)
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|freeBytes
operator|>
name|diskThresholdSettings
operator|.
name|getFreeBytesThresholdHigh
argument_list|()
operator|.
name|bytes
argument_list|()
condition|)
block|{
comment|// Allow the shard to be allocated because it is primary that
comment|// has never been allocated if it's under the high watermark
if|if
condition|(
name|logger
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"less than the required {} free bytes threshold ({} bytes free) on node {}, "
operator|+
literal|"but allowing allocation because primary has never been allocated"
argument_list|,
name|diskThresholdSettings
operator|.
name|getFreeBytesThresholdLow
argument_list|()
argument_list|,
name|freeBytes
argument_list|,
name|node
operator|.
name|nodeId
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|allocation
operator|.
name|decision
argument_list|(
name|Decision
operator|.
name|YES
argument_list|,
name|NAME
argument_list|,
literal|"the node is above the low watermark, but this primary shard has never been allocated before"
argument_list|)
return|;
block|}
else|else
block|{
comment|// Even though the primary has never been allocated, the node is
comment|// above the high watermark, so don't allow allocating the shard
if|if
condition|(
name|logger
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"less than the required {} free bytes threshold ({} bytes free) on node {}, "
operator|+
literal|"preventing allocation even though primary has never been allocated"
argument_list|,
name|diskThresholdSettings
operator|.
name|getFreeBytesThresholdHigh
argument_list|()
argument_list|,
name|freeBytes
argument_list|,
name|node
operator|.
name|nodeId
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|allocation
operator|.
name|decision
argument_list|(
name|Decision
operator|.
name|NO
argument_list|,
name|NAME
argument_list|,
literal|"the node is above the high watermark even though this shard has never been allocated "
operator|+
literal|"and has less than required [%s] free on node, free: [%s]"
argument_list|,
name|diskThresholdSettings
operator|.
name|getFreeBytesThresholdHigh
argument_list|()
argument_list|,
operator|new
name|ByteSizeValue
argument_list|(
name|freeBytes
argument_list|)
argument_list|)
return|;
block|}
block|}
comment|// checks for percentage comparisons
if|if
condition|(
name|freeDiskPercentage
operator|<
name|diskThresholdSettings
operator|.
name|getFreeDiskThresholdLow
argument_list|()
condition|)
block|{
comment|// If the shard is a replica or is a non-empty primary, check the low threshold
if|if
condition|(
name|skipLowTresholdChecks
operator|==
literal|false
condition|)
block|{
if|if
condition|(
name|logger
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"more than the allowed {} used disk threshold ({} used) on node [{}], preventing allocation"
argument_list|,
name|Strings
operator|.
name|format1Decimals
argument_list|(
name|usedDiskThresholdLow
argument_list|,
literal|"%"
argument_list|)
argument_list|,
name|Strings
operator|.
name|format1Decimals
argument_list|(
name|usedDiskPercentage
argument_list|,
literal|"%"
argument_list|)
argument_list|,
name|node
operator|.
name|nodeId
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|allocation
operator|.
name|decision
argument_list|(
name|Decision
operator|.
name|NO
argument_list|,
name|NAME
argument_list|,
literal|"the node is above the low watermark and has more than allowed [%s%%] used disk, free: [%s%%]"
argument_list|,
name|usedDiskThresholdLow
argument_list|,
name|freeDiskPercentage
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|freeDiskPercentage
operator|>
name|diskThresholdSettings
operator|.
name|getFreeDiskThresholdHigh
argument_list|()
condition|)
block|{
comment|// Allow the shard to be allocated because it is primary that
comment|// has never been allocated if it's under the high watermark
if|if
condition|(
name|logger
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"more than the allowed {} used disk threshold ({} used) on node [{}], "
operator|+
literal|"but allowing allocation because primary has never been allocated"
argument_list|,
name|Strings
operator|.
name|format1Decimals
argument_list|(
name|usedDiskThresholdLow
argument_list|,
literal|"%"
argument_list|)
argument_list|,
name|Strings
operator|.
name|format1Decimals
argument_list|(
name|usedDiskPercentage
argument_list|,
literal|"%"
argument_list|)
argument_list|,
name|node
operator|.
name|nodeId
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|allocation
operator|.
name|decision
argument_list|(
name|Decision
operator|.
name|YES
argument_list|,
name|NAME
argument_list|,
literal|"the node is above the low watermark, but this primary shard has never been allocated before"
argument_list|)
return|;
block|}
else|else
block|{
comment|// Even though the primary has never been allocated, the node is
comment|// above the high watermark, so don't allow allocating the shard
if|if
condition|(
name|logger
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"less than the required {} free bytes threshold ({} bytes free) on node {}, "
operator|+
literal|"preventing allocation even though primary has never been allocated"
argument_list|,
name|Strings
operator|.
name|format1Decimals
argument_list|(
name|diskThresholdSettings
operator|.
name|getFreeDiskThresholdHigh
argument_list|()
argument_list|,
literal|"%"
argument_list|)
argument_list|,
name|Strings
operator|.
name|format1Decimals
argument_list|(
name|freeDiskPercentage
argument_list|,
literal|"%"
argument_list|)
argument_list|,
name|node
operator|.
name|nodeId
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|allocation
operator|.
name|decision
argument_list|(
name|Decision
operator|.
name|NO
argument_list|,
name|NAME
argument_list|,
literal|"the node is above the high watermark even though this shard has never been allocated "
operator|+
literal|"and has more than allowed [%s%%] used disk, free: [%s%%]"
argument_list|,
name|usedDiskThresholdHigh
argument_list|,
name|freeDiskPercentage
argument_list|)
return|;
block|}
block|}
comment|// Secondly, check that allocating the shard to this node doesn't put it above the high watermark
specifier|final
name|long
name|shardSize
init|=
name|getExpectedShardSize
argument_list|(
name|shardRouting
argument_list|,
name|allocation
argument_list|,
literal|0
argument_list|)
decl_stmt|;
name|double
name|freeSpaceAfterShard
init|=
name|freeDiskPercentageAfterShardAssigned
argument_list|(
name|usage
argument_list|,
name|shardSize
argument_list|)
decl_stmt|;
name|long
name|freeBytesAfterShard
init|=
name|freeBytes
operator|-
name|shardSize
decl_stmt|;
if|if
condition|(
name|freeBytesAfterShard
operator|<
name|diskThresholdSettings
operator|.
name|getFreeBytesThresholdHigh
argument_list|()
operator|.
name|bytes
argument_list|()
condition|)
block|{
name|logger
operator|.
name|warn
argument_list|(
literal|"after allocating, node [{}] would have less than the required "
operator|+
literal|"{} free bytes threshold ({} bytes free), preventing allocation"
argument_list|,
name|node
operator|.
name|nodeId
argument_list|()
argument_list|,
name|diskThresholdSettings
operator|.
name|getFreeBytesThresholdHigh
argument_list|()
argument_list|,
name|freeBytesAfterShard
argument_list|)
expr_stmt|;
return|return
name|allocation
operator|.
name|decision
argument_list|(
name|Decision
operator|.
name|NO
argument_list|,
name|NAME
argument_list|,
literal|"after allocating the shard to this node, it would be above the high watermark "
operator|+
literal|"and have less than required [%s] free, free: [%s]"
argument_list|,
name|diskThresholdSettings
operator|.
name|getFreeBytesThresholdLow
argument_list|()
argument_list|,
operator|new
name|ByteSizeValue
argument_list|(
name|freeBytesAfterShard
argument_list|)
argument_list|)
return|;
block|}
if|if
condition|(
name|freeSpaceAfterShard
operator|<
name|diskThresholdSettings
operator|.
name|getFreeDiskThresholdHigh
argument_list|()
condition|)
block|{
name|logger
operator|.
name|warn
argument_list|(
literal|"after allocating, node [{}] would have more than the allowed "
operator|+
literal|"{} free disk threshold ({} free), preventing allocation"
argument_list|,
name|node
operator|.
name|nodeId
argument_list|()
argument_list|,
name|Strings
operator|.
name|format1Decimals
argument_list|(
name|diskThresholdSettings
operator|.
name|getFreeDiskThresholdHigh
argument_list|()
argument_list|,
literal|"%"
argument_list|)
argument_list|,
name|Strings
operator|.
name|format1Decimals
argument_list|(
name|freeSpaceAfterShard
argument_list|,
literal|"%"
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|allocation
operator|.
name|decision
argument_list|(
name|Decision
operator|.
name|NO
argument_list|,
name|NAME
argument_list|,
literal|"after allocating the shard to this node, it would be above the high watermark "
operator|+
literal|"and have more than allowed [%s%%] used disk, free: [%s%%]"
argument_list|,
name|usedDiskThresholdLow
argument_list|,
name|freeSpaceAfterShard
argument_list|)
return|;
block|}
return|return
name|allocation
operator|.
name|decision
argument_list|(
name|Decision
operator|.
name|YES
argument_list|,
name|NAME
argument_list|,
literal|"enough disk for shard on node, free: [%s], shard size: [%s], free after allocating shard: [%s]"
argument_list|,
operator|new
name|ByteSizeValue
argument_list|(
name|freeBytes
argument_list|)
argument_list|,
operator|new
name|ByteSizeValue
argument_list|(
name|shardSize
argument_list|)
argument_list|,
operator|new
name|ByteSizeValue
argument_list|(
name|freeBytesAfterShard
argument_list|)
argument_list|)
return|;
block|}
annotation|@
name|Override
DECL|method|canRemain
specifier|public
name|Decision
name|canRemain
parameter_list|(
name|ShardRouting
name|shardRouting
parameter_list|,
name|RoutingNode
name|node
parameter_list|,
name|RoutingAllocation
name|allocation
parameter_list|)
block|{
if|if
condition|(
name|shardRouting
operator|.
name|currentNodeId
argument_list|()
operator|.
name|equals
argument_list|(
name|node
operator|.
name|nodeId
argument_list|()
argument_list|)
operator|==
literal|false
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Shard ["
operator|+
name|shardRouting
operator|+
literal|"] is not allocated on node: ["
operator|+
name|node
operator|.
name|nodeId
argument_list|()
operator|+
literal|"]"
argument_list|)
throw|;
block|}
specifier|final
name|ClusterInfo
name|clusterInfo
init|=
name|allocation
operator|.
name|clusterInfo
argument_list|()
decl_stmt|;
specifier|final
name|ImmutableOpenMap
argument_list|<
name|String
argument_list|,
name|DiskUsage
argument_list|>
name|usages
init|=
name|clusterInfo
operator|.
name|getNodeLeastAvailableDiskUsages
argument_list|()
decl_stmt|;
specifier|final
name|Decision
name|decision
init|=
name|earlyTerminate
argument_list|(
name|allocation
argument_list|,
name|usages
argument_list|)
decl_stmt|;
if|if
condition|(
name|decision
operator|!=
literal|null
condition|)
block|{
return|return
name|decision
return|;
block|}
comment|// subtractLeavingShards is passed as true here, since this is only for shards remaining, we will *eventually* have enough disk
comment|// since shards are moving away. No new shards will be incoming since in canAllocate we pass false for this check.
specifier|final
name|DiskUsage
name|usage
init|=
name|getDiskUsage
argument_list|(
name|node
argument_list|,
name|allocation
argument_list|,
name|usages
argument_list|,
literal|true
argument_list|)
decl_stmt|;
specifier|final
name|String
name|dataPath
init|=
name|clusterInfo
operator|.
name|getDataPath
argument_list|(
name|shardRouting
argument_list|)
decl_stmt|;
comment|// If this node is already above the high threshold, the shard cannot remain (get it off!)
specifier|final
name|double
name|freeDiskPercentage
init|=
name|usage
operator|.
name|getFreeDiskAsPercentage
argument_list|()
decl_stmt|;
specifier|final
name|long
name|freeBytes
init|=
name|usage
operator|.
name|getFreeBytes
argument_list|()
decl_stmt|;
if|if
condition|(
name|logger
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|trace
argument_list|(
literal|"node [{}] has {}% free disk ({} bytes)"
argument_list|,
name|node
operator|.
name|nodeId
argument_list|()
argument_list|,
name|freeDiskPercentage
argument_list|,
name|freeBytes
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|dataPath
operator|==
literal|null
operator|||
name|usage
operator|.
name|getPath
argument_list|()
operator|.
name|equals
argument_list|(
name|dataPath
argument_list|)
operator|==
literal|false
condition|)
block|{
return|return
name|allocation
operator|.
name|decision
argument_list|(
name|Decision
operator|.
name|YES
argument_list|,
name|NAME
argument_list|,
literal|"this shard is not allocated on the most utilized disk and can remain"
argument_list|)
return|;
block|}
if|if
condition|(
name|freeBytes
operator|<
name|diskThresholdSettings
operator|.
name|getFreeBytesThresholdHigh
argument_list|()
operator|.
name|bytes
argument_list|()
condition|)
block|{
if|if
condition|(
name|logger
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"less than the required {} free bytes threshold ({} bytes free) on node {}, shard cannot remain"
argument_list|,
name|diskThresholdSettings
operator|.
name|getFreeBytesThresholdHigh
argument_list|()
argument_list|,
name|freeBytes
argument_list|,
name|node
operator|.
name|nodeId
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|allocation
operator|.
name|decision
argument_list|(
name|Decision
operator|.
name|NO
argument_list|,
name|NAME
argument_list|,
literal|"after allocating this shard this node would be above the high watermark "
operator|+
literal|"and there would be less than required [%s] free on node, free: [%s]"
argument_list|,
name|diskThresholdSettings
operator|.
name|getFreeBytesThresholdHigh
argument_list|()
argument_list|,
operator|new
name|ByteSizeValue
argument_list|(
name|freeBytes
argument_list|)
argument_list|)
return|;
block|}
if|if
condition|(
name|freeDiskPercentage
operator|<
name|diskThresholdSettings
operator|.
name|getFreeDiskThresholdHigh
argument_list|()
condition|)
block|{
if|if
condition|(
name|logger
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"less than the required {}% free disk threshold ({}% free) on node {}, shard cannot remain"
argument_list|,
name|diskThresholdSettings
operator|.
name|getFreeDiskThresholdHigh
argument_list|()
argument_list|,
name|freeDiskPercentage
argument_list|,
name|node
operator|.
name|nodeId
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|allocation
operator|.
name|decision
argument_list|(
name|Decision
operator|.
name|NO
argument_list|,
name|NAME
argument_list|,
literal|"after allocating this shard this node would be above the high watermark "
operator|+
literal|"and there would be less than required [%s%%] free disk on node, free: [%s%%]"
argument_list|,
name|diskThresholdSettings
operator|.
name|getFreeDiskThresholdHigh
argument_list|()
argument_list|,
name|freeDiskPercentage
argument_list|)
return|;
block|}
return|return
name|allocation
operator|.
name|decision
argument_list|(
name|Decision
operator|.
name|YES
argument_list|,
name|NAME
argument_list|,
literal|"there is enough disk on this node for the shard to remain, free: [%s]"
argument_list|,
operator|new
name|ByteSizeValue
argument_list|(
name|freeBytes
argument_list|)
argument_list|)
return|;
block|}
DECL|method|getDiskUsage
specifier|private
name|DiskUsage
name|getDiskUsage
parameter_list|(
name|RoutingNode
name|node
parameter_list|,
name|RoutingAllocation
name|allocation
parameter_list|,
name|ImmutableOpenMap
argument_list|<
name|String
argument_list|,
name|DiskUsage
argument_list|>
name|usages
parameter_list|,
name|boolean
name|subtractLeavingShards
parameter_list|)
block|{
name|DiskUsage
name|usage
init|=
name|usages
operator|.
name|get
argument_list|(
name|node
operator|.
name|nodeId
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|usage
operator|==
literal|null
condition|)
block|{
comment|// If there is no usage, and we have other nodes in the cluster,
comment|// use the average usage for all nodes as the usage for this node
name|usage
operator|=
name|averageUsage
argument_list|(
name|node
argument_list|,
name|usages
argument_list|)
expr_stmt|;
if|if
condition|(
name|logger
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"unable to determine disk usage for {}, defaulting to average across nodes [{} total] [{} free] [{}% free]"
argument_list|,
name|node
operator|.
name|nodeId
argument_list|()
argument_list|,
name|usage
operator|.
name|getTotalBytes
argument_list|()
argument_list|,
name|usage
operator|.
name|getFreeBytes
argument_list|()
argument_list|,
name|usage
operator|.
name|getFreeDiskAsPercentage
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|diskThresholdSettings
operator|.
name|includeRelocations
argument_list|()
condition|)
block|{
name|long
name|relocatingShardsSize
init|=
name|sizeOfRelocatingShards
argument_list|(
name|node
argument_list|,
name|allocation
argument_list|,
name|subtractLeavingShards
argument_list|,
name|usage
operator|.
name|getPath
argument_list|()
argument_list|)
decl_stmt|;
name|DiskUsage
name|usageIncludingRelocations
init|=
operator|new
name|DiskUsage
argument_list|(
name|node
operator|.
name|nodeId
argument_list|()
argument_list|,
name|node
operator|.
name|node
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|,
name|usage
operator|.
name|getPath
argument_list|()
argument_list|,
name|usage
operator|.
name|getTotalBytes
argument_list|()
argument_list|,
name|usage
operator|.
name|getFreeBytes
argument_list|()
operator|-
name|relocatingShardsSize
argument_list|)
decl_stmt|;
if|if
condition|(
name|logger
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|trace
argument_list|(
literal|"usage without relocations: {}"
argument_list|,
name|usage
argument_list|)
expr_stmt|;
name|logger
operator|.
name|trace
argument_list|(
literal|"usage with relocations: [{} bytes] {}"
argument_list|,
name|relocatingShardsSize
argument_list|,
name|usageIncludingRelocations
argument_list|)
expr_stmt|;
block|}
name|usage
operator|=
name|usageIncludingRelocations
expr_stmt|;
block|}
return|return
name|usage
return|;
block|}
comment|/**      * Returns a {@link DiskUsage} for the {@link RoutingNode} using the      * average usage of other nodes in the disk usage map.      * @param node Node to return an averaged DiskUsage object for      * @param usages Map of nodeId to DiskUsage for all known nodes      * @return DiskUsage representing given node using the average disk usage      */
DECL|method|averageUsage
name|DiskUsage
name|averageUsage
parameter_list|(
name|RoutingNode
name|node
parameter_list|,
name|ImmutableOpenMap
argument_list|<
name|String
argument_list|,
name|DiskUsage
argument_list|>
name|usages
parameter_list|)
block|{
if|if
condition|(
name|usages
operator|.
name|size
argument_list|()
operator|==
literal|0
condition|)
block|{
return|return
operator|new
name|DiskUsage
argument_list|(
name|node
operator|.
name|nodeId
argument_list|()
argument_list|,
name|node
operator|.
name|node
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|,
literal|"_na_"
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|)
return|;
block|}
name|long
name|totalBytes
init|=
literal|0
decl_stmt|;
name|long
name|freeBytes
init|=
literal|0
decl_stmt|;
for|for
control|(
name|ObjectCursor
argument_list|<
name|DiskUsage
argument_list|>
name|du
range|:
name|usages
operator|.
name|values
argument_list|()
control|)
block|{
name|totalBytes
operator|+=
name|du
operator|.
name|value
operator|.
name|getTotalBytes
argument_list|()
expr_stmt|;
name|freeBytes
operator|+=
name|du
operator|.
name|value
operator|.
name|getFreeBytes
argument_list|()
expr_stmt|;
block|}
return|return
operator|new
name|DiskUsage
argument_list|(
name|node
operator|.
name|nodeId
argument_list|()
argument_list|,
name|node
operator|.
name|node
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|,
literal|"_na_"
argument_list|,
name|totalBytes
operator|/
name|usages
operator|.
name|size
argument_list|()
argument_list|,
name|freeBytes
operator|/
name|usages
operator|.
name|size
argument_list|()
argument_list|)
return|;
block|}
comment|/**      * Given the DiskUsage for a node and the size of the shard, return the      * percentage of free disk if the shard were to be allocated to the node.      * @param usage A DiskUsage for the node to have space computed for      * @param shardSize Size in bytes of the shard      * @return Percentage of free space after the shard is assigned to the node      */
DECL|method|freeDiskPercentageAfterShardAssigned
name|double
name|freeDiskPercentageAfterShardAssigned
parameter_list|(
name|DiskUsage
name|usage
parameter_list|,
name|Long
name|shardSize
parameter_list|)
block|{
name|shardSize
operator|=
operator|(
name|shardSize
operator|==
literal|null
operator|)
condition|?
literal|0
else|:
name|shardSize
expr_stmt|;
name|DiskUsage
name|newUsage
init|=
operator|new
name|DiskUsage
argument_list|(
name|usage
operator|.
name|getNodeId
argument_list|()
argument_list|,
name|usage
operator|.
name|getNodeName
argument_list|()
argument_list|,
name|usage
operator|.
name|getPath
argument_list|()
argument_list|,
name|usage
operator|.
name|getTotalBytes
argument_list|()
argument_list|,
name|usage
operator|.
name|getFreeBytes
argument_list|()
operator|-
name|shardSize
argument_list|)
decl_stmt|;
return|return
name|newUsage
operator|.
name|getFreeDiskAsPercentage
argument_list|()
return|;
block|}
DECL|method|earlyTerminate
specifier|private
name|Decision
name|earlyTerminate
parameter_list|(
name|RoutingAllocation
name|allocation
parameter_list|,
name|ImmutableOpenMap
argument_list|<
name|String
argument_list|,
name|DiskUsage
argument_list|>
name|usages
parameter_list|)
block|{
comment|// Always allow allocation if the decider is disabled
if|if
condition|(
name|diskThresholdSettings
operator|.
name|isEnabled
argument_list|()
operator|==
literal|false
condition|)
block|{
return|return
name|allocation
operator|.
name|decision
argument_list|(
name|Decision
operator|.
name|YES
argument_list|,
name|NAME
argument_list|,
literal|"the disk threshold decider is disabled"
argument_list|)
return|;
block|}
comment|// Allow allocation regardless if only a single data node is available
if|if
condition|(
name|allocation
operator|.
name|nodes
argument_list|()
operator|.
name|getDataNodes
argument_list|()
operator|.
name|size
argument_list|()
operator|<=
literal|1
condition|)
block|{
if|if
condition|(
name|logger
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|trace
argument_list|(
literal|"only a single data node is present, allowing allocation"
argument_list|)
expr_stmt|;
block|}
return|return
name|allocation
operator|.
name|decision
argument_list|(
name|Decision
operator|.
name|YES
argument_list|,
name|NAME
argument_list|,
literal|"there is only a single data node present"
argument_list|)
return|;
block|}
comment|// Fail open there is no info available
specifier|final
name|ClusterInfo
name|clusterInfo
init|=
name|allocation
operator|.
name|clusterInfo
argument_list|()
decl_stmt|;
if|if
condition|(
name|clusterInfo
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|logger
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|trace
argument_list|(
literal|"cluster info unavailable for disk threshold decider, allowing allocation."
argument_list|)
expr_stmt|;
block|}
return|return
name|allocation
operator|.
name|decision
argument_list|(
name|Decision
operator|.
name|YES
argument_list|,
name|NAME
argument_list|,
literal|"the cluster info is unavailable"
argument_list|)
return|;
block|}
comment|// Fail open if there are no disk usages available
if|if
condition|(
name|usages
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
if|if
condition|(
name|logger
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|trace
argument_list|(
literal|"unable to determine disk usages for disk-aware allocation, allowing allocation"
argument_list|)
expr_stmt|;
block|}
return|return
name|allocation
operator|.
name|decision
argument_list|(
name|Decision
operator|.
name|YES
argument_list|,
name|NAME
argument_list|,
literal|"disk usages are unavailable"
argument_list|)
return|;
block|}
return|return
literal|null
return|;
block|}
comment|/**      * Returns the expected shard size for the given shard or the default value provided if not enough information are available      * to estimate the shards size.      */
DECL|method|getExpectedShardSize
specifier|public
specifier|static
name|long
name|getExpectedShardSize
parameter_list|(
name|ShardRouting
name|shard
parameter_list|,
name|RoutingAllocation
name|allocation
parameter_list|,
name|long
name|defaultValue
parameter_list|)
block|{
specifier|final
name|IndexMetaData
name|metaData
init|=
name|allocation
operator|.
name|metaData
argument_list|()
operator|.
name|getIndexSafe
argument_list|(
name|shard
operator|.
name|index
argument_list|()
argument_list|)
decl_stmt|;
specifier|final
name|ClusterInfo
name|info
init|=
name|allocation
operator|.
name|clusterInfo
argument_list|()
decl_stmt|;
if|if
condition|(
name|metaData
operator|.
name|getMergeSourceIndex
argument_list|()
operator|!=
literal|null
operator|&&
name|shard
operator|.
name|active
argument_list|()
operator|==
literal|false
operator|&&
name|shard
operator|.
name|recoverySource
argument_list|()
operator|.
name|getType
argument_list|()
operator|==
name|RecoverySource
operator|.
name|Type
operator|.
name|LOCAL_SHARDS
condition|)
block|{
comment|// in the shrink index case we sum up the source index shards since we basically make a copy of the shard in
comment|// the worst case
name|long
name|targetShardSize
init|=
literal|0
decl_stmt|;
specifier|final
name|Index
name|mergeSourceIndex
init|=
name|metaData
operator|.
name|getMergeSourceIndex
argument_list|()
decl_stmt|;
specifier|final
name|IndexMetaData
name|sourceIndexMeta
init|=
name|allocation
operator|.
name|metaData
argument_list|()
operator|.
name|getIndexSafe
argument_list|(
name|mergeSourceIndex
argument_list|)
decl_stmt|;
specifier|final
name|Set
argument_list|<
name|ShardId
argument_list|>
name|shardIds
init|=
name|IndexMetaData
operator|.
name|selectShrinkShards
argument_list|(
name|shard
operator|.
name|id
argument_list|()
argument_list|,
name|sourceIndexMeta
argument_list|,
name|metaData
operator|.
name|getNumberOfShards
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|IndexShardRoutingTable
name|shardRoutingTable
range|:
name|allocation
operator|.
name|routingTable
argument_list|()
operator|.
name|index
argument_list|(
name|mergeSourceIndex
operator|.
name|getName
argument_list|()
argument_list|)
control|)
block|{
if|if
condition|(
name|shardIds
operator|.
name|contains
argument_list|(
name|shardRoutingTable
operator|.
name|shardId
argument_list|()
argument_list|)
condition|)
block|{
name|targetShardSize
operator|+=
name|info
operator|.
name|getShardSize
argument_list|(
name|shardRoutingTable
operator|.
name|primaryShard
argument_list|()
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|targetShardSize
operator|==
literal|0
condition|?
name|defaultValue
else|:
name|targetShardSize
return|;
block|}
else|else
block|{
return|return
name|info
operator|.
name|getShardSize
argument_list|(
name|shard
argument_list|,
name|defaultValue
argument_list|)
return|;
block|}
block|}
block|}
end_class

end_unit

