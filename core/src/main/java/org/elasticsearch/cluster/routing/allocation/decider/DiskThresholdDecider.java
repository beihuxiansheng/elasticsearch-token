begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to Elasticsearch under one or more contributor  * license agreements. See the NOTICE file distributed with  * this work for additional information regarding copyright  * ownership. Elasticsearch licenses this file to you under  * the Apache License, Version 2.0 (the "License"); you may  * not use this file except in compliance with the License.  * You may obtain a copy of the License at  *  *    http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing,  * software distributed under the License is distributed on an  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY  * KIND, either express or implied.  See the License for the  * specific language governing permissions and limitations  * under the License.  */
end_comment

begin_package
DECL|package|org.elasticsearch.cluster.routing.allocation.decider
package|package
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|routing
operator|.
name|allocation
operator|.
name|decider
package|;
end_package

begin_import
import|import
name|com
operator|.
name|carrotsearch
operator|.
name|hppc
operator|.
name|ObjectLookupContainer
import|;
end_import

begin_import
import|import
name|com
operator|.
name|carrotsearch
operator|.
name|hppc
operator|.
name|cursors
operator|.
name|ObjectCursor
import|;
end_import

begin_import
import|import
name|com
operator|.
name|carrotsearch
operator|.
name|hppc
operator|.
name|cursors
operator|.
name|ObjectObjectCursor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|ElasticsearchParseException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|client
operator|.
name|Client
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|ClusterInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|ClusterInfoService
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|DiskUsage
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|EmptyClusterInfoService
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|routing
operator|.
name|RoutingNode
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|routing
operator|.
name|ShardRouting
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|routing
operator|.
name|ShardRoutingState
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|routing
operator|.
name|allocation
operator|.
name|RoutingAllocation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|settings
operator|.
name|ClusterSettings
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|Strings
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|collect
operator|.
name|ImmutableOpenMap
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|inject
operator|.
name|Inject
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|settings
operator|.
name|Setting
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|settings
operator|.
name|Settings
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|unit
operator|.
name|ByteSizeValue
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|unit
operator|.
name|RatioValue
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|unit
operator|.
name|TimeValue
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|util
operator|.
name|set
operator|.
name|Sets
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|settings
operator|.
name|ClusterSettingsService
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_comment
comment|/**  * The {@link DiskThresholdDecider} checks that the node a shard is potentially  * being allocated to has enough disk space.  *  * It has three configurable settings, all of which can be changed dynamically:  *  *<code>cluster.routing.allocation.disk.watermark.low</code> is the low disk  * watermark. New shards will not allocated to a node with usage higher than this,  * although this watermark may be passed by allocating a shard. It defaults to  * 0.85 (85.0%).  *  *<code>cluster.routing.allocation.disk.watermark.high</code> is the high disk  * watermark. If a node has usage higher than this, shards are not allowed to  * remain on the node. In addition, if allocating a shard to a node causes the  * node to pass this watermark, it will not be allowed. It defaults to  * 0.90 (90.0%).  *  * Both watermark settings are expressed in terms of used disk percentage, or  * exact byte values for free space (like "500mb")  *  *<code>cluster.routing.allocation.disk.threshold_enabled</code> is used to  * enable or disable this decider. It defaults to false (disabled).  */
end_comment

begin_class
DECL|class|DiskThresholdDecider
specifier|public
class|class
name|DiskThresholdDecider
extends|extends
name|AllocationDecider
block|{
DECL|field|NAME
specifier|public
specifier|static
specifier|final
name|String
name|NAME
init|=
literal|"disk_threshold"
decl_stmt|;
DECL|field|freeDiskThresholdLow
specifier|private
specifier|volatile
name|Double
name|freeDiskThresholdLow
decl_stmt|;
DECL|field|freeDiskThresholdHigh
specifier|private
specifier|volatile
name|Double
name|freeDiskThresholdHigh
decl_stmt|;
DECL|field|freeBytesThresholdLow
specifier|private
specifier|volatile
name|ByteSizeValue
name|freeBytesThresholdLow
decl_stmt|;
DECL|field|freeBytesThresholdHigh
specifier|private
specifier|volatile
name|ByteSizeValue
name|freeBytesThresholdHigh
decl_stmt|;
DECL|field|includeRelocations
specifier|private
specifier|volatile
name|boolean
name|includeRelocations
decl_stmt|;
DECL|field|enabled
specifier|private
specifier|volatile
name|boolean
name|enabled
decl_stmt|;
DECL|field|rerouteInterval
specifier|private
specifier|volatile
name|TimeValue
name|rerouteInterval
decl_stmt|;
DECL|field|CLUSTER_ROUTING_ALLOCATION_DISK_THRESHOLD_ENABLED_SETTING
specifier|public
specifier|static
specifier|final
name|Setting
argument_list|<
name|Boolean
argument_list|>
name|CLUSTER_ROUTING_ALLOCATION_DISK_THRESHOLD_ENABLED_SETTING
init|=
name|Setting
operator|.
name|boolSetting
argument_list|(
literal|"cluster.routing.allocation.disk.threshold_enabled"
argument_list|,
literal|true
argument_list|,
literal|true
argument_list|,
name|Setting
operator|.
name|Scope
operator|.
name|Cluster
argument_list|)
decl_stmt|;
DECL|field|CLUSTER_ROUTING_ALLOCATION_LOW_DISK_WATERMARK_SETTING
specifier|public
specifier|static
specifier|final
name|Setting
argument_list|<
name|String
argument_list|>
name|CLUSTER_ROUTING_ALLOCATION_LOW_DISK_WATERMARK_SETTING
init|=
operator|new
name|Setting
argument_list|<>
argument_list|(
literal|"cluster.routing.allocation.disk.watermark.low"
argument_list|,
literal|"85%"
argument_list|,
parameter_list|(
name|s
parameter_list|)
lambda|->
name|validWatermarkSetting
argument_list|(
name|s
argument_list|,
literal|"cluster.routing.allocation.disk.watermark.low"
argument_list|)
argument_list|,
literal|true
argument_list|,
name|Setting
operator|.
name|Scope
operator|.
name|Cluster
argument_list|)
decl_stmt|;
DECL|field|CLUSTER_ROUTING_ALLOCATION_HIGH_DISK_WATERMARK_SETTING
specifier|public
specifier|static
specifier|final
name|Setting
argument_list|<
name|String
argument_list|>
name|CLUSTER_ROUTING_ALLOCATION_HIGH_DISK_WATERMARK_SETTING
init|=
operator|new
name|Setting
argument_list|<>
argument_list|(
literal|"cluster.routing.allocation.disk.watermark.high"
argument_list|,
literal|"90%"
argument_list|,
parameter_list|(
name|s
parameter_list|)
lambda|->
name|validWatermarkSetting
argument_list|(
name|s
argument_list|,
literal|"cluster.routing.allocation.disk.watermark.high"
argument_list|)
argument_list|,
literal|true
argument_list|,
name|Setting
operator|.
name|Scope
operator|.
name|Cluster
argument_list|)
decl_stmt|;
DECL|field|CLUSTER_ROUTING_ALLOCATION_INCLUDE_RELOCATIONS_SETTING
specifier|public
specifier|static
specifier|final
name|Setting
argument_list|<
name|Boolean
argument_list|>
name|CLUSTER_ROUTING_ALLOCATION_INCLUDE_RELOCATIONS_SETTING
init|=
name|Setting
operator|.
name|boolSetting
argument_list|(
literal|"cluster.routing.allocation.disk.include_relocations"
argument_list|,
literal|true
argument_list|,
literal|true
argument_list|,
name|Setting
operator|.
name|Scope
operator|.
name|Cluster
argument_list|)
decl_stmt|;
empty_stmt|;
DECL|field|CLUSTER_ROUTING_ALLOCATION_REROUTE_INTERVAL_SETTING
specifier|public
specifier|static
specifier|final
name|Setting
argument_list|<
name|TimeValue
argument_list|>
name|CLUSTER_ROUTING_ALLOCATION_REROUTE_INTERVAL_SETTING
init|=
name|Setting
operator|.
name|positiveTimeSetting
argument_list|(
literal|"cluster.routing.allocation.disk.reroute_interval"
argument_list|,
name|TimeValue
operator|.
name|timeValueSeconds
argument_list|(
literal|60
argument_list|)
argument_list|,
literal|true
argument_list|,
name|Setting
operator|.
name|Scope
operator|.
name|Cluster
argument_list|)
decl_stmt|;
comment|/**      * Listens for a node to go over the high watermark and kicks off an empty      * reroute if it does. Also responsible for logging about nodes that have      * passed the disk watermarks      */
DECL|class|DiskListener
class|class
name|DiskListener
implements|implements
name|ClusterInfoService
operator|.
name|Listener
block|{
DECL|field|client
specifier|private
specifier|final
name|Client
name|client
decl_stmt|;
DECL|field|nodeHasPassedWatermark
specifier|private
specifier|final
name|Set
argument_list|<
name|String
argument_list|>
name|nodeHasPassedWatermark
init|=
name|Sets
operator|.
name|newConcurrentHashSet
argument_list|()
decl_stmt|;
DECL|field|lastRunNS
specifier|private
name|long
name|lastRunNS
decl_stmt|;
DECL|method|DiskListener
name|DiskListener
parameter_list|(
name|Client
name|client
parameter_list|)
block|{
name|this
operator|.
name|client
operator|=
name|client
expr_stmt|;
block|}
comment|/**          * Warn about the given disk usage if the low or high watermark has been passed          */
DECL|method|warnAboutDiskIfNeeded
specifier|private
name|void
name|warnAboutDiskIfNeeded
parameter_list|(
name|DiskUsage
name|usage
parameter_list|)
block|{
comment|// Check absolute disk values
if|if
condition|(
name|usage
operator|.
name|getFreeBytes
argument_list|()
operator|<
name|DiskThresholdDecider
operator|.
name|this
operator|.
name|freeBytesThresholdHigh
operator|.
name|bytes
argument_list|()
condition|)
block|{
name|logger
operator|.
name|warn
argument_list|(
literal|"high disk watermark [{}] exceeded on {}, shards will be relocated away from this node"
argument_list|,
name|DiskThresholdDecider
operator|.
name|this
operator|.
name|freeBytesThresholdHigh
argument_list|,
name|usage
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|usage
operator|.
name|getFreeBytes
argument_list|()
operator|<
name|DiskThresholdDecider
operator|.
name|this
operator|.
name|freeBytesThresholdLow
operator|.
name|bytes
argument_list|()
condition|)
block|{
name|logger
operator|.
name|info
argument_list|(
literal|"low disk watermark [{}] exceeded on {}, replicas will not be assigned to this node"
argument_list|,
name|DiskThresholdDecider
operator|.
name|this
operator|.
name|freeBytesThresholdLow
argument_list|,
name|usage
argument_list|)
expr_stmt|;
block|}
comment|// Check percentage disk values
if|if
condition|(
name|usage
operator|.
name|getFreeDiskAsPercentage
argument_list|()
operator|<
name|DiskThresholdDecider
operator|.
name|this
operator|.
name|freeDiskThresholdHigh
condition|)
block|{
name|logger
operator|.
name|warn
argument_list|(
literal|"high disk watermark [{}] exceeded on {}, shards will be relocated away from this node"
argument_list|,
name|Strings
operator|.
name|format1Decimals
argument_list|(
literal|100.0
operator|-
name|DiskThresholdDecider
operator|.
name|this
operator|.
name|freeDiskThresholdHigh
argument_list|,
literal|"%"
argument_list|)
argument_list|,
name|usage
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|usage
operator|.
name|getFreeDiskAsPercentage
argument_list|()
operator|<
name|DiskThresholdDecider
operator|.
name|this
operator|.
name|freeDiskThresholdLow
condition|)
block|{
name|logger
operator|.
name|info
argument_list|(
literal|"low disk watermark [{}] exceeded on {}, replicas will not be assigned to this node"
argument_list|,
name|Strings
operator|.
name|format1Decimals
argument_list|(
literal|100.0
operator|-
name|DiskThresholdDecider
operator|.
name|this
operator|.
name|freeDiskThresholdLow
argument_list|,
literal|"%"
argument_list|)
argument_list|,
name|usage
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Override
DECL|method|onNewInfo
specifier|public
name|void
name|onNewInfo
parameter_list|(
name|ClusterInfo
name|info
parameter_list|)
block|{
name|ImmutableOpenMap
argument_list|<
name|String
argument_list|,
name|DiskUsage
argument_list|>
name|usages
init|=
name|info
operator|.
name|getNodeLeastAvailableDiskUsages
argument_list|()
decl_stmt|;
if|if
condition|(
name|usages
operator|!=
literal|null
condition|)
block|{
name|boolean
name|reroute
init|=
literal|false
decl_stmt|;
name|String
name|explanation
init|=
literal|""
decl_stmt|;
comment|// Garbage collect nodes that have been removed from the cluster
comment|// from the map that tracks watermark crossing
name|ObjectLookupContainer
argument_list|<
name|String
argument_list|>
name|nodes
init|=
name|usages
operator|.
name|keys
argument_list|()
decl_stmt|;
for|for
control|(
name|String
name|node
range|:
name|nodeHasPassedWatermark
control|)
block|{
if|if
condition|(
name|nodes
operator|.
name|contains
argument_list|(
name|node
argument_list|)
operator|==
literal|false
condition|)
block|{
name|nodeHasPassedWatermark
operator|.
name|remove
argument_list|(
name|node
argument_list|)
expr_stmt|;
block|}
block|}
for|for
control|(
name|ObjectObjectCursor
argument_list|<
name|String
argument_list|,
name|DiskUsage
argument_list|>
name|entry
range|:
name|usages
control|)
block|{
name|String
name|node
init|=
name|entry
operator|.
name|key
decl_stmt|;
name|DiskUsage
name|usage
init|=
name|entry
operator|.
name|value
decl_stmt|;
name|warnAboutDiskIfNeeded
argument_list|(
name|usage
argument_list|)
expr_stmt|;
if|if
condition|(
name|usage
operator|.
name|getFreeBytes
argument_list|()
operator|<
name|DiskThresholdDecider
operator|.
name|this
operator|.
name|freeBytesThresholdHigh
operator|.
name|bytes
argument_list|()
operator|||
name|usage
operator|.
name|getFreeDiskAsPercentage
argument_list|()
operator|<
name|DiskThresholdDecider
operator|.
name|this
operator|.
name|freeDiskThresholdHigh
condition|)
block|{
if|if
condition|(
operator|(
name|System
operator|.
name|nanoTime
argument_list|()
operator|-
name|lastRunNS
operator|)
operator|>
name|DiskThresholdDecider
operator|.
name|this
operator|.
name|rerouteInterval
operator|.
name|nanos
argument_list|()
condition|)
block|{
name|lastRunNS
operator|=
name|System
operator|.
name|nanoTime
argument_list|()
expr_stmt|;
name|reroute
operator|=
literal|true
expr_stmt|;
name|explanation
operator|=
literal|"high disk watermark exceeded on one or more nodes"
expr_stmt|;
block|}
else|else
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"high disk watermark exceeded on {} but an automatic reroute has occurred in the last [{}], skipping reroute"
argument_list|,
name|node
argument_list|,
name|DiskThresholdDecider
operator|.
name|this
operator|.
name|rerouteInterval
argument_list|)
expr_stmt|;
block|}
name|nodeHasPassedWatermark
operator|.
name|add
argument_list|(
name|node
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|usage
operator|.
name|getFreeBytes
argument_list|()
operator|<
name|DiskThresholdDecider
operator|.
name|this
operator|.
name|freeBytesThresholdLow
operator|.
name|bytes
argument_list|()
operator|||
name|usage
operator|.
name|getFreeDiskAsPercentage
argument_list|()
operator|<
name|DiskThresholdDecider
operator|.
name|this
operator|.
name|freeDiskThresholdLow
condition|)
block|{
name|nodeHasPassedWatermark
operator|.
name|add
argument_list|(
name|node
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|nodeHasPassedWatermark
operator|.
name|contains
argument_list|(
name|node
argument_list|)
condition|)
block|{
comment|// The node has previously been over the high or
comment|// low watermark, but is no longer, so we should
comment|// reroute so any unassigned shards can be allocated
comment|// if they are able to be
if|if
condition|(
operator|(
name|System
operator|.
name|nanoTime
argument_list|()
operator|-
name|lastRunNS
operator|)
operator|>
name|DiskThresholdDecider
operator|.
name|this
operator|.
name|rerouteInterval
operator|.
name|nanos
argument_list|()
condition|)
block|{
name|lastRunNS
operator|=
name|System
operator|.
name|nanoTime
argument_list|()
expr_stmt|;
name|reroute
operator|=
literal|true
expr_stmt|;
name|explanation
operator|=
literal|"one or more nodes has gone under the high or low watermark"
expr_stmt|;
name|nodeHasPassedWatermark
operator|.
name|remove
argument_list|(
name|node
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"{} has gone below a disk threshold, but an automatic reroute has occurred in the last [{}], skipping reroute"
argument_list|,
name|node
argument_list|,
name|DiskThresholdDecider
operator|.
name|this
operator|.
name|rerouteInterval
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
if|if
condition|(
name|reroute
condition|)
block|{
name|logger
operator|.
name|info
argument_list|(
literal|"rerouting shards: [{}]"
argument_list|,
name|explanation
argument_list|)
expr_stmt|;
comment|// Execute an empty reroute, but don't block on the response
name|client
operator|.
name|admin
argument_list|()
operator|.
name|cluster
argument_list|()
operator|.
name|prepareReroute
argument_list|()
operator|.
name|execute
argument_list|()
expr_stmt|;
block|}
block|}
block|}
block|}
DECL|method|DiskThresholdDecider
specifier|public
name|DiskThresholdDecider
parameter_list|(
name|Settings
name|settings
parameter_list|)
block|{
comment|// It's okay the Client is null here, because the empty cluster info
comment|// service will never actually call the listener where the client is
comment|// needed. Also this constructor is only used for tests
name|this
argument_list|(
name|settings
argument_list|,
operator|new
name|ClusterSettingsService
argument_list|(
name|settings
argument_list|,
operator|new
name|ClusterSettings
argument_list|(
name|ClusterSettings
operator|.
name|BUILT_IN_CLUSTER_SETTINGS
argument_list|)
argument_list|)
argument_list|,
name|EmptyClusterInfoService
operator|.
name|INSTANCE
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Inject
DECL|method|DiskThresholdDecider
specifier|public
name|DiskThresholdDecider
parameter_list|(
name|Settings
name|settings
parameter_list|,
name|ClusterSettingsService
name|clusterSettingsService
parameter_list|,
name|ClusterInfoService
name|infoService
parameter_list|,
name|Client
name|client
parameter_list|)
block|{
name|super
argument_list|(
name|settings
argument_list|)
expr_stmt|;
specifier|final
name|String
name|lowWatermark
init|=
name|CLUSTER_ROUTING_ALLOCATION_LOW_DISK_WATERMARK_SETTING
operator|.
name|get
argument_list|(
name|settings
argument_list|)
decl_stmt|;
specifier|final
name|String
name|highWatermark
init|=
name|CLUSTER_ROUTING_ALLOCATION_HIGH_DISK_WATERMARK_SETTING
operator|.
name|get
argument_list|(
name|settings
argument_list|)
decl_stmt|;
name|setHighWatermark
argument_list|(
name|highWatermark
argument_list|)
expr_stmt|;
name|setLowWatermark
argument_list|(
name|lowWatermark
argument_list|)
expr_stmt|;
name|this
operator|.
name|includeRelocations
operator|=
name|CLUSTER_ROUTING_ALLOCATION_INCLUDE_RELOCATIONS_SETTING
operator|.
name|get
argument_list|(
name|settings
argument_list|)
expr_stmt|;
name|this
operator|.
name|rerouteInterval
operator|=
name|CLUSTER_ROUTING_ALLOCATION_REROUTE_INTERVAL_SETTING
operator|.
name|get
argument_list|(
name|settings
argument_list|)
expr_stmt|;
name|this
operator|.
name|enabled
operator|=
name|CLUSTER_ROUTING_ALLOCATION_DISK_THRESHOLD_ENABLED_SETTING
operator|.
name|get
argument_list|(
name|settings
argument_list|)
expr_stmt|;
name|clusterSettingsService
operator|.
name|addSettingsUpdateConsumer
argument_list|(
name|CLUSTER_ROUTING_ALLOCATION_LOW_DISK_WATERMARK_SETTING
argument_list|,
name|this
operator|::
name|setLowWatermark
argument_list|)
expr_stmt|;
name|clusterSettingsService
operator|.
name|addSettingsUpdateConsumer
argument_list|(
name|CLUSTER_ROUTING_ALLOCATION_HIGH_DISK_WATERMARK_SETTING
argument_list|,
name|this
operator|::
name|setHighWatermark
argument_list|)
expr_stmt|;
name|clusterSettingsService
operator|.
name|addSettingsUpdateConsumer
argument_list|(
name|CLUSTER_ROUTING_ALLOCATION_INCLUDE_RELOCATIONS_SETTING
argument_list|,
name|this
operator|::
name|setIncludeRelocations
argument_list|)
expr_stmt|;
name|clusterSettingsService
operator|.
name|addSettingsUpdateConsumer
argument_list|(
name|CLUSTER_ROUTING_ALLOCATION_REROUTE_INTERVAL_SETTING
argument_list|,
name|this
operator|::
name|setRerouteInterval
argument_list|)
expr_stmt|;
name|clusterSettingsService
operator|.
name|addSettingsUpdateConsumer
argument_list|(
name|CLUSTER_ROUTING_ALLOCATION_DISK_THRESHOLD_ENABLED_SETTING
argument_list|,
name|this
operator|::
name|setEnabled
argument_list|)
expr_stmt|;
name|infoService
operator|.
name|addListener
argument_list|(
operator|new
name|DiskListener
argument_list|(
name|client
argument_list|)
argument_list|)
expr_stmt|;
block|}
DECL|method|setIncludeRelocations
specifier|private
name|void
name|setIncludeRelocations
parameter_list|(
name|boolean
name|includeRelocations
parameter_list|)
block|{
name|this
operator|.
name|includeRelocations
operator|=
name|includeRelocations
expr_stmt|;
block|}
DECL|method|setRerouteInterval
specifier|private
name|void
name|setRerouteInterval
parameter_list|(
name|TimeValue
name|rerouteInterval
parameter_list|)
block|{
name|this
operator|.
name|rerouteInterval
operator|=
name|rerouteInterval
expr_stmt|;
block|}
DECL|method|setEnabled
specifier|private
name|void
name|setEnabled
parameter_list|(
name|boolean
name|enabled
parameter_list|)
block|{
name|this
operator|.
name|enabled
operator|=
name|enabled
expr_stmt|;
block|}
DECL|method|setLowWatermark
specifier|private
name|void
name|setLowWatermark
parameter_list|(
name|String
name|lowWatermark
parameter_list|)
block|{
comment|// Watermark is expressed in terms of used data, but we need "free" data watermark
name|this
operator|.
name|freeDiskThresholdLow
operator|=
literal|100.0
operator|-
name|thresholdPercentageFromWatermark
argument_list|(
name|lowWatermark
argument_list|)
expr_stmt|;
name|this
operator|.
name|freeBytesThresholdLow
operator|=
name|thresholdBytesFromWatermark
argument_list|(
name|lowWatermark
argument_list|,
name|CLUSTER_ROUTING_ALLOCATION_LOW_DISK_WATERMARK_SETTING
operator|.
name|getKey
argument_list|()
argument_list|)
expr_stmt|;
block|}
DECL|method|setHighWatermark
specifier|private
name|void
name|setHighWatermark
parameter_list|(
name|String
name|highWatermark
parameter_list|)
block|{
comment|// Watermark is expressed in terms of used data, but we need "free" data watermark
name|this
operator|.
name|freeDiskThresholdHigh
operator|=
literal|100.0
operator|-
name|thresholdPercentageFromWatermark
argument_list|(
name|highWatermark
argument_list|)
expr_stmt|;
name|this
operator|.
name|freeBytesThresholdHigh
operator|=
name|thresholdBytesFromWatermark
argument_list|(
name|highWatermark
argument_list|,
name|CLUSTER_ROUTING_ALLOCATION_LOW_DISK_WATERMARK_SETTING
operator|.
name|getKey
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// For Testing
DECL|method|getFreeDiskThresholdLow
specifier|public
name|Double
name|getFreeDiskThresholdLow
parameter_list|()
block|{
return|return
name|freeDiskThresholdLow
return|;
block|}
comment|// For Testing
DECL|method|getFreeDiskThresholdHigh
specifier|public
name|Double
name|getFreeDiskThresholdHigh
parameter_list|()
block|{
return|return
name|freeDiskThresholdHigh
return|;
block|}
comment|// For Testing
DECL|method|getUsedDiskThresholdLow
specifier|public
name|Double
name|getUsedDiskThresholdLow
parameter_list|()
block|{
return|return
literal|100.0
operator|-
name|freeDiskThresholdLow
return|;
block|}
comment|// For Testing
DECL|method|getUsedDiskThresholdHigh
specifier|public
name|Double
name|getUsedDiskThresholdHigh
parameter_list|()
block|{
return|return
literal|100.0
operator|-
name|freeDiskThresholdHigh
return|;
block|}
comment|// For Testing
DECL|method|getFreeBytesThresholdLow
specifier|public
name|ByteSizeValue
name|getFreeBytesThresholdLow
parameter_list|()
block|{
return|return
name|freeBytesThresholdLow
return|;
block|}
comment|// For Testing
DECL|method|getFreeBytesThresholdHigh
specifier|public
name|ByteSizeValue
name|getFreeBytesThresholdHigh
parameter_list|()
block|{
return|return
name|freeBytesThresholdHigh
return|;
block|}
comment|// For Testing
DECL|method|isIncludeRelocations
specifier|public
name|boolean
name|isIncludeRelocations
parameter_list|()
block|{
return|return
name|includeRelocations
return|;
block|}
comment|// For Testing
DECL|method|isEnabled
specifier|public
name|boolean
name|isEnabled
parameter_list|()
block|{
return|return
name|enabled
return|;
block|}
comment|// For Testing
DECL|method|getRerouteInterval
specifier|public
name|TimeValue
name|getRerouteInterval
parameter_list|()
block|{
return|return
name|rerouteInterval
return|;
block|}
comment|/**      * Returns the size of all shards that are currently being relocated to      * the node, but may not be finished transfering yet.      *      * If subtractShardsMovingAway is set then the size of shards moving away is subtracted from the total size      * of all shards      */
DECL|method|sizeOfRelocatingShards
specifier|public
specifier|static
name|long
name|sizeOfRelocatingShards
parameter_list|(
name|RoutingNode
name|node
parameter_list|,
name|ClusterInfo
name|clusterInfo
parameter_list|,
name|boolean
name|subtractShardsMovingAway
parameter_list|,
name|String
name|dataPath
parameter_list|)
block|{
name|long
name|totalSize
init|=
literal|0
decl_stmt|;
for|for
control|(
name|ShardRouting
name|routing
range|:
name|node
operator|.
name|shardsWithState
argument_list|(
name|ShardRoutingState
operator|.
name|RELOCATING
argument_list|,
name|ShardRoutingState
operator|.
name|INITIALIZING
argument_list|)
control|)
block|{
name|String
name|actualPath
init|=
name|clusterInfo
operator|.
name|getDataPath
argument_list|(
name|routing
argument_list|)
decl_stmt|;
if|if
condition|(
name|dataPath
operator|.
name|equals
argument_list|(
name|actualPath
argument_list|)
condition|)
block|{
if|if
condition|(
name|routing
operator|.
name|initializing
argument_list|()
operator|&&
name|routing
operator|.
name|relocatingNodeId
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|totalSize
operator|+=
name|getShardSize
argument_list|(
name|routing
argument_list|,
name|clusterInfo
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|subtractShardsMovingAway
operator|&&
name|routing
operator|.
name|relocating
argument_list|()
condition|)
block|{
name|totalSize
operator|-=
name|getShardSize
argument_list|(
name|routing
argument_list|,
name|clusterInfo
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|totalSize
return|;
block|}
DECL|method|getShardSize
specifier|static
name|long
name|getShardSize
parameter_list|(
name|ShardRouting
name|routing
parameter_list|,
name|ClusterInfo
name|clusterInfo
parameter_list|)
block|{
name|Long
name|shardSize
init|=
name|clusterInfo
operator|.
name|getShardSize
argument_list|(
name|routing
argument_list|)
decl_stmt|;
return|return
name|shardSize
operator|==
literal|null
condition|?
literal|0
else|:
name|shardSize
return|;
block|}
annotation|@
name|Override
DECL|method|canAllocate
specifier|public
name|Decision
name|canAllocate
parameter_list|(
name|ShardRouting
name|shardRouting
parameter_list|,
name|RoutingNode
name|node
parameter_list|,
name|RoutingAllocation
name|allocation
parameter_list|)
block|{
name|ClusterInfo
name|clusterInfo
init|=
name|allocation
operator|.
name|clusterInfo
argument_list|()
decl_stmt|;
name|ImmutableOpenMap
argument_list|<
name|String
argument_list|,
name|DiskUsage
argument_list|>
name|usages
init|=
name|clusterInfo
operator|.
name|getNodeMostAvailableDiskUsages
argument_list|()
decl_stmt|;
specifier|final
name|Decision
name|decision
init|=
name|earlyTerminate
argument_list|(
name|allocation
argument_list|,
name|usages
argument_list|)
decl_stmt|;
if|if
condition|(
name|decision
operator|!=
literal|null
condition|)
block|{
return|return
name|decision
return|;
block|}
specifier|final
name|double
name|usedDiskThresholdLow
init|=
literal|100.0
operator|-
name|DiskThresholdDecider
operator|.
name|this
operator|.
name|freeDiskThresholdLow
decl_stmt|;
specifier|final
name|double
name|usedDiskThresholdHigh
init|=
literal|100.0
operator|-
name|DiskThresholdDecider
operator|.
name|this
operator|.
name|freeDiskThresholdHigh
decl_stmt|;
name|DiskUsage
name|usage
init|=
name|getDiskUsage
argument_list|(
name|node
argument_list|,
name|allocation
argument_list|,
name|usages
argument_list|)
decl_stmt|;
comment|// First, check that the node currently over the low watermark
name|double
name|freeDiskPercentage
init|=
name|usage
operator|.
name|getFreeDiskAsPercentage
argument_list|()
decl_stmt|;
comment|// Cache the used disk percentage for displaying disk percentages consistent with documentation
name|double
name|usedDiskPercentage
init|=
name|usage
operator|.
name|getUsedDiskAsPercentage
argument_list|()
decl_stmt|;
name|long
name|freeBytes
init|=
name|usage
operator|.
name|getFreeBytes
argument_list|()
decl_stmt|;
if|if
condition|(
name|logger
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|trace
argument_list|(
literal|"node [{}] has {}% used disk"
argument_list|,
name|node
operator|.
name|nodeId
argument_list|()
argument_list|,
name|usedDiskPercentage
argument_list|)
expr_stmt|;
block|}
comment|// a flag for whether the primary shard has been previously allocated
name|boolean
name|primaryHasBeenAllocated
init|=
name|shardRouting
operator|.
name|primary
argument_list|()
operator|&&
name|shardRouting
operator|.
name|allocatedPostIndexCreate
argument_list|()
decl_stmt|;
comment|// checks for exact byte comparisons
if|if
condition|(
name|freeBytes
operator|<
name|freeBytesThresholdLow
operator|.
name|bytes
argument_list|()
condition|)
block|{
comment|// If the shard is a replica or has a primary that has already been allocated before, check the low threshold
if|if
condition|(
operator|!
name|shardRouting
operator|.
name|primary
argument_list|()
operator|||
operator|(
name|shardRouting
operator|.
name|primary
argument_list|()
operator|&&
name|primaryHasBeenAllocated
operator|)
condition|)
block|{
if|if
condition|(
name|logger
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"less than the required {} free bytes threshold ({} bytes free) on node {}, preventing allocation"
argument_list|,
name|freeBytesThresholdLow
argument_list|,
name|freeBytes
argument_list|,
name|node
operator|.
name|nodeId
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|allocation
operator|.
name|decision
argument_list|(
name|Decision
operator|.
name|NO
argument_list|,
name|NAME
argument_list|,
literal|"less than required [%s] free on node, free: [%s]"
argument_list|,
name|freeBytesThresholdLow
argument_list|,
operator|new
name|ByteSizeValue
argument_list|(
name|freeBytes
argument_list|)
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|freeBytes
operator|>
name|freeBytesThresholdHigh
operator|.
name|bytes
argument_list|()
condition|)
block|{
comment|// Allow the shard to be allocated because it is primary that
comment|// has never been allocated if it's under the high watermark
if|if
condition|(
name|logger
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"less than the required {} free bytes threshold ({} bytes free) on node {}, "
operator|+
literal|"but allowing allocation because primary has never been allocated"
argument_list|,
name|freeBytesThresholdLow
argument_list|,
name|freeBytes
argument_list|,
name|node
operator|.
name|nodeId
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|allocation
operator|.
name|decision
argument_list|(
name|Decision
operator|.
name|YES
argument_list|,
name|NAME
argument_list|,
literal|"primary has never been allocated before"
argument_list|)
return|;
block|}
else|else
block|{
comment|// Even though the primary has never been allocated, the node is
comment|// above the high watermark, so don't allow allocating the shard
if|if
condition|(
name|logger
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"less than the required {} free bytes threshold ({} bytes free) on node {}, "
operator|+
literal|"preventing allocation even though primary has never been allocated"
argument_list|,
name|freeBytesThresholdHigh
argument_list|,
name|freeBytes
argument_list|,
name|node
operator|.
name|nodeId
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|allocation
operator|.
name|decision
argument_list|(
name|Decision
operator|.
name|NO
argument_list|,
name|NAME
argument_list|,
literal|"less than required [%s] free on node, free: [%s]"
argument_list|,
name|freeBytesThresholdHigh
argument_list|,
operator|new
name|ByteSizeValue
argument_list|(
name|freeBytes
argument_list|)
argument_list|)
return|;
block|}
block|}
comment|// checks for percentage comparisons
if|if
condition|(
name|freeDiskPercentage
operator|<
name|freeDiskThresholdLow
condition|)
block|{
comment|// If the shard is a replica or has a primary that has already been allocated before, check the low threshold
if|if
condition|(
operator|!
name|shardRouting
operator|.
name|primary
argument_list|()
operator|||
operator|(
name|shardRouting
operator|.
name|primary
argument_list|()
operator|&&
name|primaryHasBeenAllocated
operator|)
condition|)
block|{
if|if
condition|(
name|logger
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"more than the allowed {} used disk threshold ({} used) on node [{}], preventing allocation"
argument_list|,
name|Strings
operator|.
name|format1Decimals
argument_list|(
name|usedDiskThresholdLow
argument_list|,
literal|"%"
argument_list|)
argument_list|,
name|Strings
operator|.
name|format1Decimals
argument_list|(
name|usedDiskPercentage
argument_list|,
literal|"%"
argument_list|)
argument_list|,
name|node
operator|.
name|nodeId
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|allocation
operator|.
name|decision
argument_list|(
name|Decision
operator|.
name|NO
argument_list|,
name|NAME
argument_list|,
literal|"more than allowed [%s%%] used disk on node, free: [%s%%]"
argument_list|,
name|usedDiskThresholdLow
argument_list|,
name|freeDiskPercentage
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|freeDiskPercentage
operator|>
name|freeDiskThresholdHigh
condition|)
block|{
comment|// Allow the shard to be allocated because it is primary that
comment|// has never been allocated if it's under the high watermark
if|if
condition|(
name|logger
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"more than the allowed {} used disk threshold ({} used) on node [{}], "
operator|+
literal|"but allowing allocation because primary has never been allocated"
argument_list|,
name|Strings
operator|.
name|format1Decimals
argument_list|(
name|usedDiskThresholdLow
argument_list|,
literal|"%"
argument_list|)
argument_list|,
name|Strings
operator|.
name|format1Decimals
argument_list|(
name|usedDiskPercentage
argument_list|,
literal|"%"
argument_list|)
argument_list|,
name|node
operator|.
name|nodeId
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|allocation
operator|.
name|decision
argument_list|(
name|Decision
operator|.
name|YES
argument_list|,
name|NAME
argument_list|,
literal|"primary has never been allocated before"
argument_list|)
return|;
block|}
else|else
block|{
comment|// Even though the primary has never been allocated, the node is
comment|// above the high watermark, so don't allow allocating the shard
if|if
condition|(
name|logger
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"less than the required {} free bytes threshold ({} bytes free) on node {}, "
operator|+
literal|"preventing allocation even though primary has never been allocated"
argument_list|,
name|Strings
operator|.
name|format1Decimals
argument_list|(
name|freeDiskThresholdHigh
argument_list|,
literal|"%"
argument_list|)
argument_list|,
name|Strings
operator|.
name|format1Decimals
argument_list|(
name|freeDiskPercentage
argument_list|,
literal|"%"
argument_list|)
argument_list|,
name|node
operator|.
name|nodeId
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|allocation
operator|.
name|decision
argument_list|(
name|Decision
operator|.
name|NO
argument_list|,
name|NAME
argument_list|,
literal|"more than allowed [%s%%] used disk on node, free: [%s%%]"
argument_list|,
name|usedDiskThresholdHigh
argument_list|,
name|freeDiskPercentage
argument_list|)
return|;
block|}
block|}
comment|// Secondly, check that allocating the shard to this node doesn't put it above the high watermark
specifier|final
name|long
name|shardSize
init|=
name|getShardSize
argument_list|(
name|shardRouting
argument_list|,
name|allocation
operator|.
name|clusterInfo
argument_list|()
argument_list|)
decl_stmt|;
name|double
name|freeSpaceAfterShard
init|=
name|freeDiskPercentageAfterShardAssigned
argument_list|(
name|usage
argument_list|,
name|shardSize
argument_list|)
decl_stmt|;
name|long
name|freeBytesAfterShard
init|=
name|freeBytes
operator|-
name|shardSize
decl_stmt|;
if|if
condition|(
name|freeBytesAfterShard
operator|<
name|freeBytesThresholdHigh
operator|.
name|bytes
argument_list|()
condition|)
block|{
name|logger
operator|.
name|warn
argument_list|(
literal|"after allocating, node [{}] would have less than the required {} free bytes threshold ({} bytes free), preventing allocation"
argument_list|,
name|node
operator|.
name|nodeId
argument_list|()
argument_list|,
name|freeBytesThresholdHigh
argument_list|,
name|freeBytesAfterShard
argument_list|)
expr_stmt|;
return|return
name|allocation
operator|.
name|decision
argument_list|(
name|Decision
operator|.
name|NO
argument_list|,
name|NAME
argument_list|,
literal|"after allocation less than required [%s] free on node, free: [%s]"
argument_list|,
name|freeBytesThresholdLow
argument_list|,
operator|new
name|ByteSizeValue
argument_list|(
name|freeBytesAfterShard
argument_list|)
argument_list|)
return|;
block|}
if|if
condition|(
name|freeSpaceAfterShard
operator|<
name|freeDiskThresholdHigh
condition|)
block|{
name|logger
operator|.
name|warn
argument_list|(
literal|"after allocating, node [{}] would have more than the allowed {} free disk threshold ({} free), preventing allocation"
argument_list|,
name|node
operator|.
name|nodeId
argument_list|()
argument_list|,
name|Strings
operator|.
name|format1Decimals
argument_list|(
name|freeDiskThresholdHigh
argument_list|,
literal|"%"
argument_list|)
argument_list|,
name|Strings
operator|.
name|format1Decimals
argument_list|(
name|freeSpaceAfterShard
argument_list|,
literal|"%"
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|allocation
operator|.
name|decision
argument_list|(
name|Decision
operator|.
name|NO
argument_list|,
name|NAME
argument_list|,
literal|"after allocation more than allowed [%s%%] used disk on node, free: [%s%%]"
argument_list|,
name|usedDiskThresholdLow
argument_list|,
name|freeSpaceAfterShard
argument_list|)
return|;
block|}
return|return
name|allocation
operator|.
name|decision
argument_list|(
name|Decision
operator|.
name|YES
argument_list|,
name|NAME
argument_list|,
literal|"enough disk for shard on node, free: [%s]"
argument_list|,
operator|new
name|ByteSizeValue
argument_list|(
name|freeBytes
argument_list|)
argument_list|)
return|;
block|}
annotation|@
name|Override
DECL|method|canRemain
specifier|public
name|Decision
name|canRemain
parameter_list|(
name|ShardRouting
name|shardRouting
parameter_list|,
name|RoutingNode
name|node
parameter_list|,
name|RoutingAllocation
name|allocation
parameter_list|)
block|{
if|if
condition|(
name|shardRouting
operator|.
name|currentNodeId
argument_list|()
operator|.
name|equals
argument_list|(
name|node
operator|.
name|nodeId
argument_list|()
argument_list|)
operator|==
literal|false
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Shard ["
operator|+
name|shardRouting
operator|+
literal|"] is not allocated on node: ["
operator|+
name|node
operator|.
name|nodeId
argument_list|()
operator|+
literal|"]"
argument_list|)
throw|;
block|}
specifier|final
name|ClusterInfo
name|clusterInfo
init|=
name|allocation
operator|.
name|clusterInfo
argument_list|()
decl_stmt|;
specifier|final
name|ImmutableOpenMap
argument_list|<
name|String
argument_list|,
name|DiskUsage
argument_list|>
name|usages
init|=
name|clusterInfo
operator|.
name|getNodeLeastAvailableDiskUsages
argument_list|()
decl_stmt|;
specifier|final
name|Decision
name|decision
init|=
name|earlyTerminate
argument_list|(
name|allocation
argument_list|,
name|usages
argument_list|)
decl_stmt|;
if|if
condition|(
name|decision
operator|!=
literal|null
condition|)
block|{
return|return
name|decision
return|;
block|}
specifier|final
name|DiskUsage
name|usage
init|=
name|getDiskUsage
argument_list|(
name|node
argument_list|,
name|allocation
argument_list|,
name|usages
argument_list|)
decl_stmt|;
specifier|final
name|String
name|dataPath
init|=
name|clusterInfo
operator|.
name|getDataPath
argument_list|(
name|shardRouting
argument_list|)
decl_stmt|;
comment|// If this node is already above the high threshold, the shard cannot remain (get it off!)
specifier|final
name|double
name|freeDiskPercentage
init|=
name|usage
operator|.
name|getFreeDiskAsPercentage
argument_list|()
decl_stmt|;
specifier|final
name|long
name|freeBytes
init|=
name|usage
operator|.
name|getFreeBytes
argument_list|()
decl_stmt|;
if|if
condition|(
name|logger
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|trace
argument_list|(
literal|"node [{}] has {}% free disk ({} bytes)"
argument_list|,
name|node
operator|.
name|nodeId
argument_list|()
argument_list|,
name|freeDiskPercentage
argument_list|,
name|freeBytes
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|dataPath
operator|==
literal|null
operator|||
name|usage
operator|.
name|getPath
argument_list|()
operator|.
name|equals
argument_list|(
name|dataPath
argument_list|)
operator|==
literal|false
condition|)
block|{
return|return
name|allocation
operator|.
name|decision
argument_list|(
name|Decision
operator|.
name|YES
argument_list|,
name|NAME
argument_list|,
literal|"shard is not allocated on the most utilized disk"
argument_list|)
return|;
block|}
if|if
condition|(
name|freeBytes
operator|<
name|freeBytesThresholdHigh
operator|.
name|bytes
argument_list|()
condition|)
block|{
if|if
condition|(
name|logger
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"less than the required {} free bytes threshold ({} bytes free) on node {}, shard cannot remain"
argument_list|,
name|freeBytesThresholdHigh
argument_list|,
name|freeBytes
argument_list|,
name|node
operator|.
name|nodeId
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|allocation
operator|.
name|decision
argument_list|(
name|Decision
operator|.
name|NO
argument_list|,
name|NAME
argument_list|,
literal|"after allocation less than required [%s] free on node, free: [%s]"
argument_list|,
name|freeBytesThresholdHigh
argument_list|,
operator|new
name|ByteSizeValue
argument_list|(
name|freeBytes
argument_list|)
argument_list|)
return|;
block|}
if|if
condition|(
name|freeDiskPercentage
operator|<
name|freeDiskThresholdHigh
condition|)
block|{
if|if
condition|(
name|logger
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"less than the required {}% free disk threshold ({}% free) on node {}, shard cannot remain"
argument_list|,
name|freeDiskThresholdHigh
argument_list|,
name|freeDiskPercentage
argument_list|,
name|node
operator|.
name|nodeId
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|allocation
operator|.
name|decision
argument_list|(
name|Decision
operator|.
name|NO
argument_list|,
name|NAME
argument_list|,
literal|"after allocation less than required [%s%%] free disk on node, free: [%s%%]"
argument_list|,
name|freeDiskThresholdHigh
argument_list|,
name|freeDiskPercentage
argument_list|)
return|;
block|}
return|return
name|allocation
operator|.
name|decision
argument_list|(
name|Decision
operator|.
name|YES
argument_list|,
name|NAME
argument_list|,
literal|"enough disk for shard to remain on node, free: [%s]"
argument_list|,
operator|new
name|ByteSizeValue
argument_list|(
name|freeBytes
argument_list|)
argument_list|)
return|;
block|}
DECL|method|getDiskUsage
specifier|private
name|DiskUsage
name|getDiskUsage
parameter_list|(
name|RoutingNode
name|node
parameter_list|,
name|RoutingAllocation
name|allocation
parameter_list|,
name|ImmutableOpenMap
argument_list|<
name|String
argument_list|,
name|DiskUsage
argument_list|>
name|usages
parameter_list|)
block|{
name|ClusterInfo
name|clusterInfo
init|=
name|allocation
operator|.
name|clusterInfo
argument_list|()
decl_stmt|;
name|DiskUsage
name|usage
init|=
name|usages
operator|.
name|get
argument_list|(
name|node
operator|.
name|nodeId
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|usage
operator|==
literal|null
condition|)
block|{
comment|// If there is no usage, and we have other nodes in the cluster,
comment|// use the average usage for all nodes as the usage for this node
name|usage
operator|=
name|averageUsage
argument_list|(
name|node
argument_list|,
name|usages
argument_list|)
expr_stmt|;
if|if
condition|(
name|logger
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"unable to determine disk usage for {}, defaulting to average across nodes [{} total] [{} free] [{}% free]"
argument_list|,
name|node
operator|.
name|nodeId
argument_list|()
argument_list|,
name|usage
operator|.
name|getTotalBytes
argument_list|()
argument_list|,
name|usage
operator|.
name|getFreeBytes
argument_list|()
argument_list|,
name|usage
operator|.
name|getFreeDiskAsPercentage
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|includeRelocations
condition|)
block|{
name|long
name|relocatingShardsSize
init|=
name|sizeOfRelocatingShards
argument_list|(
name|node
argument_list|,
name|clusterInfo
argument_list|,
literal|true
argument_list|,
name|usage
operator|.
name|getPath
argument_list|()
argument_list|)
decl_stmt|;
name|DiskUsage
name|usageIncludingRelocations
init|=
operator|new
name|DiskUsage
argument_list|(
name|node
operator|.
name|nodeId
argument_list|()
argument_list|,
name|node
operator|.
name|node
argument_list|()
operator|.
name|name
argument_list|()
argument_list|,
name|usage
operator|.
name|getPath
argument_list|()
argument_list|,
name|usage
operator|.
name|getTotalBytes
argument_list|()
argument_list|,
name|usage
operator|.
name|getFreeBytes
argument_list|()
operator|-
name|relocatingShardsSize
argument_list|)
decl_stmt|;
if|if
condition|(
name|logger
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|trace
argument_list|(
literal|"usage without relocations: {}"
argument_list|,
name|usage
argument_list|)
expr_stmt|;
name|logger
operator|.
name|trace
argument_list|(
literal|"usage with relocations: [{} bytes] {}"
argument_list|,
name|relocatingShardsSize
argument_list|,
name|usageIncludingRelocations
argument_list|)
expr_stmt|;
block|}
name|usage
operator|=
name|usageIncludingRelocations
expr_stmt|;
block|}
return|return
name|usage
return|;
block|}
comment|/**      * Returns a {@link DiskUsage} for the {@link RoutingNode} using the      * average usage of other nodes in the disk usage map.      * @param node Node to return an averaged DiskUsage object for      * @param usages Map of nodeId to DiskUsage for all known nodes      * @return DiskUsage representing given node using the average disk usage      */
DECL|method|averageUsage
specifier|public
name|DiskUsage
name|averageUsage
parameter_list|(
name|RoutingNode
name|node
parameter_list|,
name|ImmutableOpenMap
argument_list|<
name|String
argument_list|,
name|DiskUsage
argument_list|>
name|usages
parameter_list|)
block|{
if|if
condition|(
name|usages
operator|.
name|size
argument_list|()
operator|==
literal|0
condition|)
block|{
return|return
operator|new
name|DiskUsage
argument_list|(
name|node
operator|.
name|nodeId
argument_list|()
argument_list|,
name|node
operator|.
name|node
argument_list|()
operator|.
name|name
argument_list|()
argument_list|,
literal|"_na_"
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|)
return|;
block|}
name|long
name|totalBytes
init|=
literal|0
decl_stmt|;
name|long
name|freeBytes
init|=
literal|0
decl_stmt|;
for|for
control|(
name|ObjectCursor
argument_list|<
name|DiskUsage
argument_list|>
name|du
range|:
name|usages
operator|.
name|values
argument_list|()
control|)
block|{
name|totalBytes
operator|+=
name|du
operator|.
name|value
operator|.
name|getTotalBytes
argument_list|()
expr_stmt|;
name|freeBytes
operator|+=
name|du
operator|.
name|value
operator|.
name|getFreeBytes
argument_list|()
expr_stmt|;
block|}
return|return
operator|new
name|DiskUsage
argument_list|(
name|node
operator|.
name|nodeId
argument_list|()
argument_list|,
name|node
operator|.
name|node
argument_list|()
operator|.
name|name
argument_list|()
argument_list|,
literal|"_na_"
argument_list|,
name|totalBytes
operator|/
name|usages
operator|.
name|size
argument_list|()
argument_list|,
name|freeBytes
operator|/
name|usages
operator|.
name|size
argument_list|()
argument_list|)
return|;
block|}
comment|/**      * Given the DiskUsage for a node and the size of the shard, return the      * percentage of free disk if the shard were to be allocated to the node.      * @param usage A DiskUsage for the node to have space computed for      * @param shardSize Size in bytes of the shard      * @return Percentage of free space after the shard is assigned to the node      */
DECL|method|freeDiskPercentageAfterShardAssigned
specifier|public
name|double
name|freeDiskPercentageAfterShardAssigned
parameter_list|(
name|DiskUsage
name|usage
parameter_list|,
name|Long
name|shardSize
parameter_list|)
block|{
name|shardSize
operator|=
operator|(
name|shardSize
operator|==
literal|null
operator|)
condition|?
literal|0
else|:
name|shardSize
expr_stmt|;
name|DiskUsage
name|newUsage
init|=
operator|new
name|DiskUsage
argument_list|(
name|usage
operator|.
name|getNodeId
argument_list|()
argument_list|,
name|usage
operator|.
name|getNodeName
argument_list|()
argument_list|,
name|usage
operator|.
name|getPath
argument_list|()
argument_list|,
name|usage
operator|.
name|getTotalBytes
argument_list|()
argument_list|,
name|usage
operator|.
name|getFreeBytes
argument_list|()
operator|-
name|shardSize
argument_list|)
decl_stmt|;
return|return
name|newUsage
operator|.
name|getFreeDiskAsPercentage
argument_list|()
return|;
block|}
comment|/**      * Attempts to parse the watermark into a percentage, returning 100.0% if      * it cannot be parsed.      */
DECL|method|thresholdPercentageFromWatermark
specifier|public
name|double
name|thresholdPercentageFromWatermark
parameter_list|(
name|String
name|watermark
parameter_list|)
block|{
try|try
block|{
return|return
name|RatioValue
operator|.
name|parseRatioValue
argument_list|(
name|watermark
argument_list|)
operator|.
name|getAsPercent
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|ElasticsearchParseException
name|ex
parameter_list|)
block|{
comment|// NOTE: this is not end-user leniency, since up above we check that it's a valid byte or percentage, and then store the two cases separately
return|return
literal|100.0
return|;
block|}
block|}
comment|/**      * Attempts to parse the watermark into a {@link ByteSizeValue}, returning      * a ByteSizeValue of 0 bytes if the value cannot be parsed.      */
DECL|method|thresholdBytesFromWatermark
specifier|public
name|ByteSizeValue
name|thresholdBytesFromWatermark
parameter_list|(
name|String
name|watermark
parameter_list|,
name|String
name|settingName
parameter_list|)
block|{
try|try
block|{
return|return
name|ByteSizeValue
operator|.
name|parseBytesSizeValue
argument_list|(
name|watermark
argument_list|,
name|settingName
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|ElasticsearchParseException
name|ex
parameter_list|)
block|{
comment|// NOTE: this is not end-user leniency, since up above we check that it's a valid byte or percentage, and then store the two cases separately
return|return
name|ByteSizeValue
operator|.
name|parseBytesSizeValue
argument_list|(
literal|"0b"
argument_list|,
name|settingName
argument_list|)
return|;
block|}
block|}
comment|/**      * Checks if a watermark string is a valid percentage or byte size value,      * returning true if valid, false if invalid.      */
DECL|method|validWatermarkSetting
specifier|public
specifier|static
name|String
name|validWatermarkSetting
parameter_list|(
name|String
name|watermark
parameter_list|,
name|String
name|settingName
parameter_list|)
block|{
try|try
block|{
name|RatioValue
operator|.
name|parseRatioValue
argument_list|(
name|watermark
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ElasticsearchParseException
name|e
parameter_list|)
block|{
try|try
block|{
name|ByteSizeValue
operator|.
name|parseBytesSizeValue
argument_list|(
name|watermark
argument_list|,
name|settingName
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ElasticsearchParseException
name|ex
parameter_list|)
block|{
name|ex
operator|.
name|addSuppressed
argument_list|(
name|e
argument_list|)
expr_stmt|;
throw|throw
name|ex
throw|;
block|}
block|}
return|return
name|watermark
return|;
block|}
DECL|method|earlyTerminate
specifier|private
name|Decision
name|earlyTerminate
parameter_list|(
name|RoutingAllocation
name|allocation
parameter_list|,
name|ImmutableOpenMap
argument_list|<
name|String
argument_list|,
name|DiskUsage
argument_list|>
name|usages
parameter_list|)
block|{
comment|// Always allow allocation if the decider is disabled
if|if
condition|(
operator|!
name|enabled
condition|)
block|{
return|return
name|allocation
operator|.
name|decision
argument_list|(
name|Decision
operator|.
name|YES
argument_list|,
name|NAME
argument_list|,
literal|"disk threshold decider disabled"
argument_list|)
return|;
block|}
comment|// Allow allocation regardless if only a single data node is available
if|if
condition|(
name|allocation
operator|.
name|nodes
argument_list|()
operator|.
name|dataNodes
argument_list|()
operator|.
name|size
argument_list|()
operator|<=
literal|1
condition|)
block|{
if|if
condition|(
name|logger
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|trace
argument_list|(
literal|"only a single data node is present, allowing allocation"
argument_list|)
expr_stmt|;
block|}
return|return
name|allocation
operator|.
name|decision
argument_list|(
name|Decision
operator|.
name|YES
argument_list|,
name|NAME
argument_list|,
literal|"only a single data node is present"
argument_list|)
return|;
block|}
comment|// Fail open there is no info available
specifier|final
name|ClusterInfo
name|clusterInfo
init|=
name|allocation
operator|.
name|clusterInfo
argument_list|()
decl_stmt|;
if|if
condition|(
name|clusterInfo
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|logger
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|trace
argument_list|(
literal|"cluster info unavailable for disk threshold decider, allowing allocation."
argument_list|)
expr_stmt|;
block|}
return|return
name|allocation
operator|.
name|decision
argument_list|(
name|Decision
operator|.
name|YES
argument_list|,
name|NAME
argument_list|,
literal|"cluster info unavailable"
argument_list|)
return|;
block|}
comment|// Fail open if there are no disk usages available
if|if
condition|(
name|usages
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
if|if
condition|(
name|logger
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|trace
argument_list|(
literal|"unable to determine disk usages for disk-aware allocation, allowing allocation"
argument_list|)
expr_stmt|;
block|}
return|return
name|allocation
operator|.
name|decision
argument_list|(
name|Decision
operator|.
name|YES
argument_list|,
name|NAME
argument_list|,
literal|"disk usages unavailable"
argument_list|)
return|;
block|}
return|return
literal|null
return|;
block|}
block|}
end_class

end_unit

