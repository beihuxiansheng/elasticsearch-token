begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to Elasticsearch under one or more contributor  * license agreements. See the NOTICE file distributed with  * this work for additional information regarding copyright  * ownership. Elasticsearch licenses this file to you under  * the Apache License, Version 2.0 (the "License"); you may  * not use this file except in compliance with the License.  * You may obtain a copy of the License at  *  *    http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing,  * software distributed under the License is distributed on an  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY  * KIND, either express or implied.  See the License for the  * specific language governing permissions and limitations  * under the License.  */
end_comment

begin_package
DECL|package|org.elasticsearch.gateway
package|package
name|org
operator|.
name|elasticsearch
operator|.
name|gateway
package|;
end_package

begin_import
import|import
name|com
operator|.
name|carrotsearch
operator|.
name|hppc
operator|.
name|ObjectLongHashMap
import|;
end_import

begin_import
import|import
name|com
operator|.
name|carrotsearch
operator|.
name|hppc
operator|.
name|cursors
operator|.
name|ObjectCursor
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Lists
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Maps
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Sets
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|CollectionUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|action
operator|.
name|support
operator|.
name|nodes
operator|.
name|BaseNodeResponse
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|action
operator|.
name|support
operator|.
name|nodes
operator|.
name|BaseNodesResponse
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|*
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|metadata
operator|.
name|IndexMetaData
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|metadata
operator|.
name|MetaData
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|node
operator|.
name|DiscoveryNode
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|node
operator|.
name|DiscoveryNodes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|routing
operator|.
name|*
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|routing
operator|.
name|RoutingNode
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|routing
operator|.
name|RoutingNodes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|routing
operator|.
name|ShardRouting
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|routing
operator|.
name|allocation
operator|.
name|FailedRerouteAllocation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|routing
operator|.
name|allocation
operator|.
name|RoutingAllocation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|routing
operator|.
name|allocation
operator|.
name|StartedRerouteAllocation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|routing
operator|.
name|allocation
operator|.
name|decider
operator|.
name|Decision
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|component
operator|.
name|AbstractComponent
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|inject
operator|.
name|Inject
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|lease
operator|.
name|Releasables
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|logging
operator|.
name|ESLogger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|settings
operator|.
name|Settings
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|unit
operator|.
name|ByteSizeValue
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|unit
operator|.
name|TimeValue
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ConcurrentCollections
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|index
operator|.
name|settings
operator|.
name|IndexSettings
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|index
operator|.
name|shard
operator|.
name|ShardId
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|index
operator|.
name|store
operator|.
name|StoreFileMetaData
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|indices
operator|.
name|store
operator|.
name|TransportNodesListShardStoreMetaData
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|*
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ConcurrentMap
import|;
end_import

begin_comment
comment|/**  *  */
end_comment

begin_class
DECL|class|GatewayAllocator
specifier|public
class|class
name|GatewayAllocator
extends|extends
name|AbstractComponent
block|{
DECL|field|INDEX_RECOVERY_INITIAL_SHARDS
specifier|public
specifier|static
specifier|final
name|String
name|INDEX_RECOVERY_INITIAL_SHARDS
init|=
literal|"index.recovery.initial_shards"
decl_stmt|;
DECL|field|initialShards
specifier|private
specifier|final
name|String
name|initialShards
decl_stmt|;
DECL|field|startedAction
specifier|private
specifier|final
name|TransportNodesListGatewayStartedShards
name|startedAction
decl_stmt|;
DECL|field|storeAction
specifier|private
specifier|final
name|TransportNodesListShardStoreMetaData
name|storeAction
decl_stmt|;
DECL|field|routingService
specifier|private
name|RoutingService
name|routingService
decl_stmt|;
DECL|field|asyncFetchStarted
specifier|private
specifier|final
name|ConcurrentMap
argument_list|<
name|ShardId
argument_list|,
name|AsyncShardFetch
argument_list|<
name|TransportNodesListGatewayStartedShards
operator|.
name|NodeGatewayStartedShards
argument_list|>
argument_list|>
name|asyncFetchStarted
init|=
name|ConcurrentCollections
operator|.
name|newConcurrentMap
argument_list|()
decl_stmt|;
DECL|field|asyncFetchStore
specifier|private
specifier|final
name|ConcurrentMap
argument_list|<
name|ShardId
argument_list|,
name|AsyncShardFetch
argument_list|<
name|TransportNodesListShardStoreMetaData
operator|.
name|NodeStoreFilesMetaData
argument_list|>
argument_list|>
name|asyncFetchStore
init|=
name|ConcurrentCollections
operator|.
name|newConcurrentMap
argument_list|()
decl_stmt|;
annotation|@
name|Inject
DECL|method|GatewayAllocator
specifier|public
name|GatewayAllocator
parameter_list|(
name|Settings
name|settings
parameter_list|,
name|TransportNodesListGatewayStartedShards
name|startedAction
parameter_list|,
name|TransportNodesListShardStoreMetaData
name|storeAction
parameter_list|)
block|{
name|super
argument_list|(
name|settings
argument_list|)
expr_stmt|;
name|this
operator|.
name|startedAction
operator|=
name|startedAction
expr_stmt|;
name|this
operator|.
name|storeAction
operator|=
name|storeAction
expr_stmt|;
name|this
operator|.
name|initialShards
operator|=
name|settings
operator|.
name|get
argument_list|(
literal|"gateway.initial_shards"
argument_list|,
name|settings
operator|.
name|get
argument_list|(
literal|"gateway.local.initial_shards"
argument_list|,
literal|"quorum"
argument_list|)
argument_list|)
expr_stmt|;
name|logger
operator|.
name|debug
argument_list|(
literal|"using initial_shards [{}]"
argument_list|,
name|initialShards
argument_list|)
expr_stmt|;
block|}
DECL|method|setReallocation
specifier|public
name|void
name|setReallocation
parameter_list|(
specifier|final
name|ClusterService
name|clusterService
parameter_list|,
specifier|final
name|RoutingService
name|routingService
parameter_list|)
block|{
name|this
operator|.
name|routingService
operator|=
name|routingService
expr_stmt|;
name|clusterService
operator|.
name|add
argument_list|(
operator|new
name|ClusterStateListener
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|clusterChanged
parameter_list|(
name|ClusterChangedEvent
name|event
parameter_list|)
block|{
name|boolean
name|cleanCache
init|=
literal|false
decl_stmt|;
name|DiscoveryNode
name|localNode
init|=
name|event
operator|.
name|state
argument_list|()
operator|.
name|nodes
argument_list|()
operator|.
name|localNode
argument_list|()
decl_stmt|;
if|if
condition|(
name|localNode
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|localNode
operator|.
name|masterNode
argument_list|()
operator|==
literal|true
operator|&&
name|event
operator|.
name|localNodeMaster
argument_list|()
operator|==
literal|false
condition|)
block|{
name|cleanCache
operator|=
literal|true
expr_stmt|;
block|}
block|}
else|else
block|{
name|cleanCache
operator|=
literal|true
expr_stmt|;
block|}
if|if
condition|(
name|cleanCache
condition|)
block|{
name|Releasables
operator|.
name|close
argument_list|(
name|asyncFetchStarted
operator|.
name|values
argument_list|()
argument_list|)
expr_stmt|;
name|asyncFetchStarted
operator|.
name|clear
argument_list|()
expr_stmt|;
name|Releasables
operator|.
name|close
argument_list|(
name|asyncFetchStore
operator|.
name|values
argument_list|()
argument_list|)
expr_stmt|;
name|asyncFetchStore
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
block|}
block|}
argument_list|)
expr_stmt|;
block|}
DECL|method|getNumberOfInFlightFetch
specifier|public
name|int
name|getNumberOfInFlightFetch
parameter_list|()
block|{
name|int
name|count
init|=
literal|0
decl_stmt|;
for|for
control|(
name|AsyncShardFetch
argument_list|<
name|TransportNodesListGatewayStartedShards
operator|.
name|NodeGatewayStartedShards
argument_list|>
name|fetch
range|:
name|asyncFetchStarted
operator|.
name|values
argument_list|()
control|)
block|{
name|count
operator|+=
name|fetch
operator|.
name|getNumberOfInFlightFetches
argument_list|()
expr_stmt|;
block|}
for|for
control|(
name|AsyncShardFetch
argument_list|<
name|TransportNodesListShardStoreMetaData
operator|.
name|NodeStoreFilesMetaData
argument_list|>
name|fetch
range|:
name|asyncFetchStore
operator|.
name|values
argument_list|()
control|)
block|{
name|count
operator|+=
name|fetch
operator|.
name|getNumberOfInFlightFetches
argument_list|()
expr_stmt|;
block|}
return|return
name|count
return|;
block|}
DECL|method|applyStartedShards
specifier|public
name|void
name|applyStartedShards
parameter_list|(
name|StartedRerouteAllocation
name|allocation
parameter_list|)
block|{
for|for
control|(
name|ShardRouting
name|shard
range|:
name|allocation
operator|.
name|startedShards
argument_list|()
control|)
block|{
name|Releasables
operator|.
name|close
argument_list|(
name|asyncFetchStarted
operator|.
name|remove
argument_list|(
name|shard
operator|.
name|shardId
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|Releasables
operator|.
name|close
argument_list|(
name|asyncFetchStore
operator|.
name|remove
argument_list|(
name|shard
operator|.
name|shardId
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|applyFailedShards
specifier|public
name|void
name|applyFailedShards
parameter_list|(
name|FailedRerouteAllocation
name|allocation
parameter_list|)
block|{
for|for
control|(
name|FailedRerouteAllocation
operator|.
name|FailedShard
name|shard
range|:
name|allocation
operator|.
name|failedShards
argument_list|()
control|)
block|{
name|Releasables
operator|.
name|close
argument_list|(
name|asyncFetchStarted
operator|.
name|remove
argument_list|(
name|shard
operator|.
name|shard
operator|.
name|shardId
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|Releasables
operator|.
name|close
argument_list|(
name|asyncFetchStore
operator|.
name|remove
argument_list|(
name|shard
operator|.
name|shard
operator|.
name|shardId
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**      * Return {@code true} if the index is configured to allow shards to be      * recovered on any node      */
DECL|method|recoverOnAnyNode
specifier|private
name|boolean
name|recoverOnAnyNode
parameter_list|(
annotation|@
name|IndexSettings
name|Settings
name|idxSettings
parameter_list|)
block|{
return|return
name|IndexMetaData
operator|.
name|isOnSharedFilesystem
argument_list|(
name|idxSettings
argument_list|)
operator|&&
name|idxSettings
operator|.
name|getAsBoolean
argument_list|(
name|IndexMetaData
operator|.
name|SETTING_SHARED_FS_ALLOW_RECOVERY_ON_ANY_NODE
argument_list|,
literal|false
argument_list|)
return|;
block|}
DECL|method|allocateUnassigned
specifier|public
name|boolean
name|allocateUnassigned
parameter_list|(
name|RoutingAllocation
name|allocation
parameter_list|)
block|{
name|boolean
name|changed
init|=
literal|false
decl_stmt|;
name|DiscoveryNodes
name|nodes
init|=
name|allocation
operator|.
name|nodes
argument_list|()
decl_stmt|;
name|RoutingNodes
name|routingNodes
init|=
name|allocation
operator|.
name|routingNodes
argument_list|()
decl_stmt|;
comment|// First, handle primaries, they must find a place to be allocated on here
name|MetaData
name|metaData
init|=
name|routingNodes
operator|.
name|metaData
argument_list|()
decl_stmt|;
name|Iterator
argument_list|<
name|ShardRouting
argument_list|>
name|unassignedIterator
init|=
name|routingNodes
operator|.
name|unassigned
argument_list|()
operator|.
name|iterator
argument_list|()
decl_stmt|;
while|while
condition|(
name|unassignedIterator
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|ShardRouting
name|shard
init|=
name|unassignedIterator
operator|.
name|next
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|shard
operator|.
name|primary
argument_list|()
condition|)
block|{
continue|continue;
block|}
comment|// this is an API allocation, ignore since we know there is no data...
if|if
condition|(
operator|!
name|routingNodes
operator|.
name|routingTable
argument_list|()
operator|.
name|index
argument_list|(
name|shard
operator|.
name|index
argument_list|()
argument_list|)
operator|.
name|shard
argument_list|(
name|shard
operator|.
name|id
argument_list|()
argument_list|)
operator|.
name|primaryAllocatedPostApi
argument_list|()
condition|)
block|{
continue|continue;
block|}
name|AsyncShardFetch
argument_list|<
name|TransportNodesListGatewayStartedShards
operator|.
name|NodeGatewayStartedShards
argument_list|>
name|fetch
init|=
name|asyncFetchStarted
operator|.
name|get
argument_list|(
name|shard
operator|.
name|shardId
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|fetch
operator|==
literal|null
condition|)
block|{
name|fetch
operator|=
operator|new
name|InternalAsyncFetch
argument_list|<>
argument_list|(
name|logger
argument_list|,
literal|"shard_started"
argument_list|,
name|shard
operator|.
name|shardId
argument_list|()
argument_list|,
name|startedAction
argument_list|)
expr_stmt|;
name|asyncFetchStarted
operator|.
name|put
argument_list|(
name|shard
operator|.
name|shardId
argument_list|()
argument_list|,
name|fetch
argument_list|)
expr_stmt|;
block|}
name|AsyncShardFetch
operator|.
name|FetchResult
argument_list|<
name|TransportNodesListGatewayStartedShards
operator|.
name|NodeGatewayStartedShards
argument_list|>
name|shardState
init|=
name|fetch
operator|.
name|fetchData
argument_list|(
name|nodes
argument_list|,
name|metaData
argument_list|,
name|allocation
operator|.
name|getIgnoreNodes
argument_list|(
name|shard
operator|.
name|shardId
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|shardState
operator|.
name|hasData
argument_list|()
operator|==
literal|false
condition|)
block|{
name|logger
operator|.
name|trace
argument_list|(
literal|"{}: ignoring allocation, still fetching shard started state"
argument_list|,
name|shard
argument_list|)
expr_stmt|;
name|unassignedIterator
operator|.
name|remove
argument_list|()
expr_stmt|;
name|routingNodes
operator|.
name|ignoredUnassigned
argument_list|()
operator|.
name|add
argument_list|(
name|shard
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|shardState
operator|.
name|processAllocation
argument_list|(
name|allocation
argument_list|)
expr_stmt|;
name|IndexMetaData
name|indexMetaData
init|=
name|metaData
operator|.
name|index
argument_list|(
name|shard
operator|.
name|getIndex
argument_list|()
argument_list|)
decl_stmt|;
comment|/**              * Build a map of DiscoveryNodes to shard state number for the given shard.              * A state of -1 means the shard does not exist on the node, where any              * shard state>= 0 is the state version of the shard on that node's disk.              *              * A shard on shared storage will return at least shard state 0 for all              * nodes, indicating that the shard can be allocated to any node.              */
name|ObjectLongHashMap
argument_list|<
name|DiscoveryNode
argument_list|>
name|nodesState
init|=
operator|new
name|ObjectLongHashMap
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|TransportNodesListGatewayStartedShards
operator|.
name|NodeGatewayStartedShards
name|nodeShardState
range|:
name|shardState
operator|.
name|getData
argument_list|()
operator|.
name|values
argument_list|()
control|)
block|{
name|long
name|version
init|=
name|nodeShardState
operator|.
name|version
argument_list|()
decl_stmt|;
comment|// -1 version means it does not exists, which is what the API returns, and what we expect to
name|logger
operator|.
name|trace
argument_list|(
literal|"[{}] on node [{}] has version [{}] of shard"
argument_list|,
name|shard
argument_list|,
name|nodeShardState
operator|.
name|getNode
argument_list|()
argument_list|,
name|version
argument_list|)
expr_stmt|;
name|nodesState
operator|.
name|put
argument_list|(
name|nodeShardState
operator|.
name|getNode
argument_list|()
argument_list|,
name|version
argument_list|)
expr_stmt|;
block|}
name|int
name|numberOfAllocationsFound
init|=
literal|0
decl_stmt|;
name|long
name|highestVersion
init|=
operator|-
literal|1
decl_stmt|;
specifier|final
name|Map
argument_list|<
name|DiscoveryNode
argument_list|,
name|Long
argument_list|>
name|nodesWithVersion
init|=
name|Maps
operator|.
name|newHashMap
argument_list|()
decl_stmt|;
assert|assert
operator|!
name|nodesState
operator|.
name|containsKey
argument_list|(
literal|null
argument_list|)
assert|;
specifier|final
name|Object
index|[]
name|keys
init|=
name|nodesState
operator|.
name|keys
decl_stmt|;
specifier|final
name|long
index|[]
name|values
init|=
name|nodesState
operator|.
name|values
decl_stmt|;
name|Settings
name|idxSettings
init|=
name|indexMetaData
operator|.
name|settings
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|keys
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|keys
index|[
name|i
index|]
operator|==
literal|null
condition|)
block|{
continue|continue;
block|}
name|DiscoveryNode
name|node
init|=
operator|(
name|DiscoveryNode
operator|)
name|keys
index|[
name|i
index|]
decl_stmt|;
name|long
name|version
init|=
name|values
index|[
name|i
index|]
decl_stmt|;
comment|// since we don't check in NO allocation, we need to double check here
if|if
condition|(
name|allocation
operator|.
name|shouldIgnoreShardForNode
argument_list|(
name|shard
operator|.
name|shardId
argument_list|()
argument_list|,
name|node
operator|.
name|id
argument_list|()
argument_list|)
condition|)
block|{
continue|continue;
block|}
if|if
condition|(
name|recoverOnAnyNode
argument_list|(
name|idxSettings
argument_list|)
condition|)
block|{
name|numberOfAllocationsFound
operator|++
expr_stmt|;
if|if
condition|(
name|version
operator|>
name|highestVersion
condition|)
block|{
name|highestVersion
operator|=
name|version
expr_stmt|;
block|}
comment|// We always put the node without clearing the map
name|nodesWithVersion
operator|.
name|put
argument_list|(
name|node
argument_list|,
name|version
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|version
operator|!=
operator|-
literal|1
condition|)
block|{
name|numberOfAllocationsFound
operator|++
expr_stmt|;
comment|// If we've found a new "best" candidate, clear the
comment|// current candidates and add it
if|if
condition|(
name|version
operator|>
name|highestVersion
condition|)
block|{
name|highestVersion
operator|=
name|version
expr_stmt|;
name|nodesWithVersion
operator|.
name|clear
argument_list|()
expr_stmt|;
name|nodesWithVersion
operator|.
name|put
argument_list|(
name|node
argument_list|,
name|version
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|version
operator|==
name|highestVersion
condition|)
block|{
comment|// If the candidate is the same, add it to the
comment|// list, but keep the current candidate
name|nodesWithVersion
operator|.
name|put
argument_list|(
name|node
argument_list|,
name|version
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|// Now that we have a map of nodes to versions along with the
comment|// number of allocations found (and not ignored), we need to sort
comment|// it so the node with the highest version is at the beginning
name|List
argument_list|<
name|DiscoveryNode
argument_list|>
name|nodesWithHighestVersion
init|=
name|Lists
operator|.
name|newArrayList
argument_list|()
decl_stmt|;
name|nodesWithHighestVersion
operator|.
name|addAll
argument_list|(
name|nodesWithVersion
operator|.
name|keySet
argument_list|()
argument_list|)
expr_stmt|;
name|CollectionUtil
operator|.
name|timSort
argument_list|(
name|nodesWithHighestVersion
argument_list|,
operator|new
name|Comparator
argument_list|<
name|DiscoveryNode
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|int
name|compare
parameter_list|(
name|DiscoveryNode
name|o1
parameter_list|,
name|DiscoveryNode
name|o2
parameter_list|)
block|{
return|return
name|Long
operator|.
name|compare
argument_list|(
name|nodesWithVersion
operator|.
name|get
argument_list|(
name|o2
argument_list|)
argument_list|,
name|nodesWithVersion
operator|.
name|get
argument_list|(
name|o1
argument_list|)
argument_list|)
return|;
block|}
block|}
argument_list|)
expr_stmt|;
if|if
condition|(
name|logger
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"[{}][{}] found {} allocations of {}, highest version: [{}]"
argument_list|,
name|shard
operator|.
name|index
argument_list|()
argument_list|,
name|shard
operator|.
name|id
argument_list|()
argument_list|,
name|numberOfAllocationsFound
argument_list|,
name|shard
argument_list|,
name|highestVersion
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|logger
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|(
literal|"["
argument_list|)
decl_stmt|;
for|for
control|(
name|DiscoveryNode
name|n
range|:
name|nodesWithHighestVersion
control|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|"["
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
name|n
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|"]"
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|" -> "
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
name|nodesWithVersion
operator|.
name|get
argument_list|(
name|n
argument_list|)
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", "
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|append
argument_list|(
literal|"]"
argument_list|)
expr_stmt|;
name|logger
operator|.
name|trace
argument_list|(
literal|"{} candidates for allocation: {}"
argument_list|,
name|shard
argument_list|,
name|sb
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// check if the counts meets the minimum set
name|int
name|requiredAllocation
init|=
literal|1
decl_stmt|;
comment|// if we restore from a repository one copy is more then enough
if|if
condition|(
name|shard
operator|.
name|restoreSource
argument_list|()
operator|==
literal|null
condition|)
block|{
try|try
block|{
name|String
name|initialShards
init|=
name|indexMetaData
operator|.
name|settings
argument_list|()
operator|.
name|get
argument_list|(
name|INDEX_RECOVERY_INITIAL_SHARDS
argument_list|,
name|settings
operator|.
name|get
argument_list|(
name|INDEX_RECOVERY_INITIAL_SHARDS
argument_list|,
name|this
operator|.
name|initialShards
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
literal|"quorum"
operator|.
name|equals
argument_list|(
name|initialShards
argument_list|)
condition|)
block|{
if|if
condition|(
name|indexMetaData
operator|.
name|numberOfReplicas
argument_list|()
operator|>
literal|1
condition|)
block|{
name|requiredAllocation
operator|=
operator|(
operator|(
literal|1
operator|+
name|indexMetaData
operator|.
name|numberOfReplicas
argument_list|()
operator|)
operator|/
literal|2
operator|)
operator|+
literal|1
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
literal|"quorum-1"
operator|.
name|equals
argument_list|(
name|initialShards
argument_list|)
operator|||
literal|"half"
operator|.
name|equals
argument_list|(
name|initialShards
argument_list|)
condition|)
block|{
if|if
condition|(
name|indexMetaData
operator|.
name|numberOfReplicas
argument_list|()
operator|>
literal|2
condition|)
block|{
name|requiredAllocation
operator|=
operator|(
operator|(
literal|1
operator|+
name|indexMetaData
operator|.
name|numberOfReplicas
argument_list|()
operator|)
operator|/
literal|2
operator|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
literal|"one"
operator|.
name|equals
argument_list|(
name|initialShards
argument_list|)
condition|)
block|{
name|requiredAllocation
operator|=
literal|1
expr_stmt|;
block|}
elseif|else
if|if
condition|(
literal|"full"
operator|.
name|equals
argument_list|(
name|initialShards
argument_list|)
operator|||
literal|"all"
operator|.
name|equals
argument_list|(
name|initialShards
argument_list|)
condition|)
block|{
name|requiredAllocation
operator|=
name|indexMetaData
operator|.
name|numberOfReplicas
argument_list|()
operator|+
literal|1
expr_stmt|;
block|}
elseif|else
if|if
condition|(
literal|"full-1"
operator|.
name|equals
argument_list|(
name|initialShards
argument_list|)
operator|||
literal|"all-1"
operator|.
name|equals
argument_list|(
name|initialShards
argument_list|)
condition|)
block|{
if|if
condition|(
name|indexMetaData
operator|.
name|numberOfReplicas
argument_list|()
operator|>
literal|1
condition|)
block|{
name|requiredAllocation
operator|=
name|indexMetaData
operator|.
name|numberOfReplicas
argument_list|()
expr_stmt|;
block|}
block|}
else|else
block|{
name|requiredAllocation
operator|=
name|Integer
operator|.
name|parseInt
argument_list|(
name|initialShards
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|logger
operator|.
name|warn
argument_list|(
literal|"[{}][{}] failed to derived initial_shards from value {}, ignore allocation for {}"
argument_list|,
name|shard
operator|.
name|index
argument_list|()
argument_list|,
name|shard
operator|.
name|id
argument_list|()
argument_list|,
name|initialShards
argument_list|,
name|shard
argument_list|)
expr_stmt|;
block|}
block|}
comment|// not enough found for this shard, continue...
if|if
condition|(
name|numberOfAllocationsFound
operator|<
name|requiredAllocation
condition|)
block|{
comment|// if we are restoring this shard we still can allocate
if|if
condition|(
name|shard
operator|.
name|restoreSource
argument_list|()
operator|==
literal|null
condition|)
block|{
comment|// we can't really allocate, so ignore it and continue
name|unassignedIterator
operator|.
name|remove
argument_list|()
expr_stmt|;
name|routingNodes
operator|.
name|ignoredUnassigned
argument_list|()
operator|.
name|add
argument_list|(
name|shard
argument_list|)
expr_stmt|;
if|if
condition|(
name|logger
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"[{}][{}]: not allocating, number_of_allocated_shards_found [{}], required_number [{}]"
argument_list|,
name|shard
operator|.
name|index
argument_list|()
argument_list|,
name|shard
operator|.
name|id
argument_list|()
argument_list|,
name|numberOfAllocationsFound
argument_list|,
name|requiredAllocation
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|logger
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"[{}][{}]: missing local data, will restore from [{}]"
argument_list|,
name|shard
operator|.
name|index
argument_list|()
argument_list|,
name|shard
operator|.
name|id
argument_list|()
argument_list|,
name|shard
operator|.
name|restoreSource
argument_list|()
argument_list|)
expr_stmt|;
block|}
continue|continue;
block|}
name|Set
argument_list|<
name|DiscoveryNode
argument_list|>
name|throttledNodes
init|=
name|Sets
operator|.
name|newHashSet
argument_list|()
decl_stmt|;
name|Set
argument_list|<
name|DiscoveryNode
argument_list|>
name|noNodes
init|=
name|Sets
operator|.
name|newHashSet
argument_list|()
decl_stmt|;
for|for
control|(
name|DiscoveryNode
name|discoNode
range|:
name|nodesWithHighestVersion
control|)
block|{
name|RoutingNode
name|node
init|=
name|routingNodes
operator|.
name|node
argument_list|(
name|discoNode
operator|.
name|id
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|node
operator|==
literal|null
condition|)
block|{
continue|continue;
block|}
name|Decision
name|decision
init|=
name|allocation
operator|.
name|deciders
argument_list|()
operator|.
name|canAllocate
argument_list|(
name|shard
argument_list|,
name|node
argument_list|,
name|allocation
argument_list|)
decl_stmt|;
if|if
condition|(
name|decision
operator|.
name|type
argument_list|()
operator|==
name|Decision
operator|.
name|Type
operator|.
name|THROTTLE
condition|)
block|{
name|throttledNodes
operator|.
name|add
argument_list|(
name|discoNode
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|decision
operator|.
name|type
argument_list|()
operator|==
name|Decision
operator|.
name|Type
operator|.
name|NO
condition|)
block|{
name|noNodes
operator|.
name|add
argument_list|(
name|discoNode
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|logger
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"[{}][{}]: allocating [{}] to [{}] on primary allocation"
argument_list|,
name|shard
operator|.
name|index
argument_list|()
argument_list|,
name|shard
operator|.
name|id
argument_list|()
argument_list|,
name|shard
argument_list|,
name|discoNode
argument_list|)
expr_stmt|;
block|}
comment|// we found a match
name|changed
operator|=
literal|true
expr_stmt|;
comment|// make sure we create one with the version from the recovered state
name|allocation
operator|.
name|routingNodes
argument_list|()
operator|.
name|assign
argument_list|(
operator|new
name|ShardRouting
argument_list|(
name|shard
argument_list|,
name|highestVersion
argument_list|)
argument_list|,
name|node
operator|.
name|nodeId
argument_list|()
argument_list|)
expr_stmt|;
name|unassignedIterator
operator|.
name|remove
argument_list|()
expr_stmt|;
comment|// found a node, so no throttling, no "no", and break out of the loop
name|throttledNodes
operator|.
name|clear
argument_list|()
expr_stmt|;
name|noNodes
operator|.
name|clear
argument_list|()
expr_stmt|;
break|break;
block|}
block|}
if|if
condition|(
name|throttledNodes
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// if we have a node that we "can't" allocate to, force allocation, since this is our master data!
if|if
condition|(
operator|!
name|noNodes
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|DiscoveryNode
name|discoNode
init|=
name|noNodes
operator|.
name|iterator
argument_list|()
operator|.
name|next
argument_list|()
decl_stmt|;
name|RoutingNode
name|node
init|=
name|routingNodes
operator|.
name|node
argument_list|(
name|discoNode
operator|.
name|id
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|logger
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"[{}][{}]: forcing allocating [{}] to [{}] on primary allocation"
argument_list|,
name|shard
operator|.
name|index
argument_list|()
argument_list|,
name|shard
operator|.
name|id
argument_list|()
argument_list|,
name|shard
argument_list|,
name|discoNode
argument_list|)
expr_stmt|;
block|}
comment|// we found a match
name|changed
operator|=
literal|true
expr_stmt|;
comment|// make sure we create one with the version from the recovered state
name|allocation
operator|.
name|routingNodes
argument_list|()
operator|.
name|assign
argument_list|(
operator|new
name|ShardRouting
argument_list|(
name|shard
argument_list|,
name|highestVersion
argument_list|)
argument_list|,
name|node
operator|.
name|nodeId
argument_list|()
argument_list|)
expr_stmt|;
name|unassignedIterator
operator|.
name|remove
argument_list|()
expr_stmt|;
block|}
block|}
else|else
block|{
if|if
condition|(
name|logger
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"[{}][{}]: throttling allocation [{}] to [{}] on primary allocation"
argument_list|,
name|shard
operator|.
name|index
argument_list|()
argument_list|,
name|shard
operator|.
name|id
argument_list|()
argument_list|,
name|shard
argument_list|,
name|throttledNodes
argument_list|)
expr_stmt|;
block|}
comment|// we are throttling this, but we have enough to allocate to this node, ignore it for now
name|unassignedIterator
operator|.
name|remove
argument_list|()
expr_stmt|;
name|routingNodes
operator|.
name|ignoredUnassigned
argument_list|()
operator|.
name|add
argument_list|(
name|shard
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|!
name|routingNodes
operator|.
name|hasUnassigned
argument_list|()
condition|)
block|{
return|return
name|changed
return|;
block|}
comment|// Now, handle replicas, try to assign them to nodes that are similar to the one the primary was allocated on
name|unassignedIterator
operator|=
name|routingNodes
operator|.
name|unassigned
argument_list|()
operator|.
name|iterator
argument_list|()
expr_stmt|;
while|while
condition|(
name|unassignedIterator
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|ShardRouting
name|shard
init|=
name|unassignedIterator
operator|.
name|next
argument_list|()
decl_stmt|;
if|if
condition|(
name|shard
operator|.
name|primary
argument_list|()
condition|)
block|{
continue|continue;
block|}
comment|// pre-check if it can be allocated to any node that currently exists, so we won't list the store for it for nothing
name|boolean
name|canBeAllocatedToAtLeastOneNode
init|=
literal|false
decl_stmt|;
for|for
control|(
name|ObjectCursor
argument_list|<
name|DiscoveryNode
argument_list|>
name|cursor
range|:
name|nodes
operator|.
name|dataNodes
argument_list|()
operator|.
name|values
argument_list|()
control|)
block|{
name|RoutingNode
name|node
init|=
name|routingNodes
operator|.
name|node
argument_list|(
name|cursor
operator|.
name|value
operator|.
name|id
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|node
operator|==
literal|null
condition|)
block|{
continue|continue;
block|}
comment|// if we can't allocate it on a node, ignore it, for example, this handles
comment|// cases for only allocating a replica after a primary
name|Decision
name|decision
init|=
name|allocation
operator|.
name|deciders
argument_list|()
operator|.
name|canAllocate
argument_list|(
name|shard
argument_list|,
name|node
argument_list|,
name|allocation
argument_list|)
decl_stmt|;
if|if
condition|(
name|decision
operator|.
name|type
argument_list|()
operator|==
name|Decision
operator|.
name|Type
operator|.
name|YES
condition|)
block|{
name|canBeAllocatedToAtLeastOneNode
operator|=
literal|true
expr_stmt|;
break|break;
block|}
block|}
if|if
condition|(
operator|!
name|canBeAllocatedToAtLeastOneNode
condition|)
block|{
name|logger
operator|.
name|trace
argument_list|(
literal|"{}: ignoring allocation, can't be allocated on any node"
argument_list|,
name|shard
argument_list|)
expr_stmt|;
name|unassignedIterator
operator|.
name|remove
argument_list|()
expr_stmt|;
name|routingNodes
operator|.
name|ignoredUnassigned
argument_list|()
operator|.
name|add
argument_list|(
name|shard
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|AsyncShardFetch
argument_list|<
name|TransportNodesListShardStoreMetaData
operator|.
name|NodeStoreFilesMetaData
argument_list|>
name|fetch
init|=
name|asyncFetchStore
operator|.
name|get
argument_list|(
name|shard
operator|.
name|shardId
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|fetch
operator|==
literal|null
condition|)
block|{
name|fetch
operator|=
operator|new
name|InternalAsyncFetch
argument_list|<>
argument_list|(
name|logger
argument_list|,
literal|"shard_store"
argument_list|,
name|shard
operator|.
name|shardId
argument_list|()
argument_list|,
name|storeAction
argument_list|)
expr_stmt|;
name|asyncFetchStore
operator|.
name|put
argument_list|(
name|shard
operator|.
name|shardId
argument_list|()
argument_list|,
name|fetch
argument_list|)
expr_stmt|;
block|}
name|AsyncShardFetch
operator|.
name|FetchResult
argument_list|<
name|TransportNodesListShardStoreMetaData
operator|.
name|NodeStoreFilesMetaData
argument_list|>
name|shardStores
init|=
name|fetch
operator|.
name|fetchData
argument_list|(
name|nodes
argument_list|,
name|metaData
argument_list|,
name|allocation
operator|.
name|getIgnoreNodes
argument_list|(
name|shard
operator|.
name|shardId
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|shardStores
operator|.
name|hasData
argument_list|()
operator|==
literal|false
condition|)
block|{
name|logger
operator|.
name|trace
argument_list|(
literal|"{}: ignoring allocation, still fetching shard stores"
argument_list|,
name|shard
argument_list|)
expr_stmt|;
name|unassignedIterator
operator|.
name|remove
argument_list|()
expr_stmt|;
name|routingNodes
operator|.
name|ignoredUnassigned
argument_list|()
operator|.
name|add
argument_list|(
name|shard
argument_list|)
expr_stmt|;
continue|continue;
comment|// still fetching
block|}
name|shardStores
operator|.
name|processAllocation
argument_list|(
name|allocation
argument_list|)
expr_stmt|;
name|long
name|lastSizeMatched
init|=
literal|0
decl_stmt|;
name|DiscoveryNode
name|lastDiscoNodeMatched
init|=
literal|null
decl_stmt|;
name|RoutingNode
name|lastNodeMatched
init|=
literal|null
decl_stmt|;
name|boolean
name|hasReplicaData
init|=
literal|false
decl_stmt|;
name|IndexMetaData
name|indexMetaData
init|=
name|metaData
operator|.
name|index
argument_list|(
name|shard
operator|.
name|getIndex
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|DiscoveryNode
argument_list|,
name|TransportNodesListShardStoreMetaData
operator|.
name|NodeStoreFilesMetaData
argument_list|>
name|nodeStoreEntry
range|:
name|shardStores
operator|.
name|getData
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|DiscoveryNode
name|discoNode
init|=
name|nodeStoreEntry
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|TransportNodesListShardStoreMetaData
operator|.
name|StoreFilesMetaData
name|storeFilesMetaData
init|=
name|nodeStoreEntry
operator|.
name|getValue
argument_list|()
operator|.
name|storeFilesMetaData
argument_list|()
decl_stmt|;
name|logger
operator|.
name|trace
argument_list|(
literal|"{}: checking node [{}]"
argument_list|,
name|shard
argument_list|,
name|discoNode
argument_list|)
expr_stmt|;
if|if
condition|(
name|storeFilesMetaData
operator|==
literal|null
condition|)
block|{
comment|// already allocated on that node...
continue|continue;
block|}
name|RoutingNode
name|node
init|=
name|routingNodes
operator|.
name|node
argument_list|(
name|discoNode
operator|.
name|id
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|node
operator|==
literal|null
condition|)
block|{
continue|continue;
block|}
comment|// check if we can allocate on that node...
comment|// we only check for NO, since if this node is THROTTLING and it has enough "same data"
comment|// then we will try and assign it next time
name|Decision
name|decision
init|=
name|allocation
operator|.
name|deciders
argument_list|()
operator|.
name|canAllocate
argument_list|(
name|shard
argument_list|,
name|node
argument_list|,
name|allocation
argument_list|)
decl_stmt|;
if|if
condition|(
name|decision
operator|.
name|type
argument_list|()
operator|==
name|Decision
operator|.
name|Type
operator|.
name|NO
condition|)
block|{
continue|continue;
block|}
comment|// if it is already allocated, we can't assign to it...
if|if
condition|(
name|storeFilesMetaData
operator|.
name|allocated
argument_list|()
condition|)
block|{
continue|continue;
block|}
if|if
condition|(
operator|!
name|shard
operator|.
name|primary
argument_list|()
condition|)
block|{
name|hasReplicaData
operator||=
name|storeFilesMetaData
operator|.
name|iterator
argument_list|()
operator|.
name|hasNext
argument_list|()
expr_stmt|;
name|ShardRouting
name|primaryShard
init|=
name|routingNodes
operator|.
name|activePrimary
argument_list|(
name|shard
argument_list|)
decl_stmt|;
if|if
condition|(
name|primaryShard
operator|!=
literal|null
condition|)
block|{
assert|assert
name|primaryShard
operator|.
name|active
argument_list|()
assert|;
name|DiscoveryNode
name|primaryNode
init|=
name|nodes
operator|.
name|get
argument_list|(
name|primaryShard
operator|.
name|currentNodeId
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|primaryNode
operator|!=
literal|null
condition|)
block|{
name|TransportNodesListShardStoreMetaData
operator|.
name|NodeStoreFilesMetaData
name|primaryNodeFilesStore
init|=
name|shardStores
operator|.
name|getData
argument_list|()
operator|.
name|get
argument_list|(
name|primaryNode
argument_list|)
decl_stmt|;
if|if
condition|(
name|primaryNodeFilesStore
operator|!=
literal|null
condition|)
block|{
name|TransportNodesListShardStoreMetaData
operator|.
name|StoreFilesMetaData
name|primaryNodeStore
init|=
name|primaryNodeFilesStore
operator|.
name|storeFilesMetaData
argument_list|()
decl_stmt|;
if|if
condition|(
name|primaryNodeStore
operator|!=
literal|null
operator|&&
name|primaryNodeStore
operator|.
name|allocated
argument_list|()
condition|)
block|{
name|long
name|sizeMatched
init|=
literal|0
decl_stmt|;
name|String
name|primarySyncId
init|=
name|primaryNodeStore
operator|.
name|syncId
argument_list|()
decl_stmt|;
name|String
name|replicaSyncId
init|=
name|storeFilesMetaData
operator|.
name|syncId
argument_list|()
decl_stmt|;
comment|// see if we have a sync id we can make use of
if|if
condition|(
name|replicaSyncId
operator|!=
literal|null
operator|&&
name|replicaSyncId
operator|.
name|equals
argument_list|(
name|primarySyncId
argument_list|)
condition|)
block|{
name|logger
operator|.
name|trace
argument_list|(
literal|"{}: node [{}] has same sync id {} as primary"
argument_list|,
name|shard
argument_list|,
name|discoNode
operator|.
name|name
argument_list|()
argument_list|,
name|replicaSyncId
argument_list|)
expr_stmt|;
name|lastNodeMatched
operator|=
name|node
expr_stmt|;
name|lastSizeMatched
operator|=
name|Long
operator|.
name|MAX_VALUE
expr_stmt|;
name|lastDiscoNodeMatched
operator|=
name|discoNode
expr_stmt|;
block|}
else|else
block|{
for|for
control|(
name|StoreFileMetaData
name|storeFileMetaData
range|:
name|storeFilesMetaData
control|)
block|{
name|String
name|metaDataFileName
init|=
name|storeFileMetaData
operator|.
name|name
argument_list|()
decl_stmt|;
if|if
condition|(
name|primaryNodeStore
operator|.
name|fileExists
argument_list|(
name|metaDataFileName
argument_list|)
operator|&&
name|primaryNodeStore
operator|.
name|file
argument_list|(
name|metaDataFileName
argument_list|)
operator|.
name|isSame
argument_list|(
name|storeFileMetaData
argument_list|)
condition|)
block|{
name|sizeMatched
operator|+=
name|storeFileMetaData
operator|.
name|length
argument_list|()
expr_stmt|;
block|}
block|}
name|logger
operator|.
name|trace
argument_list|(
literal|"{}: node [{}] has [{}/{}] bytes of re-usable data"
argument_list|,
name|shard
argument_list|,
name|discoNode
operator|.
name|name
argument_list|()
argument_list|,
operator|new
name|ByteSizeValue
argument_list|(
name|sizeMatched
argument_list|)
argument_list|,
name|sizeMatched
argument_list|)
expr_stmt|;
if|if
condition|(
name|sizeMatched
operator|>
name|lastSizeMatched
condition|)
block|{
name|lastSizeMatched
operator|=
name|sizeMatched
expr_stmt|;
name|lastDiscoNodeMatched
operator|=
name|discoNode
expr_stmt|;
name|lastNodeMatched
operator|=
name|node
expr_stmt|;
block|}
block|}
block|}
block|}
block|}
block|}
block|}
block|}
if|if
condition|(
name|lastNodeMatched
operator|!=
literal|null
condition|)
block|{
comment|// we only check on THROTTLE since we checked before before on NO
name|Decision
name|decision
init|=
name|allocation
operator|.
name|deciders
argument_list|()
operator|.
name|canAllocate
argument_list|(
name|shard
argument_list|,
name|lastNodeMatched
argument_list|,
name|allocation
argument_list|)
decl_stmt|;
if|if
condition|(
name|decision
operator|.
name|type
argument_list|()
operator|==
name|Decision
operator|.
name|Type
operator|.
name|THROTTLE
condition|)
block|{
if|if
condition|(
name|logger
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"[{}][{}]: throttling allocation [{}] to [{}] in order to reuse its unallocated persistent store with total_size [{}]"
argument_list|,
name|shard
operator|.
name|index
argument_list|()
argument_list|,
name|shard
operator|.
name|id
argument_list|()
argument_list|,
name|shard
argument_list|,
name|lastDiscoNodeMatched
argument_list|,
operator|new
name|ByteSizeValue
argument_list|(
name|lastSizeMatched
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// we are throttling this, but we have enough to allocate to this node, ignore it for now
name|unassignedIterator
operator|.
name|remove
argument_list|()
expr_stmt|;
name|routingNodes
operator|.
name|ignoredUnassigned
argument_list|()
operator|.
name|add
argument_list|(
name|shard
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|logger
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"[{}][{}]: allocating [{}] to [{}] in order to reuse its unallocated persistent store with total_size [{}]"
argument_list|,
name|shard
operator|.
name|index
argument_list|()
argument_list|,
name|shard
operator|.
name|id
argument_list|()
argument_list|,
name|shard
argument_list|,
name|lastDiscoNodeMatched
argument_list|,
operator|new
name|ByteSizeValue
argument_list|(
name|lastSizeMatched
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// we found a match
name|changed
operator|=
literal|true
expr_stmt|;
name|allocation
operator|.
name|routingNodes
argument_list|()
operator|.
name|assign
argument_list|(
name|shard
argument_list|,
name|lastNodeMatched
operator|.
name|nodeId
argument_list|()
argument_list|)
expr_stmt|;
name|unassignedIterator
operator|.
name|remove
argument_list|()
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|hasReplicaData
operator|==
literal|false
condition|)
block|{
comment|// if we didn't manage to find *any* data (regardless of matching sizes), check if the allocation
comment|// of the replica shard needs to be delayed, and if so, add it to the ignore unassigned list
comment|// note: we only care about replica in delayed allocation, since if we have an unassigned primary it
comment|//       will anyhow wait to find an existing copy of the shard to be allocated
comment|// note: the other side of the equation is scheduling a reroute in a timely manner, which happens in the RoutingService
name|long
name|delay
init|=
name|shard
operator|.
name|unassignedInfo
argument_list|()
operator|.
name|getDelayAllocationExpirationIn
argument_list|(
name|settings
argument_list|,
name|indexMetaData
operator|.
name|getSettings
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|delay
operator|>
literal|0
condition|)
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"[{}][{}]: delaying allocation of [{}] for [{}]"
argument_list|,
name|shard
operator|.
name|index
argument_list|()
argument_list|,
name|shard
operator|.
name|id
argument_list|()
argument_list|,
name|shard
argument_list|,
name|TimeValue
operator|.
name|timeValueMillis
argument_list|(
name|delay
argument_list|)
argument_list|)
expr_stmt|;
comment|/**                      * mark it as changed, since we want to kick a publishing to schedule future allocation,                      * see {@link org.elasticsearch.cluster.routing.RoutingService#clusterChanged(ClusterChangedEvent)}).                      */
name|changed
operator|=
literal|true
expr_stmt|;
name|unassignedIterator
operator|.
name|remove
argument_list|()
expr_stmt|;
name|routingNodes
operator|.
name|ignoredUnassigned
argument_list|()
operator|.
name|add
argument_list|(
name|shard
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|changed
return|;
block|}
DECL|class|InternalAsyncFetch
class|class
name|InternalAsyncFetch
parameter_list|<
name|T
extends|extends
name|BaseNodeResponse
parameter_list|>
extends|extends
name|AsyncShardFetch
argument_list|<
name|T
argument_list|>
block|{
DECL|method|InternalAsyncFetch
specifier|public
name|InternalAsyncFetch
parameter_list|(
name|ESLogger
name|logger
parameter_list|,
name|String
name|type
parameter_list|,
name|ShardId
name|shardId
parameter_list|,
name|List
argument_list|<
name|?
extends|extends
name|BaseNodesResponse
argument_list|<
name|T
argument_list|>
argument_list|,
name|T
argument_list|>
name|action
parameter_list|)
block|{
name|super
argument_list|(
name|logger
argument_list|,
name|type
argument_list|,
name|shardId
argument_list|,
name|action
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|reroute
specifier|protected
name|void
name|reroute
parameter_list|(
name|ShardId
name|shardId
parameter_list|,
name|String
name|reason
parameter_list|)
block|{
name|logger
operator|.
name|trace
argument_list|(
literal|"{} scheduling reroute for {}"
argument_list|,
name|shardId
argument_list|,
name|reason
argument_list|)
expr_stmt|;
name|routingService
operator|.
name|reroute
argument_list|(
literal|"async_shard_fetch"
argument_list|)
expr_stmt|;
block|}
block|}
block|}
end_class

end_unit

