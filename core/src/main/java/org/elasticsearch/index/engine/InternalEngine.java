begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to Elasticsearch under one or more contributor  * license agreements. See the NOTICE file distributed with  * this work for additional information regarding copyright  * ownership. Elasticsearch licenses this file to you under  * the Apache License, Version 2.0 (the "License"); you may  * not use this file except in compliance with the License.  * You may obtain a copy of the License at  *  *    http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing,  * software distributed under the License is distributed on an  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY  * KIND, either express or implied.  See the License for the  * specific language governing permissions and limitations  * under the License.  */
end_comment

begin_package
DECL|package|org.elasticsearch.index.engine
package|package
name|org
operator|.
name|elasticsearch
operator|.
name|index
operator|.
name|engine
package|;
end_package

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|logging
operator|.
name|log4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|DirectoryReader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|IndexCommit
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|IndexFormatTooOldException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|IndexReader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|IndexWriter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|IndexWriterConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|LeafReader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|LiveIndexWriterConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|MergePolicy
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|SegmentCommitInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|SegmentInfos
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|index
operator|.
name|Term
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|IndexSearcher
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|SearcherFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|search
operator|.
name|SearcherManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|store
operator|.
name|AlreadyClosedException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|store
operator|.
name|Directory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|store
operator|.
name|LockObtainFailedException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|BytesRef
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|IOUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|InfoStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|ExceptionsHelper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|Version
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|action
operator|.
name|index
operator|.
name|IndexRequest
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|Nullable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|lease
operator|.
name|Releasable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|lucene
operator|.
name|LoggerInfoStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|lucene
operator|.
name|Lucene
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|lucene
operator|.
name|index
operator|.
name|ElasticsearchDirectoryReader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|lucene
operator|.
name|uid
operator|.
name|Versions
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|metrics
operator|.
name|CounterMetric
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|unit
operator|.
name|ByteSizeValue
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|util
operator|.
name|concurrent
operator|.
name|AbstractRunnable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|util
operator|.
name|concurrent
operator|.
name|KeyedLock
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ReleasableLock
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|index
operator|.
name|IndexSettings
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|index
operator|.
name|VersionType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|index
operator|.
name|mapper
operator|.
name|ParseContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|index
operator|.
name|mapper
operator|.
name|Uid
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|index
operator|.
name|merge
operator|.
name|MergeStats
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|index
operator|.
name|merge
operator|.
name|OnGoingMerge
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|index
operator|.
name|shard
operator|.
name|DocsStats
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|index
operator|.
name|shard
operator|.
name|ElasticsearchMergePolicy
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|index
operator|.
name|shard
operator|.
name|ShardId
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|index
operator|.
name|shard
operator|.
name|TranslogRecoveryPerformer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|index
operator|.
name|translog
operator|.
name|Translog
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|index
operator|.
name|translog
operator|.
name|TranslogConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|index
operator|.
name|translog
operator|.
name|TranslogCorruptedException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|threadpool
operator|.
name|ThreadPool
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicBoolean
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicInteger
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicLong
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|locks
operator|.
name|Lock
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|locks
operator|.
name|ReentrantLock
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|function
operator|.
name|Function
import|;
end_import

begin_class
DECL|class|InternalEngine
specifier|public
class|class
name|InternalEngine
extends|extends
name|Engine
block|{
comment|/**      * When we last pruned expired tombstones from versionMap.deletes:      */
DECL|field|lastDeleteVersionPruneTimeMSec
specifier|private
specifier|volatile
name|long
name|lastDeleteVersionPruneTimeMSec
decl_stmt|;
DECL|field|translog
specifier|private
specifier|final
name|Translog
name|translog
decl_stmt|;
DECL|field|mergeScheduler
specifier|private
specifier|final
name|ElasticsearchConcurrentMergeScheduler
name|mergeScheduler
decl_stmt|;
DECL|field|indexWriter
specifier|private
specifier|final
name|IndexWriter
name|indexWriter
decl_stmt|;
DECL|field|searcherFactory
specifier|private
specifier|final
name|SearcherFactory
name|searcherFactory
decl_stmt|;
DECL|field|searcherManager
specifier|private
specifier|final
name|SearcherManager
name|searcherManager
decl_stmt|;
DECL|field|flushLock
specifier|private
specifier|final
name|Lock
name|flushLock
init|=
operator|new
name|ReentrantLock
argument_list|()
decl_stmt|;
DECL|field|optimizeLock
specifier|private
specifier|final
name|ReentrantLock
name|optimizeLock
init|=
operator|new
name|ReentrantLock
argument_list|()
decl_stmt|;
comment|// A uid (in the form of BytesRef) to the version map
comment|// we use the hashed variant since we iterate over it and check removal and additions on existing keys
DECL|field|versionMap
specifier|private
specifier|final
name|LiveVersionMap
name|versionMap
decl_stmt|;
DECL|field|keyedLock
specifier|private
specifier|final
name|KeyedLock
argument_list|<
name|BytesRef
argument_list|>
name|keyedLock
init|=
operator|new
name|KeyedLock
argument_list|<>
argument_list|()
decl_stmt|;
DECL|field|versionMapRefreshPending
specifier|private
specifier|final
name|AtomicBoolean
name|versionMapRefreshPending
init|=
operator|new
name|AtomicBoolean
argument_list|()
decl_stmt|;
DECL|field|lastCommittedSegmentInfos
specifier|private
specifier|volatile
name|SegmentInfos
name|lastCommittedSegmentInfos
decl_stmt|;
DECL|field|throttle
specifier|private
specifier|final
name|IndexThrottle
name|throttle
decl_stmt|;
comment|// How many callers are currently requesting index throttling.  Currently there are only two situations where we do this: when merges
comment|// are falling behind and when writing indexing buffer to disk is too slow.  When this is 0, there is no throttling, else we throttling
comment|// incoming indexing ops to a single thread:
DECL|field|throttleRequestCount
specifier|private
specifier|final
name|AtomicInteger
name|throttleRequestCount
init|=
operator|new
name|AtomicInteger
argument_list|()
decl_stmt|;
DECL|field|openMode
specifier|private
specifier|final
name|EngineConfig
operator|.
name|OpenMode
name|openMode
decl_stmt|;
DECL|field|pendingTranslogRecovery
specifier|private
specifier|final
name|AtomicBoolean
name|pendingTranslogRecovery
init|=
operator|new
name|AtomicBoolean
argument_list|(
literal|false
argument_list|)
decl_stmt|;
DECL|field|maxUnsafeAutoIdTimestamp
specifier|private
specifier|final
name|AtomicLong
name|maxUnsafeAutoIdTimestamp
init|=
operator|new
name|AtomicLong
argument_list|(
operator|-
literal|1
argument_list|)
decl_stmt|;
DECL|field|numVersionLookups
specifier|private
specifier|final
name|CounterMetric
name|numVersionLookups
init|=
operator|new
name|CounterMetric
argument_list|()
decl_stmt|;
DECL|field|numIndexVersionsLookups
specifier|private
specifier|final
name|CounterMetric
name|numIndexVersionsLookups
init|=
operator|new
name|CounterMetric
argument_list|()
decl_stmt|;
DECL|method|InternalEngine
specifier|public
name|InternalEngine
parameter_list|(
name|EngineConfig
name|engineConfig
parameter_list|)
throws|throws
name|EngineException
block|{
name|super
argument_list|(
name|engineConfig
argument_list|)
expr_stmt|;
name|openMode
operator|=
name|engineConfig
operator|.
name|getOpenMode
argument_list|()
expr_stmt|;
if|if
condition|(
name|engineConfig
operator|.
name|getIndexSettings
argument_list|()
operator|.
name|getIndexVersionCreated
argument_list|()
operator|.
name|before
argument_list|(
name|Version
operator|.
name|V_5_0_0_beta1
argument_list|)
condition|)
block|{
comment|// no optimization for pre 5.0.0.alpha6 since translog might not have all information needed
name|maxUnsafeAutoIdTimestamp
operator|.
name|set
argument_list|(
name|Long
operator|.
name|MAX_VALUE
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|maxUnsafeAutoIdTimestamp
operator|.
name|set
argument_list|(
name|engineConfig
operator|.
name|getMaxUnsafeAutoIdTimestamp
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|versionMap
operator|=
operator|new
name|LiveVersionMap
argument_list|()
expr_stmt|;
name|store
operator|.
name|incRef
argument_list|()
expr_stmt|;
name|IndexWriter
name|writer
init|=
literal|null
decl_stmt|;
name|Translog
name|translog
init|=
literal|null
decl_stmt|;
name|SearcherManager
name|manager
init|=
literal|null
decl_stmt|;
name|EngineMergeScheduler
name|scheduler
init|=
literal|null
decl_stmt|;
name|boolean
name|success
init|=
literal|false
decl_stmt|;
try|try
block|{
name|this
operator|.
name|lastDeleteVersionPruneTimeMSec
operator|=
name|engineConfig
operator|.
name|getThreadPool
argument_list|()
operator|.
name|estimatedTimeInMillis
argument_list|()
expr_stmt|;
name|mergeScheduler
operator|=
name|scheduler
operator|=
operator|new
name|EngineMergeScheduler
argument_list|(
name|engineConfig
operator|.
name|getShardId
argument_list|()
argument_list|,
name|engineConfig
operator|.
name|getIndexSettings
argument_list|()
argument_list|)
expr_stmt|;
name|throttle
operator|=
operator|new
name|IndexThrottle
argument_list|()
expr_stmt|;
name|this
operator|.
name|searcherFactory
operator|=
operator|new
name|SearchFactory
argument_list|(
name|logger
argument_list|,
name|isClosed
argument_list|,
name|engineConfig
argument_list|)
expr_stmt|;
try|try
block|{
name|writer
operator|=
name|createWriter
argument_list|(
name|openMode
operator|==
name|EngineConfig
operator|.
name|OpenMode
operator|.
name|CREATE_INDEX_AND_TRANSLOG
argument_list|)
expr_stmt|;
name|indexWriter
operator|=
name|writer
expr_stmt|;
name|translog
operator|=
name|openTranslog
argument_list|(
name|engineConfig
argument_list|,
name|writer
argument_list|)
expr_stmt|;
assert|assert
name|translog
operator|.
name|getGeneration
argument_list|()
operator|!=
literal|null
assert|;
block|}
catch|catch
parameter_list|(
name|IOException
decl||
name|TranslogCorruptedException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|EngineCreationFailureException
argument_list|(
name|shardId
argument_list|,
literal|"failed to create engine"
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|AssertionError
name|e
parameter_list|)
block|{
comment|// IndexWriter throws AssertionError on init, if asserts are enabled, if any files don't exist, but tests that
comment|// randomly throw FNFE/NSFE can also hit this:
if|if
condition|(
name|ExceptionsHelper
operator|.
name|stackTrace
argument_list|(
name|e
argument_list|)
operator|.
name|contains
argument_list|(
literal|"org.apache.lucene.index.IndexWriter.filesExist"
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|EngineCreationFailureException
argument_list|(
name|shardId
argument_list|,
literal|"failed to create engine"
argument_list|,
name|e
argument_list|)
throw|;
block|}
else|else
block|{
throw|throw
name|e
throw|;
block|}
block|}
name|this
operator|.
name|translog
operator|=
name|translog
expr_stmt|;
name|manager
operator|=
name|createSearcherManager
argument_list|()
expr_stmt|;
name|this
operator|.
name|searcherManager
operator|=
name|manager
expr_stmt|;
name|this
operator|.
name|versionMap
operator|.
name|setManager
argument_list|(
name|searcherManager
argument_list|)
expr_stmt|;
assert|assert
name|pendingTranslogRecovery
operator|.
name|get
argument_list|()
operator|==
literal|false
operator|:
literal|"translog recovery can't be pending before we set it"
assert|;
comment|// don't allow commits until we are done with recovering
name|pendingTranslogRecovery
operator|.
name|set
argument_list|(
name|openMode
operator|==
name|EngineConfig
operator|.
name|OpenMode
operator|.
name|OPEN_INDEX_AND_TRANSLOG
argument_list|)
expr_stmt|;
if|if
condition|(
name|engineConfig
operator|.
name|getRefreshListeners
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|searcherManager
operator|.
name|addListener
argument_list|(
name|engineConfig
operator|.
name|getRefreshListeners
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|success
operator|=
literal|true
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
name|success
operator|==
literal|false
condition|)
block|{
name|IOUtils
operator|.
name|closeWhileHandlingException
argument_list|(
name|writer
argument_list|,
name|translog
argument_list|,
name|manager
argument_list|,
name|scheduler
argument_list|)
expr_stmt|;
name|versionMap
operator|.
name|clear
argument_list|()
expr_stmt|;
if|if
condition|(
name|isClosed
operator|.
name|get
argument_list|()
operator|==
literal|false
condition|)
block|{
comment|// failure we need to dec the store reference
name|store
operator|.
name|decRef
argument_list|()
expr_stmt|;
block|}
block|}
block|}
name|logger
operator|.
name|trace
argument_list|(
literal|"created new InternalEngine"
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|recoverFromTranslog
specifier|public
name|InternalEngine
name|recoverFromTranslog
parameter_list|()
throws|throws
name|IOException
block|{
name|flushLock
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
init|(
name|ReleasableLock
name|lock
init|=
name|readLock
operator|.
name|acquire
argument_list|()
init|)
block|{
name|ensureOpen
argument_list|()
expr_stmt|;
if|if
condition|(
name|openMode
operator|!=
name|EngineConfig
operator|.
name|OpenMode
operator|.
name|OPEN_INDEX_AND_TRANSLOG
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"Can't recover from translog with open mode: "
operator|+
name|openMode
argument_list|)
throw|;
block|}
if|if
condition|(
name|pendingTranslogRecovery
operator|.
name|get
argument_list|()
operator|==
literal|false
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"Engine has already been recovered"
argument_list|)
throw|;
block|}
try|try
block|{
name|recoverFromTranslog
argument_list|(
name|engineConfig
operator|.
name|getTranslogRecoveryPerformer
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
try|try
block|{
name|pendingTranslogRecovery
operator|.
name|set
argument_list|(
literal|true
argument_list|)
expr_stmt|;
comment|// just play safe and never allow commits on this see #ensureCanFlush
name|failEngine
argument_list|(
literal|"failed to recover from translog"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|inner
parameter_list|)
block|{
name|e
operator|.
name|addSuppressed
argument_list|(
name|inner
argument_list|)
expr_stmt|;
block|}
throw|throw
name|e
throw|;
block|}
block|}
finally|finally
block|{
name|flushLock
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
return|return
name|this
return|;
block|}
DECL|method|recoverFromTranslog
specifier|private
name|void
name|recoverFromTranslog
parameter_list|(
name|TranslogRecoveryPerformer
name|handler
parameter_list|)
throws|throws
name|IOException
block|{
name|Translog
operator|.
name|TranslogGeneration
name|translogGeneration
init|=
name|translog
operator|.
name|getGeneration
argument_list|()
decl_stmt|;
specifier|final
name|int
name|opsRecovered
decl_stmt|;
try|try
block|{
name|Translog
operator|.
name|Snapshot
name|snapshot
init|=
name|translog
operator|.
name|newSnapshot
argument_list|()
decl_stmt|;
name|opsRecovered
operator|=
name|handler
operator|.
name|recoveryFromSnapshot
argument_list|(
name|this
argument_list|,
name|snapshot
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|EngineException
argument_list|(
name|shardId
argument_list|,
literal|"failed to recover from translog"
argument_list|,
name|e
argument_list|)
throw|;
block|}
comment|// flush if we recovered something or if we have references to older translogs
comment|// note: if opsRecovered == 0 and we have older translogs it means they are corrupted or 0 length.
assert|assert
name|pendingTranslogRecovery
operator|.
name|get
argument_list|()
operator|:
literal|"translogRecovery is not pending but should be"
assert|;
name|pendingTranslogRecovery
operator|.
name|set
argument_list|(
literal|false
argument_list|)
expr_stmt|;
comment|// we are good - now we can commit
if|if
condition|(
name|opsRecovered
operator|>
literal|0
condition|)
block|{
name|logger
operator|.
name|trace
argument_list|(
literal|"flushing post recovery from translog. ops recovered [{}]. committed translog id [{}]. current id [{}]"
argument_list|,
name|opsRecovered
argument_list|,
name|translogGeneration
operator|==
literal|null
condition|?
literal|null
else|:
name|translogGeneration
operator|.
name|translogFileGeneration
argument_list|,
name|translog
operator|.
name|currentFileGeneration
argument_list|()
argument_list|)
expr_stmt|;
name|flush
argument_list|(
literal|true
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|translog
operator|.
name|isCurrent
argument_list|(
name|translogGeneration
argument_list|)
operator|==
literal|false
condition|)
block|{
name|commitIndexWriter
argument_list|(
name|indexWriter
argument_list|,
name|translog
argument_list|,
name|lastCommittedSegmentInfos
operator|.
name|getUserData
argument_list|()
operator|.
name|get
argument_list|(
name|Engine
operator|.
name|SYNC_COMMIT_ID
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|openTranslog
specifier|private
name|Translog
name|openTranslog
parameter_list|(
name|EngineConfig
name|engineConfig
parameter_list|,
name|IndexWriter
name|writer
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|TranslogConfig
name|translogConfig
init|=
name|engineConfig
operator|.
name|getTranslogConfig
argument_list|()
decl_stmt|;
name|Translog
operator|.
name|TranslogGeneration
name|generation
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|openMode
operator|==
name|EngineConfig
operator|.
name|OpenMode
operator|.
name|OPEN_INDEX_AND_TRANSLOG
condition|)
block|{
name|generation
operator|=
name|loadTranslogIdFromCommit
argument_list|(
name|writer
argument_list|)
expr_stmt|;
comment|// We expect that this shard already exists, so it must already have an existing translog else something is badly wrong!
if|if
condition|(
name|generation
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"no translog generation present in commit data but translog is expected to exist"
argument_list|)
throw|;
block|}
if|if
condition|(
name|generation
operator|!=
literal|null
operator|&&
name|generation
operator|.
name|translogUUID
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IndexFormatTooOldException
argument_list|(
literal|"trasnlog"
argument_list|,
literal|"translog has no generation nor a UUID - this might be an index from a previous version consider upgrading to N-1 first"
argument_list|)
throw|;
block|}
block|}
specifier|final
name|Translog
name|translog
init|=
operator|new
name|Translog
argument_list|(
name|translogConfig
argument_list|,
name|generation
argument_list|)
decl_stmt|;
if|if
condition|(
name|generation
operator|==
literal|null
operator|||
name|generation
operator|.
name|translogUUID
operator|==
literal|null
condition|)
block|{
assert|assert
name|openMode
operator|!=
name|EngineConfig
operator|.
name|OpenMode
operator|.
name|OPEN_INDEX_AND_TRANSLOG
operator|:
literal|"OpenMode must not be "
operator|+
name|EngineConfig
operator|.
name|OpenMode
operator|.
name|OPEN_INDEX_AND_TRANSLOG
assert|;
if|if
condition|(
name|generation
operator|==
literal|null
condition|)
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"no translog ID present in the current generation - creating one"
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|generation
operator|.
name|translogUUID
operator|==
literal|null
condition|)
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"upgraded translog to pre 2.0 format, associating translog with index - writing translog UUID"
argument_list|)
expr_stmt|;
block|}
name|boolean
name|success
init|=
literal|false
decl_stmt|;
try|try
block|{
name|commitIndexWriter
argument_list|(
name|writer
argument_list|,
name|translog
argument_list|,
name|openMode
operator|==
name|EngineConfig
operator|.
name|OpenMode
operator|.
name|OPEN_INDEX_CREATE_TRANSLOG
condition|?
name|writer
operator|.
name|getCommitData
argument_list|()
operator|.
name|get
argument_list|(
name|SYNC_COMMIT_ID
argument_list|)
else|:
literal|null
argument_list|)
expr_stmt|;
name|success
operator|=
literal|true
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
name|success
operator|==
literal|false
condition|)
block|{
name|IOUtils
operator|.
name|closeWhileHandlingException
argument_list|(
name|translog
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|translog
return|;
block|}
annotation|@
name|Override
DECL|method|getTranslog
specifier|public
name|Translog
name|getTranslog
parameter_list|()
block|{
name|ensureOpen
argument_list|()
expr_stmt|;
return|return
name|translog
return|;
block|}
comment|/**      * Reads the current stored translog ID from the IW commit data. If the id is not found, recommits the current      * translog id into lucene and returns null.      */
annotation|@
name|Nullable
DECL|method|loadTranslogIdFromCommit
specifier|private
name|Translog
operator|.
name|TranslogGeneration
name|loadTranslogIdFromCommit
parameter_list|(
name|IndexWriter
name|writer
parameter_list|)
throws|throws
name|IOException
block|{
comment|// commit on a just opened writer will commit even if there are no changes done to it
comment|// we rely on that for the commit data translog id key
specifier|final
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|commitUserData
init|=
name|writer
operator|.
name|getCommitData
argument_list|()
decl_stmt|;
if|if
condition|(
name|commitUserData
operator|.
name|containsKey
argument_list|(
literal|"translog_id"
argument_list|)
condition|)
block|{
assert|assert
name|commitUserData
operator|.
name|containsKey
argument_list|(
name|Translog
operator|.
name|TRANSLOG_UUID_KEY
argument_list|)
operator|==
literal|false
operator|:
literal|"legacy commit contains translog UUID"
assert|;
return|return
operator|new
name|Translog
operator|.
name|TranslogGeneration
argument_list|(
literal|null
argument_list|,
name|Long
operator|.
name|parseLong
argument_list|(
name|commitUserData
operator|.
name|get
argument_list|(
literal|"translog_id"
argument_list|)
argument_list|)
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|commitUserData
operator|.
name|containsKey
argument_list|(
name|Translog
operator|.
name|TRANSLOG_GENERATION_KEY
argument_list|)
condition|)
block|{
if|if
condition|(
name|commitUserData
operator|.
name|containsKey
argument_list|(
name|Translog
operator|.
name|TRANSLOG_UUID_KEY
argument_list|)
operator|==
literal|false
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"commit doesn't contain translog UUID"
argument_list|)
throw|;
block|}
specifier|final
name|String
name|translogUUID
init|=
name|commitUserData
operator|.
name|get
argument_list|(
name|Translog
operator|.
name|TRANSLOG_UUID_KEY
argument_list|)
decl_stmt|;
specifier|final
name|long
name|translogGen
init|=
name|Long
operator|.
name|parseLong
argument_list|(
name|commitUserData
operator|.
name|get
argument_list|(
name|Translog
operator|.
name|TRANSLOG_GENERATION_KEY
argument_list|)
argument_list|)
decl_stmt|;
return|return
operator|new
name|Translog
operator|.
name|TranslogGeneration
argument_list|(
name|translogUUID
argument_list|,
name|translogGen
argument_list|)
return|;
block|}
return|return
literal|null
return|;
block|}
DECL|method|createSearcherManager
specifier|private
name|SearcherManager
name|createSearcherManager
parameter_list|()
throws|throws
name|EngineException
block|{
name|boolean
name|success
init|=
literal|false
decl_stmt|;
name|SearcherManager
name|searcherManager
init|=
literal|null
decl_stmt|;
try|try
block|{
try|try
block|{
specifier|final
name|DirectoryReader
name|directoryReader
init|=
name|ElasticsearchDirectoryReader
operator|.
name|wrap
argument_list|(
name|DirectoryReader
operator|.
name|open
argument_list|(
name|indexWriter
argument_list|)
argument_list|,
name|shardId
argument_list|)
decl_stmt|;
name|searcherManager
operator|=
operator|new
name|SearcherManager
argument_list|(
name|directoryReader
argument_list|,
name|searcherFactory
argument_list|)
expr_stmt|;
name|lastCommittedSegmentInfos
operator|=
name|readLastCommittedSegmentInfos
argument_list|(
name|searcherManager
argument_list|,
name|store
argument_list|)
expr_stmt|;
name|success
operator|=
literal|true
expr_stmt|;
return|return
name|searcherManager
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|maybeFailEngine
argument_list|(
literal|"start"
argument_list|,
name|e
argument_list|)
expr_stmt|;
try|try
block|{
name|indexWriter
operator|.
name|rollback
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|inner
parameter_list|)
block|{
comment|// iw is closed below
name|e
operator|.
name|addSuppressed
argument_list|(
name|inner
argument_list|)
expr_stmt|;
block|}
throw|throw
operator|new
name|EngineCreationFailureException
argument_list|(
name|shardId
argument_list|,
literal|"failed to open reader on writer"
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
finally|finally
block|{
if|if
condition|(
name|success
operator|==
literal|false
condition|)
block|{
comment|// release everything we created on a failure
name|IOUtils
operator|.
name|closeWhileHandlingException
argument_list|(
name|searcherManager
argument_list|,
name|indexWriter
argument_list|)
expr_stmt|;
block|}
block|}
block|}
annotation|@
name|Override
DECL|method|get
specifier|public
name|GetResult
name|get
parameter_list|(
name|Get
name|get
parameter_list|,
name|Function
argument_list|<
name|String
argument_list|,
name|Searcher
argument_list|>
name|searcherFactory
parameter_list|)
throws|throws
name|EngineException
block|{
try|try
init|(
name|ReleasableLock
name|lock
init|=
name|readLock
operator|.
name|acquire
argument_list|()
init|)
block|{
name|ensureOpen
argument_list|()
expr_stmt|;
if|if
condition|(
name|get
operator|.
name|realtime
argument_list|()
condition|)
block|{
name|VersionValue
name|versionValue
init|=
name|versionMap
operator|.
name|getUnderLock
argument_list|(
name|get
operator|.
name|uid
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|versionValue
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|versionValue
operator|.
name|delete
argument_list|()
condition|)
block|{
return|return
name|GetResult
operator|.
name|NOT_EXISTS
return|;
block|}
if|if
condition|(
name|get
operator|.
name|versionType
argument_list|()
operator|.
name|isVersionConflictForReads
argument_list|(
name|versionValue
operator|.
name|version
argument_list|()
argument_list|,
name|get
operator|.
name|version
argument_list|()
argument_list|)
condition|)
block|{
name|Uid
name|uid
init|=
name|Uid
operator|.
name|createUid
argument_list|(
name|get
operator|.
name|uid
argument_list|()
operator|.
name|text
argument_list|()
argument_list|)
decl_stmt|;
throw|throw
operator|new
name|VersionConflictEngineException
argument_list|(
name|shardId
argument_list|,
name|uid
operator|.
name|type
argument_list|()
argument_list|,
name|uid
operator|.
name|id
argument_list|()
argument_list|,
name|get
operator|.
name|versionType
argument_list|()
operator|.
name|explainConflictForReads
argument_list|(
name|versionValue
operator|.
name|version
argument_list|()
argument_list|,
name|get
operator|.
name|version
argument_list|()
argument_list|)
argument_list|)
throw|;
block|}
name|refresh
argument_list|(
literal|"realtime_get"
argument_list|)
expr_stmt|;
block|}
block|}
comment|// no version, get the version from the index, we know that we refresh on flush
return|return
name|getFromSearcher
argument_list|(
name|get
argument_list|,
name|searcherFactory
argument_list|)
return|;
block|}
block|}
DECL|method|checkVersionConflict
specifier|private
name|boolean
name|checkVersionConflict
parameter_list|(
specifier|final
name|Operation
name|op
parameter_list|,
specifier|final
name|long
name|currentVersion
parameter_list|,
specifier|final
name|long
name|expectedVersion
parameter_list|,
specifier|final
name|boolean
name|deleted
parameter_list|)
block|{
if|if
condition|(
name|op
operator|.
name|versionType
argument_list|()
operator|==
name|VersionType
operator|.
name|FORCE
condition|)
block|{
if|if
condition|(
name|engineConfig
operator|.
name|getIndexSettings
argument_list|()
operator|.
name|getIndexVersionCreated
argument_list|()
operator|.
name|onOrAfter
argument_list|(
name|Version
operator|.
name|V_6_0_0_alpha1
argument_list|)
condition|)
block|{
comment|// If index was created in 5.0 or later, 'force' is not allowed at all
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"version type [FORCE] may not be used for indices created after 6.0"
argument_list|)
throw|;
block|}
elseif|else
if|if
condition|(
name|op
operator|.
name|origin
argument_list|()
operator|!=
name|Operation
operator|.
name|Origin
operator|.
name|LOCAL_TRANSLOG_RECOVERY
condition|)
block|{
comment|// For earlier indices, 'force' is only allowed for translog recovery
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"version type [FORCE] may not be used for non-translog operations"
argument_list|)
throw|;
block|}
block|}
if|if
condition|(
name|op
operator|.
name|versionType
argument_list|()
operator|.
name|isVersionConflictForWrites
argument_list|(
name|currentVersion
argument_list|,
name|expectedVersion
argument_list|,
name|deleted
argument_list|)
condition|)
block|{
if|if
condition|(
name|op
operator|.
name|origin
argument_list|()
operator|.
name|isRecovery
argument_list|()
condition|)
block|{
comment|// version conflict, but okay
return|return
literal|true
return|;
block|}
else|else
block|{
comment|// fatal version conflict
throw|throw
operator|new
name|VersionConflictEngineException
argument_list|(
name|shardId
argument_list|,
name|op
operator|.
name|type
argument_list|()
argument_list|,
name|op
operator|.
name|id
argument_list|()
argument_list|,
name|op
operator|.
name|versionType
argument_list|()
operator|.
name|explainConflictForWrites
argument_list|(
name|currentVersion
argument_list|,
name|expectedVersion
argument_list|,
name|deleted
argument_list|)
argument_list|)
throw|;
block|}
block|}
return|return
literal|false
return|;
block|}
DECL|method|checkDeletedAndGCed
specifier|private
name|long
name|checkDeletedAndGCed
parameter_list|(
name|VersionValue
name|versionValue
parameter_list|)
block|{
name|long
name|currentVersion
decl_stmt|;
if|if
condition|(
name|engineConfig
operator|.
name|isEnableGcDeletes
argument_list|()
operator|&&
name|versionValue
operator|.
name|delete
argument_list|()
operator|&&
operator|(
name|engineConfig
operator|.
name|getThreadPool
argument_list|()
operator|.
name|estimatedTimeInMillis
argument_list|()
operator|-
name|versionValue
operator|.
name|time
argument_list|()
operator|)
operator|>
name|getGcDeletesInMillis
argument_list|()
condition|)
block|{
name|currentVersion
operator|=
name|Versions
operator|.
name|NOT_FOUND
expr_stmt|;
comment|// deleted, and GC
block|}
else|else
block|{
name|currentVersion
operator|=
name|versionValue
operator|.
name|version
argument_list|()
expr_stmt|;
block|}
return|return
name|currentVersion
return|;
block|}
annotation|@
name|Override
DECL|method|index
specifier|public
name|IndexResult
name|index
parameter_list|(
name|Index
name|index
parameter_list|)
block|{
name|IndexResult
name|result
decl_stmt|;
try|try
init|(
name|ReleasableLock
name|lock
init|=
name|readLock
operator|.
name|acquire
argument_list|()
init|)
block|{
name|ensureOpen
argument_list|()
expr_stmt|;
if|if
condition|(
name|index
operator|.
name|origin
argument_list|()
operator|.
name|isRecovery
argument_list|()
condition|)
block|{
comment|// Don't throttle recovery operations
name|result
operator|=
name|innerIndex
argument_list|(
name|index
argument_list|)
expr_stmt|;
block|}
else|else
block|{
try|try
init|(
name|Releasable
name|r
init|=
name|throttle
operator|.
name|acquireThrottle
argument_list|()
init|)
block|{
name|result
operator|=
name|innerIndex
argument_list|(
name|index
argument_list|)
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|Exception
name|documentFailure
init|=
name|extractDocumentFailure
argument_list|(
name|index
argument_list|,
name|e
argument_list|)
decl_stmt|;
name|result
operator|=
operator|new
name|IndexResult
argument_list|(
name|documentFailure
argument_list|,
name|index
operator|.
name|version
argument_list|()
argument_list|,
name|index
operator|.
name|estimatedSizeInBytes
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
comment|/**      * Inspects exception thrown when executing index or delete operations      *      * @return failure if the failure is a document specific failure (e.g. analysis chain failure)      * @throws OperationFailedEngineException if the failure caused the engine to fail      * (e.g. out of disk, lucene tragic event)      */
DECL|method|extractDocumentFailure
specifier|private
name|Exception
name|extractDocumentFailure
parameter_list|(
specifier|final
name|Operation
name|operation
parameter_list|,
specifier|final
name|Exception
name|failure
parameter_list|)
block|{
name|boolean
name|isDocumentFailure
decl_stmt|;
try|try
block|{
comment|// When indexing a document into Lucene, Lucene distinguishes between environment related errors
comment|// (like out of disk space) and document specific errors (like analysis chain problems) by setting
comment|// the IndexWriter.getTragicEvent() value for the former. maybeFailEngine checks for these kind of
comment|// errors and returns true if that is the case. We use that to indicate a document level failure
comment|// and set the error in operation.setFailure. In case of environment related errors, the failure
comment|// is bubbled up
name|isDocumentFailure
operator|=
operator|!
operator|(
operator|(
name|failure
operator|instanceof
name|IllegalStateException
operator|||
name|failure
operator|instanceof
name|IOException
operator|)
operator|&&
name|maybeFailEngine
argument_list|(
name|operation
operator|.
name|operationType
argument_list|()
operator|.
name|getLowercase
argument_list|()
argument_list|,
name|failure
argument_list|)
operator|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|inner
parameter_list|)
block|{
comment|// we failed checking whether the failure can fail the engine, treat it as a persistent engine failure
name|isDocumentFailure
operator|=
literal|false
expr_stmt|;
name|failure
operator|.
name|addSuppressed
argument_list|(
name|inner
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|isDocumentFailure
condition|)
block|{
return|return
name|failure
return|;
block|}
else|else
block|{
throw|throw
operator|new
name|OperationFailedEngineException
argument_list|(
name|shardId
argument_list|,
name|operation
operator|.
name|operationType
argument_list|()
operator|.
name|getLowercase
argument_list|()
argument_list|,
name|operation
operator|.
name|type
argument_list|()
argument_list|,
name|operation
operator|.
name|id
argument_list|()
argument_list|,
name|failure
argument_list|)
throw|;
block|}
block|}
DECL|method|canOptimizeAddDocument
specifier|private
name|boolean
name|canOptimizeAddDocument
parameter_list|(
name|Index
name|index
parameter_list|)
block|{
if|if
condition|(
name|index
operator|.
name|getAutoGeneratedIdTimestamp
argument_list|()
operator|!=
name|IndexRequest
operator|.
name|UNSET_AUTO_GENERATED_TIMESTAMP
condition|)
block|{
assert|assert
name|index
operator|.
name|getAutoGeneratedIdTimestamp
argument_list|()
operator|>=
literal|0
operator|:
literal|"autoGeneratedIdTimestamp must be positive but was: "
operator|+
name|index
operator|.
name|getAutoGeneratedIdTimestamp
argument_list|()
assert|;
switch|switch
condition|(
name|index
operator|.
name|origin
argument_list|()
condition|)
block|{
case|case
name|PRIMARY
case|:
assert|assert
operator|(
name|index
operator|.
name|version
argument_list|()
operator|==
name|Versions
operator|.
name|MATCH_ANY
operator|&&
name|index
operator|.
name|versionType
argument_list|()
operator|==
name|VersionType
operator|.
name|INTERNAL
operator|)
operator|:
literal|"version: "
operator|+
name|index
operator|.
name|version
argument_list|()
operator|+
literal|" type: "
operator|+
name|index
operator|.
name|versionType
argument_list|()
assert|;
return|return
literal|true
return|;
case|case
name|PEER_RECOVERY
case|:
case|case
name|REPLICA
case|:
assert|assert
name|index
operator|.
name|version
argument_list|()
operator|==
literal|1
operator|&&
name|index
operator|.
name|versionType
argument_list|()
operator|==
name|VersionType
operator|.
name|EXTERNAL
operator|:
literal|"version: "
operator|+
name|index
operator|.
name|version
argument_list|()
operator|+
literal|" type: "
operator|+
name|index
operator|.
name|versionType
argument_list|()
assert|;
return|return
literal|true
return|;
case|case
name|LOCAL_TRANSLOG_RECOVERY
case|:
assert|assert
name|index
operator|.
name|isRetry
argument_list|()
assert|;
return|return
literal|false
return|;
comment|// even if retry is set we never optimize local recovery
default|default:
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"unknown origin "
operator|+
name|index
operator|.
name|origin
argument_list|()
argument_list|)
throw|;
block|}
block|}
return|return
literal|false
return|;
block|}
DECL|method|innerIndex
specifier|private
name|IndexResult
name|innerIndex
parameter_list|(
name|Index
name|index
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|Translog
operator|.
name|Location
name|location
decl_stmt|;
specifier|final
name|long
name|updatedVersion
decl_stmt|;
try|try
init|(
name|Releasable
name|ignored
init|=
name|acquireLock
argument_list|(
name|index
operator|.
name|uid
argument_list|()
argument_list|)
init|)
block|{
name|lastWriteNanos
operator|=
name|index
operator|.
name|startTime
argument_list|()
expr_stmt|;
comment|/* if we have an autoGeneratedID that comes into the engine we can potentially optimize              * and just use addDocument instead of updateDocument and skip the entire version and index lookup across the board.              * Yet, we have to deal with multiple document delivery, for this we use a property of the document that is added              * to detect if it has potentially been added before. We use the documents timestamp for this since it's something              * that:              *  - doesn't change per document              *  - is preserved in the transaction log              *  - and is assigned before we start to index / replicate              * NOTE: it's not important for this timestamp to be consistent across nodes etc. it's just a number that is in the common              * case increasing and can be used in the failure case when we retry and resent documents to establish a happens before relationship.              * for instance:              *  - doc A has autoGeneratedIdTimestamp = 10, isRetry = false              *  - doc B has autoGeneratedIdTimestamp = 9, isRetry = false              *              *  while both docs are in in flight, we disconnect on one node, reconnect and send doc A again              *  - now doc A' has autoGeneratedIdTimestamp = 10, isRetry = true              *              *  if A' arrives on the shard first we update maxUnsafeAutoIdTimestamp to 10 and use update document. All subsequent              *  documents that arrive (A and B) will also use updateDocument since their timestamps are less than maxUnsafeAutoIdTimestamp.              *  While this is not strictly needed for doc B it is just much simpler to implement since it will just de-optimize some doc in the worst case.              *              *  if A arrives on the shard first we use addDocument since maxUnsafeAutoIdTimestamp is< 10. A` will then just be skipped or calls              *  updateDocument.              */
name|long
name|currentVersion
decl_stmt|;
specifier|final
name|boolean
name|deleted
decl_stmt|;
comment|// if anything is fishy here ie. there is a retry we go and force updateDocument below so we are updating the document in the
comment|// lucene index without checking the version map but we still do the version check
specifier|final
name|boolean
name|forceUpdateDocument
decl_stmt|;
if|if
condition|(
name|canOptimizeAddDocument
argument_list|(
name|index
argument_list|)
condition|)
block|{
name|long
name|deOptimizeTimestamp
init|=
name|maxUnsafeAutoIdTimestamp
operator|.
name|get
argument_list|()
decl_stmt|;
if|if
condition|(
name|index
operator|.
name|isRetry
argument_list|()
condition|)
block|{
name|forceUpdateDocument
operator|=
literal|true
expr_stmt|;
do|do
block|{
name|deOptimizeTimestamp
operator|=
name|maxUnsafeAutoIdTimestamp
operator|.
name|get
argument_list|()
expr_stmt|;
if|if
condition|(
name|deOptimizeTimestamp
operator|>=
name|index
operator|.
name|getAutoGeneratedIdTimestamp
argument_list|()
condition|)
block|{
break|break;
block|}
block|}
do|while
condition|(
name|maxUnsafeAutoIdTimestamp
operator|.
name|compareAndSet
argument_list|(
name|deOptimizeTimestamp
argument_list|,
name|index
operator|.
name|getAutoGeneratedIdTimestamp
argument_list|()
argument_list|)
operator|==
literal|false
condition|)
do|;
assert|assert
name|maxUnsafeAutoIdTimestamp
operator|.
name|get
argument_list|()
operator|>=
name|index
operator|.
name|getAutoGeneratedIdTimestamp
argument_list|()
assert|;
block|}
else|else
block|{
comment|// in this case we force
name|forceUpdateDocument
operator|=
name|deOptimizeTimestamp
operator|>=
name|index
operator|.
name|getAutoGeneratedIdTimestamp
argument_list|()
expr_stmt|;
block|}
name|currentVersion
operator|=
name|Versions
operator|.
name|NOT_FOUND
expr_stmt|;
name|deleted
operator|=
literal|true
expr_stmt|;
block|}
else|else
block|{
comment|// update the document
name|forceUpdateDocument
operator|=
literal|false
expr_stmt|;
comment|// we don't force it - it depends on the version
specifier|final
name|VersionValue
name|versionValue
init|=
name|versionMap
operator|.
name|getUnderLock
argument_list|(
name|index
operator|.
name|uid
argument_list|()
argument_list|)
decl_stmt|;
assert|assert
name|incrementVersionLookup
argument_list|()
assert|;
if|if
condition|(
name|versionValue
operator|==
literal|null
condition|)
block|{
name|currentVersion
operator|=
name|loadCurrentVersionFromIndex
argument_list|(
name|index
operator|.
name|uid
argument_list|()
argument_list|)
expr_stmt|;
name|deleted
operator|=
name|currentVersion
operator|==
name|Versions
operator|.
name|NOT_FOUND
expr_stmt|;
block|}
else|else
block|{
name|currentVersion
operator|=
name|checkDeletedAndGCed
argument_list|(
name|versionValue
argument_list|)
expr_stmt|;
name|deleted
operator|=
name|versionValue
operator|.
name|delete
argument_list|()
expr_stmt|;
block|}
block|}
specifier|final
name|long
name|expectedVersion
init|=
name|index
operator|.
name|version
argument_list|()
decl_stmt|;
if|if
condition|(
name|checkVersionConflict
argument_list|(
name|index
argument_list|,
name|currentVersion
argument_list|,
name|expectedVersion
argument_list|,
name|deleted
argument_list|)
condition|)
block|{
comment|// skip index operation because of version conflict on recovery
return|return
operator|new
name|IndexResult
argument_list|(
name|expectedVersion
argument_list|,
literal|false
argument_list|,
name|index
operator|.
name|estimatedSizeInBytes
argument_list|()
argument_list|)
return|;
block|}
else|else
block|{
name|updatedVersion
operator|=
name|index
operator|.
name|versionType
argument_list|()
operator|.
name|updateVersion
argument_list|(
name|currentVersion
argument_list|,
name|expectedVersion
argument_list|)
expr_stmt|;
name|index
operator|.
name|parsedDoc
argument_list|()
operator|.
name|version
argument_list|()
operator|.
name|setLongValue
argument_list|(
name|updatedVersion
argument_list|)
expr_stmt|;
if|if
condition|(
name|currentVersion
operator|==
name|Versions
operator|.
name|NOT_FOUND
operator|&&
name|forceUpdateDocument
operator|==
literal|false
condition|)
block|{
comment|// document does not exists, we can optimize for create
name|index
argument_list|(
name|index
operator|.
name|docs
argument_list|()
argument_list|,
name|indexWriter
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|update
argument_list|(
name|index
operator|.
name|uid
argument_list|()
argument_list|,
name|index
operator|.
name|docs
argument_list|()
argument_list|,
name|indexWriter
argument_list|)
expr_stmt|;
block|}
name|IndexResult
name|indexResult
init|=
operator|new
name|IndexResult
argument_list|(
name|updatedVersion
argument_list|,
name|deleted
argument_list|,
name|index
operator|.
name|estimatedSizeInBytes
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|index
operator|.
name|origin
argument_list|()
operator|!=
name|Operation
operator|.
name|Origin
operator|.
name|LOCAL_TRANSLOG_RECOVERY
condition|)
block|{
name|location
operator|=
name|translog
operator|.
name|add
argument_list|(
operator|new
name|Translog
operator|.
name|Index
argument_list|(
name|index
argument_list|,
name|indexResult
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|location
operator|=
literal|null
expr_stmt|;
block|}
name|versionMap
operator|.
name|putUnderLock
argument_list|(
name|index
operator|.
name|uid
argument_list|()
operator|.
name|bytes
argument_list|()
argument_list|,
operator|new
name|VersionValue
argument_list|(
name|updatedVersion
argument_list|)
argument_list|)
expr_stmt|;
name|indexResult
operator|.
name|setLocation
argument_list|(
name|location
argument_list|)
expr_stmt|;
name|indexResult
operator|.
name|setTook
argument_list|(
name|System
operator|.
name|nanoTime
argument_list|()
operator|-
name|index
operator|.
name|startTime
argument_list|()
argument_list|)
expr_stmt|;
name|indexResult
operator|.
name|freeze
argument_list|()
expr_stmt|;
return|return
name|indexResult
return|;
block|}
block|}
block|}
DECL|method|index
specifier|private
specifier|static
name|void
name|index
parameter_list|(
specifier|final
name|List
argument_list|<
name|ParseContext
operator|.
name|Document
argument_list|>
name|docs
parameter_list|,
specifier|final
name|IndexWriter
name|indexWriter
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|docs
operator|.
name|size
argument_list|()
operator|>
literal|1
condition|)
block|{
name|indexWriter
operator|.
name|addDocuments
argument_list|(
name|docs
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|indexWriter
operator|.
name|addDocument
argument_list|(
name|docs
operator|.
name|get
argument_list|(
literal|0
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|update
specifier|private
specifier|static
name|void
name|update
parameter_list|(
specifier|final
name|Term
name|uid
parameter_list|,
specifier|final
name|List
argument_list|<
name|ParseContext
operator|.
name|Document
argument_list|>
name|docs
parameter_list|,
specifier|final
name|IndexWriter
name|indexWriter
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|docs
operator|.
name|size
argument_list|()
operator|>
literal|1
condition|)
block|{
name|indexWriter
operator|.
name|updateDocuments
argument_list|(
name|uid
argument_list|,
name|docs
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|indexWriter
operator|.
name|updateDocument
argument_list|(
name|uid
argument_list|,
name|docs
operator|.
name|get
argument_list|(
literal|0
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Override
DECL|method|delete
specifier|public
name|DeleteResult
name|delete
parameter_list|(
name|Delete
name|delete
parameter_list|)
block|{
name|DeleteResult
name|result
decl_stmt|;
try|try
init|(
name|ReleasableLock
name|lock
init|=
name|readLock
operator|.
name|acquire
argument_list|()
init|)
block|{
name|ensureOpen
argument_list|()
expr_stmt|;
comment|// NOTE: we don't throttle this when merges fall behind because delete-by-id does not create new segments:
name|result
operator|=
name|innerDelete
argument_list|(
name|delete
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|Exception
name|documentFailure
init|=
name|extractDocumentFailure
argument_list|(
name|delete
argument_list|,
name|e
argument_list|)
decl_stmt|;
name|result
operator|=
operator|new
name|DeleteResult
argument_list|(
name|documentFailure
argument_list|,
name|delete
operator|.
name|version
argument_list|()
argument_list|,
name|delete
operator|.
name|estimatedSizeInBytes
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|maybePruneDeletedTombstones
argument_list|()
expr_stmt|;
return|return
name|result
return|;
block|}
DECL|method|maybePruneDeletedTombstones
specifier|private
name|void
name|maybePruneDeletedTombstones
parameter_list|()
block|{
comment|// It's expensive to prune because we walk the deletes map acquiring dirtyLock for each uid so we only do it
comment|// every 1/4 of gcDeletesInMillis:
if|if
condition|(
name|engineConfig
operator|.
name|isEnableGcDeletes
argument_list|()
operator|&&
name|engineConfig
operator|.
name|getThreadPool
argument_list|()
operator|.
name|estimatedTimeInMillis
argument_list|()
operator|-
name|lastDeleteVersionPruneTimeMSec
operator|>
name|getGcDeletesInMillis
argument_list|()
operator|*
literal|0.25
condition|)
block|{
name|pruneDeletedTombstones
argument_list|()
expr_stmt|;
block|}
block|}
DECL|method|innerDelete
specifier|private
name|DeleteResult
name|innerDelete
parameter_list|(
name|Delete
name|delete
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|Translog
operator|.
name|Location
name|location
decl_stmt|;
specifier|final
name|long
name|updatedVersion
decl_stmt|;
specifier|final
name|boolean
name|found
decl_stmt|;
try|try
init|(
name|Releasable
name|ignored
init|=
name|acquireLock
argument_list|(
name|delete
operator|.
name|uid
argument_list|()
argument_list|)
init|)
block|{
name|lastWriteNanos
operator|=
name|delete
operator|.
name|startTime
argument_list|()
expr_stmt|;
specifier|final
name|long
name|currentVersion
decl_stmt|;
specifier|final
name|boolean
name|deleted
decl_stmt|;
specifier|final
name|VersionValue
name|versionValue
init|=
name|versionMap
operator|.
name|getUnderLock
argument_list|(
name|delete
operator|.
name|uid
argument_list|()
argument_list|)
decl_stmt|;
assert|assert
name|incrementVersionLookup
argument_list|()
assert|;
if|if
condition|(
name|versionValue
operator|==
literal|null
condition|)
block|{
name|currentVersion
operator|=
name|loadCurrentVersionFromIndex
argument_list|(
name|delete
operator|.
name|uid
argument_list|()
argument_list|)
expr_stmt|;
name|deleted
operator|=
name|currentVersion
operator|==
name|Versions
operator|.
name|NOT_FOUND
expr_stmt|;
block|}
else|else
block|{
name|currentVersion
operator|=
name|checkDeletedAndGCed
argument_list|(
name|versionValue
argument_list|)
expr_stmt|;
name|deleted
operator|=
name|versionValue
operator|.
name|delete
argument_list|()
expr_stmt|;
block|}
specifier|final
name|long
name|expectedVersion
init|=
name|delete
operator|.
name|version
argument_list|()
decl_stmt|;
if|if
condition|(
name|checkVersionConflict
argument_list|(
name|delete
argument_list|,
name|currentVersion
argument_list|,
name|expectedVersion
argument_list|,
name|deleted
argument_list|)
condition|)
block|{
comment|// skip executing delete because of version conflict on recovery
return|return
operator|new
name|DeleteResult
argument_list|(
name|expectedVersion
argument_list|,
literal|true
argument_list|,
name|delete
operator|.
name|estimatedSizeInBytes
argument_list|()
argument_list|)
return|;
block|}
else|else
block|{
name|updatedVersion
operator|=
name|delete
operator|.
name|versionType
argument_list|()
operator|.
name|updateVersion
argument_list|(
name|currentVersion
argument_list|,
name|expectedVersion
argument_list|)
expr_stmt|;
name|found
operator|=
name|deleteIfFound
argument_list|(
name|delete
operator|.
name|uid
argument_list|()
argument_list|,
name|currentVersion
argument_list|,
name|deleted
argument_list|,
name|versionValue
argument_list|)
expr_stmt|;
name|DeleteResult
name|deleteResult
init|=
operator|new
name|DeleteResult
argument_list|(
name|updatedVersion
argument_list|,
name|found
argument_list|,
name|delete
operator|.
name|estimatedSizeInBytes
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|delete
operator|.
name|origin
argument_list|()
operator|!=
name|Operation
operator|.
name|Origin
operator|.
name|LOCAL_TRANSLOG_RECOVERY
condition|)
block|{
name|location
operator|=
name|translog
operator|.
name|add
argument_list|(
operator|new
name|Translog
operator|.
name|Delete
argument_list|(
name|delete
argument_list|,
name|deleteResult
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|location
operator|=
literal|null
expr_stmt|;
block|}
name|versionMap
operator|.
name|putUnderLock
argument_list|(
name|delete
operator|.
name|uid
argument_list|()
operator|.
name|bytes
argument_list|()
argument_list|,
operator|new
name|DeleteVersionValue
argument_list|(
name|updatedVersion
argument_list|,
name|engineConfig
operator|.
name|getThreadPool
argument_list|()
operator|.
name|estimatedTimeInMillis
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|deleteResult
operator|.
name|setLocation
argument_list|(
name|location
argument_list|)
expr_stmt|;
name|deleteResult
operator|.
name|setTook
argument_list|(
name|System
operator|.
name|nanoTime
argument_list|()
operator|-
name|delete
operator|.
name|startTime
argument_list|()
argument_list|)
expr_stmt|;
name|deleteResult
operator|.
name|freeze
argument_list|()
expr_stmt|;
return|return
name|deleteResult
return|;
block|}
block|}
block|}
DECL|method|deleteIfFound
specifier|private
name|boolean
name|deleteIfFound
parameter_list|(
name|Term
name|uid
parameter_list|,
name|long
name|currentVersion
parameter_list|,
name|boolean
name|deleted
parameter_list|,
name|VersionValue
name|versionValue
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|boolean
name|found
decl_stmt|;
if|if
condition|(
name|currentVersion
operator|==
name|Versions
operator|.
name|NOT_FOUND
condition|)
block|{
comment|// doc does not exist and no prior deletes
name|found
operator|=
literal|false
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|versionValue
operator|!=
literal|null
operator|&&
name|deleted
condition|)
block|{
comment|// a "delete on delete", in this case, we still increment the version, log it, and return that version
name|found
operator|=
literal|false
expr_stmt|;
block|}
else|else
block|{
comment|// we deleted a currently existing document
name|indexWriter
operator|.
name|deleteDocuments
argument_list|(
name|uid
argument_list|)
expr_stmt|;
name|found
operator|=
literal|true
expr_stmt|;
block|}
return|return
name|found
return|;
block|}
annotation|@
name|Override
DECL|method|refresh
specifier|public
name|void
name|refresh
parameter_list|(
name|String
name|source
parameter_list|)
throws|throws
name|EngineException
block|{
comment|// we obtain a read lock here, since we don't want a flush to happen while we are refreshing
comment|// since it flushes the index as well (though, in terms of concurrency, we are allowed to do it)
try|try
init|(
name|ReleasableLock
name|lock
init|=
name|readLock
operator|.
name|acquire
argument_list|()
init|)
block|{
name|ensureOpen
argument_list|()
expr_stmt|;
name|searcherManager
operator|.
name|maybeRefreshBlocking
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|AlreadyClosedException
name|e
parameter_list|)
block|{
name|failOnTragicEvent
argument_list|(
name|e
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
catch|catch
parameter_list|(
name|EngineClosedException
name|e
parameter_list|)
block|{
throw|throw
name|e
throw|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
try|try
block|{
name|failEngine
argument_list|(
literal|"refresh failed"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|inner
parameter_list|)
block|{
name|e
operator|.
name|addSuppressed
argument_list|(
name|inner
argument_list|)
expr_stmt|;
block|}
throw|throw
operator|new
name|RefreshFailedEngineException
argument_list|(
name|shardId
argument_list|,
name|e
argument_list|)
throw|;
block|}
comment|// TODO: maybe we should just put a scheduled job in threadPool?
comment|// We check for pruning in each delete request, but we also prune here e.g. in case a delete burst comes in and then no more deletes
comment|// for a long time:
name|maybePruneDeletedTombstones
argument_list|()
expr_stmt|;
name|versionMapRefreshPending
operator|.
name|set
argument_list|(
literal|false
argument_list|)
expr_stmt|;
name|mergeScheduler
operator|.
name|refreshConfig
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|writeIndexingBuffer
specifier|public
name|void
name|writeIndexingBuffer
parameter_list|()
throws|throws
name|EngineException
block|{
comment|// we obtain a read lock here, since we don't want a flush to happen while we are writing
comment|// since it flushes the index as well (though, in terms of concurrency, we are allowed to do it)
try|try
init|(
name|ReleasableLock
name|lock
init|=
name|readLock
operator|.
name|acquire
argument_list|()
init|)
block|{
name|ensureOpen
argument_list|()
expr_stmt|;
comment|// TODO: it's not great that we secretly tie searcher visibility to "freeing up heap" here... really we should keep two
comment|// searcher managers, one for searching which is only refreshed by the schedule the user requested (refresh_interval, or invoking
comment|// refresh API), and another for version map interactions.  See #15768.
specifier|final
name|long
name|versionMapBytes
init|=
name|versionMap
operator|.
name|ramBytesUsedForRefresh
argument_list|()
decl_stmt|;
specifier|final
name|long
name|indexingBufferBytes
init|=
name|indexWriter
operator|.
name|ramBytesUsed
argument_list|()
decl_stmt|;
specifier|final
name|boolean
name|useRefresh
init|=
name|versionMapRefreshPending
operator|.
name|get
argument_list|()
operator|||
operator|(
name|indexingBufferBytes
operator|/
literal|4
operator|<
name|versionMapBytes
operator|)
decl_stmt|;
if|if
condition|(
name|useRefresh
condition|)
block|{
comment|// The version map is using> 25% of the indexing buffer, so we do a refresh so the version map also clears
name|logger
operator|.
name|debug
argument_list|(
literal|"use refresh to write indexing buffer (heap size=[{}]), to also clear version map (heap size=[{}])"
argument_list|,
operator|new
name|ByteSizeValue
argument_list|(
name|indexingBufferBytes
argument_list|)
argument_list|,
operator|new
name|ByteSizeValue
argument_list|(
name|versionMapBytes
argument_list|)
argument_list|)
expr_stmt|;
name|refresh
argument_list|(
literal|"write indexing buffer"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// Most of our heap is used by the indexing buffer, so we do a cheaper (just writes segments, doesn't open a new searcher) IW.flush:
name|logger
operator|.
name|debug
argument_list|(
literal|"use IndexWriter.flush to write indexing buffer (heap size=[{}]) since version map is small (heap size=[{}])"
argument_list|,
operator|new
name|ByteSizeValue
argument_list|(
name|indexingBufferBytes
argument_list|)
argument_list|,
operator|new
name|ByteSizeValue
argument_list|(
name|versionMapBytes
argument_list|)
argument_list|)
expr_stmt|;
name|indexWriter
operator|.
name|flush
argument_list|()
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|AlreadyClosedException
name|e
parameter_list|)
block|{
name|failOnTragicEvent
argument_list|(
name|e
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
catch|catch
parameter_list|(
name|EngineClosedException
name|e
parameter_list|)
block|{
throw|throw
name|e
throw|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
try|try
block|{
name|failEngine
argument_list|(
literal|"writeIndexingBuffer failed"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|inner
parameter_list|)
block|{
name|e
operator|.
name|addSuppressed
argument_list|(
name|inner
argument_list|)
expr_stmt|;
block|}
throw|throw
operator|new
name|RefreshFailedEngineException
argument_list|(
name|shardId
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
DECL|method|syncFlush
specifier|public
name|SyncedFlushResult
name|syncFlush
parameter_list|(
name|String
name|syncId
parameter_list|,
name|CommitId
name|expectedCommitId
parameter_list|)
throws|throws
name|EngineException
block|{
comment|// best effort attempt before we acquire locks
name|ensureOpen
argument_list|()
expr_stmt|;
if|if
condition|(
name|indexWriter
operator|.
name|hasUncommittedChanges
argument_list|()
condition|)
block|{
name|logger
operator|.
name|trace
argument_list|(
literal|"can't sync commit [{}]. have pending changes"
argument_list|,
name|syncId
argument_list|)
expr_stmt|;
return|return
name|SyncedFlushResult
operator|.
name|PENDING_OPERATIONS
return|;
block|}
if|if
condition|(
name|expectedCommitId
operator|.
name|idsEqual
argument_list|(
name|lastCommittedSegmentInfos
operator|.
name|getId
argument_list|()
argument_list|)
operator|==
literal|false
condition|)
block|{
name|logger
operator|.
name|trace
argument_list|(
literal|"can't sync commit [{}]. current commit id is not equal to expected."
argument_list|,
name|syncId
argument_list|)
expr_stmt|;
return|return
name|SyncedFlushResult
operator|.
name|COMMIT_MISMATCH
return|;
block|}
try|try
init|(
name|ReleasableLock
name|lock
init|=
name|writeLock
operator|.
name|acquire
argument_list|()
init|)
block|{
name|ensureOpen
argument_list|()
expr_stmt|;
name|ensureCanFlush
argument_list|()
expr_stmt|;
if|if
condition|(
name|indexWriter
operator|.
name|hasUncommittedChanges
argument_list|()
condition|)
block|{
name|logger
operator|.
name|trace
argument_list|(
literal|"can't sync commit [{}]. have pending changes"
argument_list|,
name|syncId
argument_list|)
expr_stmt|;
return|return
name|SyncedFlushResult
operator|.
name|PENDING_OPERATIONS
return|;
block|}
if|if
condition|(
name|expectedCommitId
operator|.
name|idsEqual
argument_list|(
name|lastCommittedSegmentInfos
operator|.
name|getId
argument_list|()
argument_list|)
operator|==
literal|false
condition|)
block|{
name|logger
operator|.
name|trace
argument_list|(
literal|"can't sync commit [{}]. current commit id is not equal to expected."
argument_list|,
name|syncId
argument_list|)
expr_stmt|;
return|return
name|SyncedFlushResult
operator|.
name|COMMIT_MISMATCH
return|;
block|}
name|logger
operator|.
name|trace
argument_list|(
literal|"starting sync commit [{}]"
argument_list|,
name|syncId
argument_list|)
expr_stmt|;
name|commitIndexWriter
argument_list|(
name|indexWriter
argument_list|,
name|translog
argument_list|,
name|syncId
argument_list|)
expr_stmt|;
name|logger
operator|.
name|debug
argument_list|(
literal|"successfully sync committed. sync id [{}]."
argument_list|,
name|syncId
argument_list|)
expr_stmt|;
name|lastCommittedSegmentInfos
operator|=
name|store
operator|.
name|readLastCommittedSegmentsInfo
argument_list|()
expr_stmt|;
return|return
name|SyncedFlushResult
operator|.
name|SUCCESS
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ex
parameter_list|)
block|{
name|maybeFailEngine
argument_list|(
literal|"sync commit"
argument_list|,
name|ex
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|EngineException
argument_list|(
name|shardId
argument_list|,
literal|"failed to sync commit"
argument_list|,
name|ex
argument_list|)
throw|;
block|}
block|}
DECL|method|tryRenewSyncCommit
specifier|final
name|boolean
name|tryRenewSyncCommit
parameter_list|()
block|{
name|boolean
name|renewed
init|=
literal|false
decl_stmt|;
try|try
init|(
name|ReleasableLock
name|lock
init|=
name|writeLock
operator|.
name|acquire
argument_list|()
init|)
block|{
name|ensureOpen
argument_list|()
expr_stmt|;
name|ensureCanFlush
argument_list|()
expr_stmt|;
name|String
name|syncId
init|=
name|lastCommittedSegmentInfos
operator|.
name|getUserData
argument_list|()
operator|.
name|get
argument_list|(
name|SYNC_COMMIT_ID
argument_list|)
decl_stmt|;
if|if
condition|(
name|syncId
operator|!=
literal|null
operator|&&
name|translog
operator|.
name|totalOperations
argument_list|()
operator|==
literal|0
operator|&&
name|indexWriter
operator|.
name|hasUncommittedChanges
argument_list|()
condition|)
block|{
name|logger
operator|.
name|trace
argument_list|(
literal|"start renewing sync commit [{}]"
argument_list|,
name|syncId
argument_list|)
expr_stmt|;
name|commitIndexWriter
argument_list|(
name|indexWriter
argument_list|,
name|translog
argument_list|,
name|syncId
argument_list|)
expr_stmt|;
name|logger
operator|.
name|debug
argument_list|(
literal|"successfully sync committed. sync id [{}]."
argument_list|,
name|syncId
argument_list|)
expr_stmt|;
name|lastCommittedSegmentInfos
operator|=
name|store
operator|.
name|readLastCommittedSegmentsInfo
argument_list|()
expr_stmt|;
name|renewed
operator|=
literal|true
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|ex
parameter_list|)
block|{
name|maybeFailEngine
argument_list|(
literal|"renew sync commit"
argument_list|,
name|ex
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|EngineException
argument_list|(
name|shardId
argument_list|,
literal|"failed to renew sync commit"
argument_list|,
name|ex
argument_list|)
throw|;
block|}
if|if
condition|(
name|renewed
condition|)
block|{
comment|// refresh outside of the write lock
name|refresh
argument_list|(
literal|"renew sync commit"
argument_list|)
expr_stmt|;
block|}
return|return
name|renewed
return|;
block|}
annotation|@
name|Override
DECL|method|flush
specifier|public
name|CommitId
name|flush
parameter_list|()
throws|throws
name|EngineException
block|{
return|return
name|flush
argument_list|(
literal|false
argument_list|,
literal|false
argument_list|)
return|;
block|}
annotation|@
name|Override
DECL|method|flush
specifier|public
name|CommitId
name|flush
parameter_list|(
name|boolean
name|force
parameter_list|,
name|boolean
name|waitIfOngoing
parameter_list|)
throws|throws
name|EngineException
block|{
name|ensureOpen
argument_list|()
expr_stmt|;
specifier|final
name|byte
index|[]
name|newCommitId
decl_stmt|;
comment|/*          * Unfortunately the lock order is important here. We have to acquire the readlock first otherwise          * if we are flushing at the end of the recovery while holding the write lock we can deadlock if:          *  Thread 1: flushes via API and gets the flush lock but blocks on the readlock since Thread 2 has the writeLock          *  Thread 2: flushes at the end of the recovery holding the writeLock and blocks on the flushLock owned by Thread 1          */
try|try
init|(
name|ReleasableLock
name|lock
init|=
name|readLock
operator|.
name|acquire
argument_list|()
init|)
block|{
name|ensureOpen
argument_list|()
expr_stmt|;
if|if
condition|(
name|flushLock
operator|.
name|tryLock
argument_list|()
operator|==
literal|false
condition|)
block|{
comment|// if we can't get the lock right away we block if needed otherwise barf
if|if
condition|(
name|waitIfOngoing
condition|)
block|{
name|logger
operator|.
name|trace
argument_list|(
literal|"waiting for in-flight flush to finish"
argument_list|)
expr_stmt|;
name|flushLock
operator|.
name|lock
argument_list|()
expr_stmt|;
name|logger
operator|.
name|trace
argument_list|(
literal|"acquired flush lock after blocking"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
return|return
operator|new
name|CommitId
argument_list|(
name|lastCommittedSegmentInfos
operator|.
name|getId
argument_list|()
argument_list|)
return|;
block|}
block|}
else|else
block|{
name|logger
operator|.
name|trace
argument_list|(
literal|"acquired flush lock immediately"
argument_list|)
expr_stmt|;
block|}
try|try
block|{
if|if
condition|(
name|indexWriter
operator|.
name|hasUncommittedChanges
argument_list|()
operator|||
name|force
condition|)
block|{
name|ensureCanFlush
argument_list|()
expr_stmt|;
try|try
block|{
name|translog
operator|.
name|prepareCommit
argument_list|()
expr_stmt|;
name|logger
operator|.
name|trace
argument_list|(
literal|"starting commit for flush; commitTranslog=true"
argument_list|)
expr_stmt|;
name|commitIndexWriter
argument_list|(
name|indexWriter
argument_list|,
name|translog
argument_list|,
literal|null
argument_list|)
expr_stmt|;
name|logger
operator|.
name|trace
argument_list|(
literal|"finished commit for flush"
argument_list|)
expr_stmt|;
comment|// we need to refresh in order to clear older version values
name|refresh
argument_list|(
literal|"version_table_flush"
argument_list|)
expr_stmt|;
comment|// after refresh documents can be retrieved from the index so we can now commit the translog
name|translog
operator|.
name|commit
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|FlushFailedEngineException
argument_list|(
name|shardId
argument_list|,
name|e
argument_list|)
throw|;
block|}
comment|/*                      * we have to inc-ref the store here since if the engine is closed by a tragic event                      * we don't acquire the write lock and wait until we have exclusive access. This might also                      * dec the store reference which can essentially close the store and unless we can inc the reference                      * we can't use it.                      */
name|store
operator|.
name|incRef
argument_list|()
expr_stmt|;
try|try
block|{
comment|// reread the last committed segment infos
name|lastCommittedSegmentInfos
operator|=
name|store
operator|.
name|readLastCommittedSegmentsInfo
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
if|if
condition|(
name|isClosed
operator|.
name|get
argument_list|()
operator|==
literal|false
condition|)
block|{
try|try
block|{
name|logger
operator|.
name|warn
argument_list|(
literal|"failed to read latest segment infos on flush"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|inner
parameter_list|)
block|{
name|e
operator|.
name|addSuppressed
argument_list|(
name|inner
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|Lucene
operator|.
name|isCorruptionException
argument_list|(
name|e
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|FlushFailedEngineException
argument_list|(
name|shardId
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
block|}
finally|finally
block|{
name|store
operator|.
name|decRef
argument_list|()
expr_stmt|;
block|}
block|}
name|newCommitId
operator|=
name|lastCommittedSegmentInfos
operator|.
name|getId
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|FlushFailedEngineException
name|ex
parameter_list|)
block|{
name|maybeFailEngine
argument_list|(
literal|"flush"
argument_list|,
name|ex
argument_list|)
expr_stmt|;
throw|throw
name|ex
throw|;
block|}
finally|finally
block|{
name|flushLock
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|// We don't have to do this here; we do it defensively to make sure that even if wall clock time is misbehaving
comment|// (e.g., moves backwards) we will at least still sometimes prune deleted tombstones:
if|if
condition|(
name|engineConfig
operator|.
name|isEnableGcDeletes
argument_list|()
condition|)
block|{
name|pruneDeletedTombstones
argument_list|()
expr_stmt|;
block|}
return|return
operator|new
name|CommitId
argument_list|(
name|newCommitId
argument_list|)
return|;
block|}
DECL|method|pruneDeletedTombstones
specifier|private
name|void
name|pruneDeletedTombstones
parameter_list|()
block|{
name|long
name|timeMSec
init|=
name|engineConfig
operator|.
name|getThreadPool
argument_list|()
operator|.
name|estimatedTimeInMillis
argument_list|()
decl_stmt|;
comment|// TODO: not good that we reach into LiveVersionMap here; can we move this inside VersionMap instead?  problem is the dirtyLock...
comment|// we only need to prune the deletes map; the current/old version maps are cleared on refresh:
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|BytesRef
argument_list|,
name|VersionValue
argument_list|>
name|entry
range|:
name|versionMap
operator|.
name|getAllTombstones
argument_list|()
control|)
block|{
name|BytesRef
name|uid
init|=
name|entry
operator|.
name|getKey
argument_list|()
decl_stmt|;
try|try
init|(
name|Releasable
name|ignored
init|=
name|acquireLock
argument_list|(
name|uid
argument_list|)
init|)
block|{
comment|// can we do it without this lock on each value? maybe batch to a set and get the lock once per set?
comment|// Must re-get it here, vs using entry.getValue(), in case the uid was indexed/deleted since we pulled the iterator:
name|VersionValue
name|versionValue
init|=
name|versionMap
operator|.
name|getTombstoneUnderLock
argument_list|(
name|uid
argument_list|)
decl_stmt|;
if|if
condition|(
name|versionValue
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|timeMSec
operator|-
name|versionValue
operator|.
name|time
argument_list|()
operator|>
name|getGcDeletesInMillis
argument_list|()
condition|)
block|{
name|versionMap
operator|.
name|removeTombstoneUnderLock
argument_list|(
name|uid
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
name|lastDeleteVersionPruneTimeMSec
operator|=
name|timeMSec
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|forceMerge
specifier|public
name|void
name|forceMerge
parameter_list|(
specifier|final
name|boolean
name|flush
parameter_list|,
name|int
name|maxNumSegments
parameter_list|,
name|boolean
name|onlyExpungeDeletes
parameter_list|,
specifier|final
name|boolean
name|upgrade
parameter_list|,
specifier|final
name|boolean
name|upgradeOnlyAncientSegments
parameter_list|)
throws|throws
name|EngineException
throws|,
name|EngineClosedException
throws|,
name|IOException
block|{
comment|/*          * We do NOT acquire the readlock here since we are waiting on the merges to finish          * that's fine since the IW.rollback should stop all the threads and trigger an IOException          * causing us to fail the forceMerge          *          * The way we implement upgrades is a bit hackish in the sense that we set an instance          * variable and that this setting will thus apply to the next forced merge that will be run.          * This is ok because (1) this is the only place we call forceMerge, (2) we have a single          * thread for optimize, and the 'optimizeLock' guarding this code, and (3) ConcurrentMergeScheduler          * syncs calls to findForcedMerges.          */
assert|assert
name|indexWriter
operator|.
name|getConfig
argument_list|()
operator|.
name|getMergePolicy
argument_list|()
operator|instanceof
name|ElasticsearchMergePolicy
operator|:
literal|"MergePolicy is "
operator|+
name|indexWriter
operator|.
name|getConfig
argument_list|()
operator|.
name|getMergePolicy
argument_list|()
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
assert|;
name|ElasticsearchMergePolicy
name|mp
init|=
operator|(
name|ElasticsearchMergePolicy
operator|)
name|indexWriter
operator|.
name|getConfig
argument_list|()
operator|.
name|getMergePolicy
argument_list|()
decl_stmt|;
name|optimizeLock
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|ensureOpen
argument_list|()
expr_stmt|;
if|if
condition|(
name|upgrade
condition|)
block|{
name|logger
operator|.
name|info
argument_list|(
literal|"starting segment upgrade upgradeOnlyAncientSegments={}"
argument_list|,
name|upgradeOnlyAncientSegments
argument_list|)
expr_stmt|;
name|mp
operator|.
name|setUpgradeInProgress
argument_list|(
literal|true
argument_list|,
name|upgradeOnlyAncientSegments
argument_list|)
expr_stmt|;
block|}
name|store
operator|.
name|incRef
argument_list|()
expr_stmt|;
comment|// increment the ref just to ensure nobody closes the store while we optimize
try|try
block|{
if|if
condition|(
name|onlyExpungeDeletes
condition|)
block|{
assert|assert
name|upgrade
operator|==
literal|false
assert|;
name|indexWriter
operator|.
name|forceMergeDeletes
argument_list|(
literal|true
comment|/* blocks and waits for merges*/
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|maxNumSegments
operator|<=
literal|0
condition|)
block|{
assert|assert
name|upgrade
operator|==
literal|false
assert|;
name|indexWriter
operator|.
name|maybeMerge
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|indexWriter
operator|.
name|forceMerge
argument_list|(
name|maxNumSegments
argument_list|,
literal|true
comment|/* blocks and waits for merges*/
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|flush
condition|)
block|{
if|if
condition|(
name|tryRenewSyncCommit
argument_list|()
operator|==
literal|false
condition|)
block|{
name|flush
argument_list|(
literal|false
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|upgrade
condition|)
block|{
name|logger
operator|.
name|info
argument_list|(
literal|"finished segment upgrade"
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|store
operator|.
name|decRef
argument_list|()
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|AlreadyClosedException
name|ex
parameter_list|)
block|{
comment|/* in this case we first check if the engine is still open. If so this exception is just fine              * and expected. We don't hold any locks while we block on forceMerge otherwise it would block              * closing the engine as well. If we are not closed we pass it on to failOnTragicEvent which ensures              * we are handling a tragic even exception here */
name|ensureOpen
argument_list|()
expr_stmt|;
name|failOnTragicEvent
argument_list|(
name|ex
argument_list|)
expr_stmt|;
throw|throw
name|ex
throw|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
try|try
block|{
name|maybeFailEngine
argument_list|(
literal|"force merge"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|inner
parameter_list|)
block|{
name|e
operator|.
name|addSuppressed
argument_list|(
name|inner
argument_list|)
expr_stmt|;
block|}
throw|throw
name|e
throw|;
block|}
finally|finally
block|{
try|try
block|{
name|mp
operator|.
name|setUpgradeInProgress
argument_list|(
literal|false
argument_list|,
literal|false
argument_list|)
expr_stmt|;
comment|// reset it just to make sure we reset it in a case of an error
block|}
finally|finally
block|{
name|optimizeLock
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
block|}
annotation|@
name|Override
DECL|method|acquireIndexCommit
specifier|public
name|IndexCommit
name|acquireIndexCommit
parameter_list|(
specifier|final
name|boolean
name|flushFirst
parameter_list|)
throws|throws
name|EngineException
block|{
comment|// we have to flush outside of the readlock otherwise we might have a problem upgrading
comment|// the to a write lock when we fail the engine in this operation
if|if
condition|(
name|flushFirst
condition|)
block|{
name|logger
operator|.
name|trace
argument_list|(
literal|"start flush for snapshot"
argument_list|)
expr_stmt|;
name|flush
argument_list|(
literal|false
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|logger
operator|.
name|trace
argument_list|(
literal|"finish flush for snapshot"
argument_list|)
expr_stmt|;
block|}
try|try
init|(
name|ReleasableLock
name|lock
init|=
name|readLock
operator|.
name|acquire
argument_list|()
init|)
block|{
name|ensureOpen
argument_list|()
expr_stmt|;
name|logger
operator|.
name|trace
argument_list|(
literal|"pulling snapshot"
argument_list|)
expr_stmt|;
return|return
name|deletionPolicy
operator|.
name|snapshot
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|SnapshotFailedEngineException
argument_list|(
name|shardId
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
DECL|method|failOnTragicEvent
specifier|private
name|void
name|failOnTragicEvent
parameter_list|(
name|AlreadyClosedException
name|ex
parameter_list|)
block|{
comment|// if we are already closed due to some tragic exception
comment|// we need to fail the engine. it might have already been failed before
comment|// but we are double-checking it's failed and closed
if|if
condition|(
name|indexWriter
operator|.
name|isOpen
argument_list|()
operator|==
literal|false
operator|&&
name|indexWriter
operator|.
name|getTragicException
argument_list|()
operator|!=
literal|null
condition|)
block|{
specifier|final
name|Exception
name|tragedy
init|=
name|indexWriter
operator|.
name|getTragicException
argument_list|()
operator|instanceof
name|Exception
condition|?
operator|(
name|Exception
operator|)
name|indexWriter
operator|.
name|getTragicException
argument_list|()
else|:
operator|new
name|Exception
argument_list|(
name|indexWriter
operator|.
name|getTragicException
argument_list|()
argument_list|)
decl_stmt|;
name|failEngine
argument_list|(
literal|"already closed by tragic event on the index writer"
argument_list|,
name|tragedy
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|translog
operator|.
name|isOpen
argument_list|()
operator|==
literal|false
operator|&&
name|translog
operator|.
name|getTragicException
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|failEngine
argument_list|(
literal|"already closed by tragic event on the translog"
argument_list|,
name|translog
operator|.
name|getTragicException
argument_list|()
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|failedEngine
operator|.
name|get
argument_list|()
operator|==
literal|null
condition|)
block|{
comment|// we are closed but the engine is not failed yet?
comment|// this smells like a bug - we only expect ACE if we are in a fatal case ie. either translog or IW is closed by
comment|// a tragic event or has closed itself. if that is not the case we are in a buggy state and raise an assertion error
throw|throw
operator|new
name|AssertionError
argument_list|(
literal|"Unexpected AlreadyClosedException"
argument_list|,
name|ex
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
DECL|method|maybeFailEngine
specifier|protected
name|boolean
name|maybeFailEngine
parameter_list|(
name|String
name|source
parameter_list|,
name|Exception
name|e
parameter_list|)
block|{
name|boolean
name|shouldFail
init|=
name|super
operator|.
name|maybeFailEngine
argument_list|(
name|source
argument_list|,
name|e
argument_list|)
decl_stmt|;
if|if
condition|(
name|shouldFail
condition|)
block|{
return|return
literal|true
return|;
block|}
comment|// Check for AlreadyClosedException -- ACE is a very special
comment|// exception that should only be thrown in a tragic event. we pass on the checks to failOnTragicEvent which will
comment|// throw and AssertionError if the tragic event condition is not met.
if|if
condition|(
name|e
operator|instanceof
name|AlreadyClosedException
condition|)
block|{
name|failOnTragicEvent
argument_list|(
operator|(
name|AlreadyClosedException
operator|)
name|e
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
elseif|else
if|if
condition|(
name|e
operator|!=
literal|null
operator|&&
operator|(
operator|(
name|indexWriter
operator|.
name|isOpen
argument_list|()
operator|==
literal|false
operator|&&
name|indexWriter
operator|.
name|getTragicException
argument_list|()
operator|==
name|e
operator|)
operator|||
operator|(
name|translog
operator|.
name|isOpen
argument_list|()
operator|==
literal|false
operator|&&
name|translog
operator|.
name|getTragicException
argument_list|()
operator|==
name|e
operator|)
operator|)
condition|)
block|{
comment|// this spot on - we are handling the tragic event exception here so we have to fail the engine
comment|// right away
name|failEngine
argument_list|(
name|source
argument_list|,
name|e
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
return|return
literal|false
return|;
block|}
annotation|@
name|Override
DECL|method|getLastCommittedSegmentInfos
specifier|protected
name|SegmentInfos
name|getLastCommittedSegmentInfos
parameter_list|()
block|{
return|return
name|lastCommittedSegmentInfos
return|;
block|}
annotation|@
name|Override
DECL|method|writerSegmentStats
specifier|protected
specifier|final
name|void
name|writerSegmentStats
parameter_list|(
name|SegmentsStats
name|stats
parameter_list|)
block|{
name|stats
operator|.
name|addVersionMapMemoryInBytes
argument_list|(
name|versionMap
operator|.
name|ramBytesUsed
argument_list|()
argument_list|)
expr_stmt|;
name|stats
operator|.
name|addIndexWriterMemoryInBytes
argument_list|(
name|indexWriter
operator|.
name|ramBytesUsed
argument_list|()
argument_list|)
expr_stmt|;
name|stats
operator|.
name|updateMaxUnsafeAutoIdTimestamp
argument_list|(
name|maxUnsafeAutoIdTimestamp
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|getIndexBufferRAMBytesUsed
specifier|public
name|long
name|getIndexBufferRAMBytesUsed
parameter_list|()
block|{
comment|// We don't guard w/ readLock here, so we could throw AlreadyClosedException
return|return
name|indexWriter
operator|.
name|ramBytesUsed
argument_list|()
operator|+
name|versionMap
operator|.
name|ramBytesUsedForRefresh
argument_list|()
return|;
block|}
annotation|@
name|Override
DECL|method|segments
specifier|public
name|List
argument_list|<
name|Segment
argument_list|>
name|segments
parameter_list|(
name|boolean
name|verbose
parameter_list|)
block|{
try|try
init|(
name|ReleasableLock
name|lock
init|=
name|readLock
operator|.
name|acquire
argument_list|()
init|)
block|{
name|Segment
index|[]
name|segmentsArr
init|=
name|getSegmentInfo
argument_list|(
name|lastCommittedSegmentInfos
argument_list|,
name|verbose
argument_list|)
decl_stmt|;
comment|// fill in the merges flag
name|Set
argument_list|<
name|OnGoingMerge
argument_list|>
name|onGoingMerges
init|=
name|mergeScheduler
operator|.
name|onGoingMerges
argument_list|()
decl_stmt|;
for|for
control|(
name|OnGoingMerge
name|onGoingMerge
range|:
name|onGoingMerges
control|)
block|{
for|for
control|(
name|SegmentCommitInfo
name|segmentInfoPerCommit
range|:
name|onGoingMerge
operator|.
name|getMergedSegments
argument_list|()
control|)
block|{
for|for
control|(
name|Segment
name|segment
range|:
name|segmentsArr
control|)
block|{
if|if
condition|(
name|segment
operator|.
name|getName
argument_list|()
operator|.
name|equals
argument_list|(
name|segmentInfoPerCommit
operator|.
name|info
operator|.
name|name
argument_list|)
condition|)
block|{
name|segment
operator|.
name|mergeId
operator|=
name|onGoingMerge
operator|.
name|getId
argument_list|()
expr_stmt|;
break|break;
block|}
block|}
block|}
block|}
return|return
name|Arrays
operator|.
name|asList
argument_list|(
name|segmentsArr
argument_list|)
return|;
block|}
block|}
comment|/**      * Closes the engine without acquiring the write lock. This should only be      * called while the write lock is hold or in a disaster condition ie. if the engine      * is failed.      */
annotation|@
name|Override
DECL|method|closeNoLock
specifier|protected
specifier|final
name|void
name|closeNoLock
parameter_list|(
name|String
name|reason
parameter_list|)
block|{
if|if
condition|(
name|isClosed
operator|.
name|compareAndSet
argument_list|(
literal|false
argument_list|,
literal|true
argument_list|)
condition|)
block|{
assert|assert
name|rwl
operator|.
name|isWriteLockedByCurrentThread
argument_list|()
operator|||
name|failEngineLock
operator|.
name|isHeldByCurrentThread
argument_list|()
operator|:
literal|"Either the write lock must be held or the engine must be currently be failing itself"
assert|;
try|try
block|{
name|this
operator|.
name|versionMap
operator|.
name|clear
argument_list|()
expr_stmt|;
try|try
block|{
name|IOUtils
operator|.
name|close
argument_list|(
name|searcherManager
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|logger
operator|.
name|warn
argument_list|(
literal|"Failed to close SearcherManager"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
try|try
block|{
name|IOUtils
operator|.
name|close
argument_list|(
name|translog
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|logger
operator|.
name|warn
argument_list|(
literal|"Failed to close translog"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
comment|// no need to commit in this case!, we snapshot before we close the shard, so translog and all sync'ed
name|logger
operator|.
name|trace
argument_list|(
literal|"rollback indexWriter"
argument_list|)
expr_stmt|;
try|try
block|{
name|indexWriter
operator|.
name|rollback
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|AlreadyClosedException
name|ex
parameter_list|)
block|{
name|failOnTragicEvent
argument_list|(
name|ex
argument_list|)
expr_stmt|;
throw|throw
name|ex
throw|;
block|}
name|logger
operator|.
name|trace
argument_list|(
literal|"rollback indexWriter done"
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|logger
operator|.
name|warn
argument_list|(
literal|"failed to rollback writer on close"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|store
operator|.
name|decRef
argument_list|()
expr_stmt|;
name|logger
operator|.
name|debug
argument_list|(
literal|"engine closed [{}]"
argument_list|,
name|reason
argument_list|)
expr_stmt|;
block|}
block|}
block|}
annotation|@
name|Override
DECL|method|getSearcherManager
specifier|protected
name|SearcherManager
name|getSearcherManager
parameter_list|()
block|{
return|return
name|searcherManager
return|;
block|}
DECL|method|acquireLock
specifier|private
name|Releasable
name|acquireLock
parameter_list|(
name|BytesRef
name|uid
parameter_list|)
block|{
return|return
name|keyedLock
operator|.
name|acquire
argument_list|(
name|uid
argument_list|)
return|;
block|}
DECL|method|acquireLock
specifier|private
name|Releasable
name|acquireLock
parameter_list|(
name|Term
name|uid
parameter_list|)
block|{
return|return
name|acquireLock
argument_list|(
name|uid
operator|.
name|bytes
argument_list|()
argument_list|)
return|;
block|}
DECL|method|loadCurrentVersionFromIndex
specifier|private
name|long
name|loadCurrentVersionFromIndex
parameter_list|(
name|Term
name|uid
parameter_list|)
throws|throws
name|IOException
block|{
assert|assert
name|incrementIndexVersionLookup
argument_list|()
assert|;
try|try
init|(
specifier|final
name|Searcher
name|searcher
init|=
name|acquireSearcher
argument_list|(
literal|"load_version"
argument_list|)
init|)
block|{
return|return
name|Versions
operator|.
name|loadVersion
argument_list|(
name|searcher
operator|.
name|reader
argument_list|()
argument_list|,
name|uid
argument_list|)
return|;
block|}
block|}
DECL|method|createWriter
specifier|private
name|IndexWriter
name|createWriter
parameter_list|(
name|boolean
name|create
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
specifier|final
name|IndexWriterConfig
name|iwc
init|=
operator|new
name|IndexWriterConfig
argument_list|(
name|engineConfig
operator|.
name|getAnalyzer
argument_list|()
argument_list|)
decl_stmt|;
name|iwc
operator|.
name|setCommitOnClose
argument_list|(
literal|false
argument_list|)
expr_stmt|;
comment|// we by default don't commit on close
name|iwc
operator|.
name|setOpenMode
argument_list|(
name|create
condition|?
name|IndexWriterConfig
operator|.
name|OpenMode
operator|.
name|CREATE
else|:
name|IndexWriterConfig
operator|.
name|OpenMode
operator|.
name|APPEND
argument_list|)
expr_stmt|;
name|iwc
operator|.
name|setIndexDeletionPolicy
argument_list|(
name|deletionPolicy
argument_list|)
expr_stmt|;
comment|// with tests.verbose, lucene sets this up: plumb to align with filesystem stream
name|boolean
name|verbose
init|=
literal|false
decl_stmt|;
try|try
block|{
name|verbose
operator|=
name|Boolean
operator|.
name|parseBoolean
argument_list|(
name|System
operator|.
name|getProperty
argument_list|(
literal|"tests.verbose"
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|ignore
parameter_list|)
block|{             }
name|iwc
operator|.
name|setInfoStream
argument_list|(
name|verbose
condition|?
name|InfoStream
operator|.
name|getDefault
argument_list|()
else|:
operator|new
name|LoggerInfoStream
argument_list|(
name|logger
argument_list|)
argument_list|)
expr_stmt|;
name|iwc
operator|.
name|setMergeScheduler
argument_list|(
name|mergeScheduler
argument_list|)
expr_stmt|;
name|MergePolicy
name|mergePolicy
init|=
name|config
argument_list|()
operator|.
name|getMergePolicy
argument_list|()
decl_stmt|;
comment|// Give us the opportunity to upgrade old segments while performing
comment|// background merges
name|mergePolicy
operator|=
operator|new
name|ElasticsearchMergePolicy
argument_list|(
name|mergePolicy
argument_list|)
expr_stmt|;
name|iwc
operator|.
name|setMergePolicy
argument_list|(
name|mergePolicy
argument_list|)
expr_stmt|;
name|iwc
operator|.
name|setSimilarity
argument_list|(
name|engineConfig
operator|.
name|getSimilarity
argument_list|()
argument_list|)
expr_stmt|;
name|iwc
operator|.
name|setRAMBufferSizeMB
argument_list|(
name|engineConfig
operator|.
name|getIndexingBufferSize
argument_list|()
operator|.
name|getMbFrac
argument_list|()
argument_list|)
expr_stmt|;
name|iwc
operator|.
name|setCodec
argument_list|(
name|engineConfig
operator|.
name|getCodec
argument_list|()
argument_list|)
expr_stmt|;
name|iwc
operator|.
name|setUseCompoundFile
argument_list|(
literal|true
argument_list|)
expr_stmt|;
comment|// always use compound on flush - reduces # of file-handles on refresh
return|return
operator|new
name|IndexWriter
argument_list|(
name|store
operator|.
name|directory
argument_list|()
argument_list|,
name|iwc
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|LockObtainFailedException
name|ex
parameter_list|)
block|{
name|logger
operator|.
name|warn
argument_list|(
literal|"could not lock IndexWriter"
argument_list|,
name|ex
argument_list|)
expr_stmt|;
throw|throw
name|ex
throw|;
block|}
block|}
comment|/** Extended SearcherFactory that warms the segments if needed when acquiring a new searcher */
DECL|class|SearchFactory
specifier|static
specifier|final
class|class
name|SearchFactory
extends|extends
name|EngineSearcherFactory
block|{
DECL|field|warmer
specifier|private
specifier|final
name|Engine
operator|.
name|Warmer
name|warmer
decl_stmt|;
DECL|field|logger
specifier|private
specifier|final
name|Logger
name|logger
decl_stmt|;
DECL|field|isEngineClosed
specifier|private
specifier|final
name|AtomicBoolean
name|isEngineClosed
decl_stmt|;
DECL|method|SearchFactory
name|SearchFactory
parameter_list|(
name|Logger
name|logger
parameter_list|,
name|AtomicBoolean
name|isEngineClosed
parameter_list|,
name|EngineConfig
name|engineConfig
parameter_list|)
block|{
name|super
argument_list|(
name|engineConfig
argument_list|)
expr_stmt|;
name|warmer
operator|=
name|engineConfig
operator|.
name|getWarmer
argument_list|()
expr_stmt|;
name|this
operator|.
name|logger
operator|=
name|logger
expr_stmt|;
name|this
operator|.
name|isEngineClosed
operator|=
name|isEngineClosed
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|newSearcher
specifier|public
name|IndexSearcher
name|newSearcher
parameter_list|(
name|IndexReader
name|reader
parameter_list|,
name|IndexReader
name|previousReader
parameter_list|)
throws|throws
name|IOException
block|{
name|IndexSearcher
name|searcher
init|=
name|super
operator|.
name|newSearcher
argument_list|(
name|reader
argument_list|,
name|previousReader
argument_list|)
decl_stmt|;
if|if
condition|(
name|reader
operator|instanceof
name|LeafReader
operator|&&
name|isMergedSegment
argument_list|(
operator|(
name|LeafReader
operator|)
name|reader
argument_list|)
condition|)
block|{
comment|// we call newSearcher from the IndexReaderWarmer which warms segments during merging
comment|// in that case the reader is a LeafReader and all we need to do is to build a new Searcher
comment|// and return it since it does it's own warming for that particular reader.
return|return
name|searcher
return|;
block|}
if|if
condition|(
name|warmer
operator|!=
literal|null
condition|)
block|{
try|try
block|{
assert|assert
name|searcher
operator|.
name|getIndexReader
argument_list|()
operator|instanceof
name|ElasticsearchDirectoryReader
operator|:
literal|"this class needs an ElasticsearchDirectoryReader but got: "
operator|+
name|searcher
operator|.
name|getIndexReader
argument_list|()
operator|.
name|getClass
argument_list|()
assert|;
name|warmer
operator|.
name|warm
argument_list|(
operator|new
name|Searcher
argument_list|(
literal|"top_reader_warming"
argument_list|,
name|searcher
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
if|if
condition|(
name|isEngineClosed
operator|.
name|get
argument_list|()
operator|==
literal|false
condition|)
block|{
name|logger
operator|.
name|warn
argument_list|(
literal|"failed to prepare/warm"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|searcher
return|;
block|}
block|}
annotation|@
name|Override
DECL|method|activateThrottling
specifier|public
name|void
name|activateThrottling
parameter_list|()
block|{
name|int
name|count
init|=
name|throttleRequestCount
operator|.
name|incrementAndGet
argument_list|()
decl_stmt|;
assert|assert
name|count
operator|>=
literal|1
operator|:
literal|"invalid post-increment throttleRequestCount="
operator|+
name|count
assert|;
if|if
condition|(
name|count
operator|==
literal|1
condition|)
block|{
name|throttle
operator|.
name|activate
argument_list|()
expr_stmt|;
block|}
block|}
annotation|@
name|Override
DECL|method|deactivateThrottling
specifier|public
name|void
name|deactivateThrottling
parameter_list|()
block|{
name|int
name|count
init|=
name|throttleRequestCount
operator|.
name|decrementAndGet
argument_list|()
decl_stmt|;
assert|assert
name|count
operator|>=
literal|0
operator|:
literal|"invalid post-decrement throttleRequestCount="
operator|+
name|count
assert|;
if|if
condition|(
name|count
operator|==
literal|0
condition|)
block|{
name|throttle
operator|.
name|deactivate
argument_list|()
expr_stmt|;
block|}
block|}
DECL|method|getIndexThrottleTimeInMillis
specifier|public
name|long
name|getIndexThrottleTimeInMillis
parameter_list|()
block|{
return|return
name|throttle
operator|.
name|getThrottleTimeInMillis
argument_list|()
return|;
block|}
DECL|method|getGcDeletesInMillis
name|long
name|getGcDeletesInMillis
parameter_list|()
block|{
return|return
name|engineConfig
operator|.
name|getIndexSettings
argument_list|()
operator|.
name|getGcDeletesInMillis
argument_list|()
return|;
block|}
DECL|method|getCurrentIndexWriterConfig
name|LiveIndexWriterConfig
name|getCurrentIndexWriterConfig
parameter_list|()
block|{
return|return
name|indexWriter
operator|.
name|getConfig
argument_list|()
return|;
block|}
DECL|class|EngineMergeScheduler
specifier|private
specifier|final
class|class
name|EngineMergeScheduler
extends|extends
name|ElasticsearchConcurrentMergeScheduler
block|{
DECL|field|numMergesInFlight
specifier|private
specifier|final
name|AtomicInteger
name|numMergesInFlight
init|=
operator|new
name|AtomicInteger
argument_list|(
literal|0
argument_list|)
decl_stmt|;
DECL|field|isThrottling
specifier|private
specifier|final
name|AtomicBoolean
name|isThrottling
init|=
operator|new
name|AtomicBoolean
argument_list|()
decl_stmt|;
DECL|method|EngineMergeScheduler
name|EngineMergeScheduler
parameter_list|(
name|ShardId
name|shardId
parameter_list|,
name|IndexSettings
name|indexSettings
parameter_list|)
block|{
name|super
argument_list|(
name|shardId
argument_list|,
name|indexSettings
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|beforeMerge
specifier|public
specifier|synchronized
name|void
name|beforeMerge
parameter_list|(
name|OnGoingMerge
name|merge
parameter_list|)
block|{
name|int
name|maxNumMerges
init|=
name|mergeScheduler
operator|.
name|getMaxMergeCount
argument_list|()
decl_stmt|;
if|if
condition|(
name|numMergesInFlight
operator|.
name|incrementAndGet
argument_list|()
operator|>
name|maxNumMerges
condition|)
block|{
if|if
condition|(
name|isThrottling
operator|.
name|getAndSet
argument_list|(
literal|true
argument_list|)
operator|==
literal|false
condition|)
block|{
name|logger
operator|.
name|info
argument_list|(
literal|"now throttling indexing: numMergesInFlight={}, maxNumMerges={}"
argument_list|,
name|numMergesInFlight
argument_list|,
name|maxNumMerges
argument_list|)
expr_stmt|;
name|activateThrottling
argument_list|()
expr_stmt|;
block|}
block|}
block|}
annotation|@
name|Override
DECL|method|afterMerge
specifier|public
specifier|synchronized
name|void
name|afterMerge
parameter_list|(
name|OnGoingMerge
name|merge
parameter_list|)
block|{
name|int
name|maxNumMerges
init|=
name|mergeScheduler
operator|.
name|getMaxMergeCount
argument_list|()
decl_stmt|;
if|if
condition|(
name|numMergesInFlight
operator|.
name|decrementAndGet
argument_list|()
operator|<
name|maxNumMerges
condition|)
block|{
if|if
condition|(
name|isThrottling
operator|.
name|getAndSet
argument_list|(
literal|false
argument_list|)
condition|)
block|{
name|logger
operator|.
name|info
argument_list|(
literal|"stop throttling indexing: numMergesInFlight={}, maxNumMerges={}"
argument_list|,
name|numMergesInFlight
argument_list|,
name|maxNumMerges
argument_list|)
expr_stmt|;
name|deactivateThrottling
argument_list|()
expr_stmt|;
block|}
block|}
if|if
condition|(
name|indexWriter
operator|.
name|hasPendingMerges
argument_list|()
operator|==
literal|false
operator|&&
name|System
operator|.
name|nanoTime
argument_list|()
operator|-
name|lastWriteNanos
operator|>=
name|engineConfig
operator|.
name|getFlushMergesAfter
argument_list|()
operator|.
name|nanos
argument_list|()
condition|)
block|{
comment|// NEVER do this on a merge thread since we acquire some locks blocking here and if we concurrently rollback the writer
comment|// we deadlock on engine#close for instance.
name|engineConfig
operator|.
name|getThreadPool
argument_list|()
operator|.
name|executor
argument_list|(
name|ThreadPool
operator|.
name|Names
operator|.
name|FLUSH
argument_list|)
operator|.
name|execute
argument_list|(
operator|new
name|AbstractRunnable
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|onFailure
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
if|if
condition|(
name|isClosed
operator|.
name|get
argument_list|()
operator|==
literal|false
condition|)
block|{
name|logger
operator|.
name|warn
argument_list|(
literal|"failed to flush after merge has finished"
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|protected
name|void
name|doRun
parameter_list|()
throws|throws
name|Exception
block|{
comment|// if we have no pending merges and we are supposed to flush once merges have finished
comment|// we try to renew a sync commit which is the case when we are having a big merge after we
comment|// are inactive. If that didn't work we go and do a real flush which is ok since it only doesn't work
comment|// if we either have records in the translog or if we don't have a sync ID at all...
comment|// maybe even more important, we flush after all merges finish and we are inactive indexing-wise to
comment|// free up transient disk usage of the (presumably biggish) segments that were just merged
if|if
condition|(
name|tryRenewSyncCommit
argument_list|()
operator|==
literal|false
condition|)
block|{
name|flush
argument_list|()
expr_stmt|;
block|}
block|}
block|}
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Override
DECL|method|handleMergeException
specifier|protected
name|void
name|handleMergeException
parameter_list|(
specifier|final
name|Directory
name|dir
parameter_list|,
specifier|final
name|Throwable
name|exc
parameter_list|)
block|{
name|logger
operator|.
name|error
argument_list|(
literal|"failed to merge"
argument_list|,
name|exc
argument_list|)
expr_stmt|;
name|engineConfig
operator|.
name|getThreadPool
argument_list|()
operator|.
name|generic
argument_list|()
operator|.
name|execute
argument_list|(
operator|new
name|AbstractRunnable
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|onFailure
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"merge failure action rejected"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|protected
name|void
name|doRun
parameter_list|()
throws|throws
name|Exception
block|{
name|MergePolicy
operator|.
name|MergeException
name|e
init|=
operator|new
name|MergePolicy
operator|.
name|MergeException
argument_list|(
name|exc
argument_list|,
name|dir
argument_list|)
decl_stmt|;
name|failEngine
argument_list|(
literal|"merge failed"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|commitIndexWriter
specifier|private
name|void
name|commitIndexWriter
parameter_list|(
name|IndexWriter
name|writer
parameter_list|,
name|Translog
name|translog
parameter_list|,
name|String
name|syncId
parameter_list|)
throws|throws
name|IOException
block|{
name|ensureCanFlush
argument_list|()
expr_stmt|;
try|try
block|{
name|Translog
operator|.
name|TranslogGeneration
name|translogGeneration
init|=
name|translog
operator|.
name|getGeneration
argument_list|()
decl_stmt|;
name|logger
operator|.
name|trace
argument_list|(
literal|"committing writer with translog id [{}]  and sync id [{}] "
argument_list|,
name|translogGeneration
operator|.
name|translogFileGeneration
argument_list|,
name|syncId
argument_list|)
expr_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|commitData
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|(
literal|2
argument_list|)
decl_stmt|;
name|commitData
operator|.
name|put
argument_list|(
name|Translog
operator|.
name|TRANSLOG_GENERATION_KEY
argument_list|,
name|Long
operator|.
name|toString
argument_list|(
name|translogGeneration
operator|.
name|translogFileGeneration
argument_list|)
argument_list|)
expr_stmt|;
name|commitData
operator|.
name|put
argument_list|(
name|Translog
operator|.
name|TRANSLOG_UUID_KEY
argument_list|,
name|translogGeneration
operator|.
name|translogUUID
argument_list|)
expr_stmt|;
if|if
condition|(
name|syncId
operator|!=
literal|null
condition|)
block|{
name|commitData
operator|.
name|put
argument_list|(
name|Engine
operator|.
name|SYNC_COMMIT_ID
argument_list|,
name|syncId
argument_list|)
expr_stmt|;
block|}
name|indexWriter
operator|.
name|setCommitData
argument_list|(
name|commitData
argument_list|)
expr_stmt|;
name|writer
operator|.
name|commit
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|ex
parameter_list|)
block|{
try|try
block|{
name|failEngine
argument_list|(
literal|"lucene commit failed"
argument_list|,
name|ex
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|inner
parameter_list|)
block|{
name|ex
operator|.
name|addSuppressed
argument_list|(
name|inner
argument_list|)
expr_stmt|;
block|}
throw|throw
name|ex
throw|;
block|}
catch|catch
parameter_list|(
name|AssertionError
name|e
parameter_list|)
block|{
comment|// IndexWriter throws AssertionError on commit, if asserts are enabled, if any files don't exist, but tests that
comment|// randomly throw FNFE/NSFE can also hit this:
if|if
condition|(
name|ExceptionsHelper
operator|.
name|stackTrace
argument_list|(
name|e
argument_list|)
operator|.
name|contains
argument_list|(
literal|"org.apache.lucene.index.IndexWriter.filesExist"
argument_list|)
condition|)
block|{
name|EngineException
name|engineException
init|=
operator|new
name|EngineException
argument_list|(
name|shardId
argument_list|,
literal|"failed to commit engine"
argument_list|,
name|e
argument_list|)
decl_stmt|;
try|try
block|{
name|failEngine
argument_list|(
literal|"lucene commit failed"
argument_list|,
name|engineException
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|inner
parameter_list|)
block|{
name|engineException
operator|.
name|addSuppressed
argument_list|(
name|inner
argument_list|)
expr_stmt|;
block|}
throw|throw
name|engineException
throw|;
block|}
else|else
block|{
throw|throw
name|e
throw|;
block|}
block|}
block|}
DECL|method|ensureCanFlush
specifier|private
name|void
name|ensureCanFlush
parameter_list|()
block|{
comment|// translog recover happens after the engine is fully constructed
comment|// if we are in this stage we have to prevent flushes from this
comment|// engine otherwise we might loose documents if the flush succeeds
comment|// and the translog recover fails we we "commit" the translog on flush.
if|if
condition|(
name|pendingTranslogRecovery
operator|.
name|get
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
name|shardId
operator|.
name|toString
argument_list|()
operator|+
literal|" flushes are disabled - pending translog recovery"
argument_list|)
throw|;
block|}
block|}
DECL|method|onSettingsChanged
specifier|public
name|void
name|onSettingsChanged
parameter_list|()
block|{
name|mergeScheduler
operator|.
name|refreshConfig
argument_list|()
expr_stmt|;
comment|// config().isEnableGcDeletes() or config.getGcDeletesInMillis() may have changed:
name|maybePruneDeletedTombstones
argument_list|()
expr_stmt|;
if|if
condition|(
name|engineConfig
operator|.
name|getMaxUnsafeAutoIdTimestamp
argument_list|()
operator|==
name|Long
operator|.
name|MAX_VALUE
condition|)
block|{
comment|// this is an anti-viral settings you can only opt out for the entire index
comment|// only if a shard starts up again due to relocation or if the index is closed
comment|// the setting will be re-interpreted if it's set to true
name|this
operator|.
name|maxUnsafeAutoIdTimestamp
operator|.
name|set
argument_list|(
name|Long
operator|.
name|MAX_VALUE
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|getMergeStats
specifier|public
name|MergeStats
name|getMergeStats
parameter_list|()
block|{
return|return
name|mergeScheduler
operator|.
name|stats
argument_list|()
return|;
block|}
annotation|@
name|Override
DECL|method|getDocStats
specifier|public
name|DocsStats
name|getDocStats
parameter_list|()
block|{
specifier|final
name|int
name|numDocs
init|=
name|indexWriter
operator|.
name|numDocs
argument_list|()
decl_stmt|;
specifier|final
name|int
name|maxDoc
init|=
name|indexWriter
operator|.
name|maxDoc
argument_list|()
decl_stmt|;
return|return
operator|new
name|DocsStats
argument_list|(
name|numDocs
argument_list|,
name|maxDoc
operator|-
name|numDocs
argument_list|)
return|;
block|}
comment|/**      * Returns the number of times a version was looked up either from the index.      * Note this is only available if assertions are enabled      */
DECL|method|getNumIndexVersionsLookups
name|long
name|getNumIndexVersionsLookups
parameter_list|()
block|{
comment|// for testing
return|return
name|numIndexVersionsLookups
operator|.
name|count
argument_list|()
return|;
block|}
comment|/**      * Returns the number of times a version was looked up either from memory or from the index.      * Note this is only available if assertions are enabled      */
DECL|method|getNumVersionLookups
name|long
name|getNumVersionLookups
parameter_list|()
block|{
comment|// for testing
return|return
name|numVersionLookups
operator|.
name|count
argument_list|()
return|;
block|}
DECL|method|incrementVersionLookup
specifier|private
name|boolean
name|incrementVersionLookup
parameter_list|()
block|{
comment|// only used by asserts
name|numVersionLookups
operator|.
name|inc
argument_list|()
expr_stmt|;
return|return
literal|true
return|;
block|}
DECL|method|incrementIndexVersionLookup
specifier|private
name|boolean
name|incrementIndexVersionLookup
parameter_list|()
block|{
name|numIndexVersionsLookups
operator|.
name|inc
argument_list|()
expr_stmt|;
return|return
literal|true
return|;
block|}
comment|/**      * Returns<code>true</code> iff the index writer has any deletions either buffered in memory or      * in the index.      */
DECL|method|indexWriterHasDeletions
name|boolean
name|indexWriterHasDeletions
parameter_list|()
block|{
return|return
name|indexWriter
operator|.
name|hasDeletions
argument_list|()
return|;
block|}
annotation|@
name|Override
DECL|method|isRecovering
specifier|public
name|boolean
name|isRecovering
parameter_list|()
block|{
return|return
name|pendingTranslogRecovery
operator|.
name|get
argument_list|()
return|;
block|}
block|}
end_class

end_unit

