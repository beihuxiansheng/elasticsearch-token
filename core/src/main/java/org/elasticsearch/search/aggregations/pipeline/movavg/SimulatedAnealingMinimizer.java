begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to Elasticsearch under one or more contributor  * license agreements. See the NOTICE file distributed with  * this work for additional information regarding copyright  * ownership. Elasticsearch licenses this file to you under  * the Apache License, Version 2.0 (the "License"); you may  * not use this file except in compliance with the License.  * You may obtain a copy of the License at  *  *    http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing,  * software distributed under the License is distributed on an  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY  * KIND, either express or implied.  See the License for the  * specific language governing permissions and limitations  * under the License.  */
end_comment

begin_package
DECL|package|org.elasticsearch.search.aggregations.pipeline.movavg
package|package
name|org
operator|.
name|elasticsearch
operator|.
name|search
operator|.
name|aggregations
operator|.
name|pipeline
operator|.
name|movavg
package|;
end_package

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|EvictingQueue
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|search
operator|.
name|aggregations
operator|.
name|pipeline
operator|.
name|movavg
operator|.
name|models
operator|.
name|MovAvgModel
import|;
end_import

begin_comment
comment|/**  * A cost minimizer which will fit a MovAvgModel to the data.  *  * This optimizer uses naive simulated annealing.  Random solutions in the problem space  * are generated, compared against the last period of data, and the least absolute deviation  * is recorded as a cost.  *  * If the new cost is better than the old cost, the new coefficients are chosen.  If the new  * solution is worse, there is a temperature-dependent probability it will be randomly selected  * anyway.  This allows the algo to sample the problem space widely.  As iterations progress,  * the temperature decreases and the algorithm rejects poor solutions more regularly,  * theoretically honing in on a global minimum.  */
end_comment

begin_class
DECL|class|SimulatedAnealingMinimizer
specifier|public
class|class
name|SimulatedAnealingMinimizer
block|{
comment|/**      * Runs the simulated annealing algorithm and produces a model with new coefficients that, theoretically      * fit the data better and generalizes to future forecasts without overfitting.      *      * @param model         The MovAvgModel to be optimized for      * @param train         A training set provided to the model, which predictions will be      *                      generated from      * @param test          A test set of data to compare the predictions against and derive      *                      a cost for the model      * @return              A new, minimized model that (theoretically) better fits the data      */
DECL|method|minimize
specifier|public
specifier|static
name|MovAvgModel
name|minimize
parameter_list|(
name|MovAvgModel
name|model
parameter_list|,
name|EvictingQueue
argument_list|<
name|Double
argument_list|>
name|train
parameter_list|,
name|double
index|[]
name|test
parameter_list|)
block|{
name|double
name|temp
init|=
literal|1
decl_stmt|;
name|double
name|minTemp
init|=
literal|0.0001
decl_stmt|;
name|int
name|iterations
init|=
literal|100
decl_stmt|;
name|double
name|alpha
init|=
literal|0.9
decl_stmt|;
name|MovAvgModel
name|bestModel
init|=
name|model
decl_stmt|;
name|MovAvgModel
name|oldModel
init|=
name|model
decl_stmt|;
name|double
name|oldCost
init|=
name|cost
argument_list|(
name|model
argument_list|,
name|train
argument_list|,
name|test
argument_list|)
decl_stmt|;
name|double
name|bestCost
init|=
name|oldCost
decl_stmt|;
while|while
condition|(
name|temp
operator|>
name|minTemp
condition|)
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|iterations
condition|;
name|i
operator|++
control|)
block|{
name|MovAvgModel
name|newModel
init|=
name|oldModel
operator|.
name|neighboringModel
argument_list|()
decl_stmt|;
name|double
name|newCost
init|=
name|cost
argument_list|(
name|newModel
argument_list|,
name|train
argument_list|,
name|test
argument_list|)
decl_stmt|;
name|double
name|ap
init|=
name|acceptanceProbability
argument_list|(
name|oldCost
argument_list|,
name|newCost
argument_list|,
name|temp
argument_list|)
decl_stmt|;
if|if
condition|(
name|ap
operator|>
name|Math
operator|.
name|random
argument_list|()
condition|)
block|{
name|oldModel
operator|=
name|newModel
expr_stmt|;
name|oldCost
operator|=
name|newCost
expr_stmt|;
if|if
condition|(
name|newCost
operator|<
name|bestCost
condition|)
block|{
name|bestCost
operator|=
name|newCost
expr_stmt|;
name|bestModel
operator|=
name|newModel
expr_stmt|;
block|}
block|}
block|}
name|temp
operator|*=
name|alpha
expr_stmt|;
block|}
return|return
name|bestModel
return|;
block|}
comment|/**      * If the new cost is better than old, return 1.0.  Otherwise, return a double that increases      * as the two costs are closer to each other.      *      * @param oldCost   Old model cost      * @param newCost   New model cost      * @param temp      Current annealing temperature      * @return          The probability of accepting the new cost over the old      */
DECL|method|acceptanceProbability
specifier|private
specifier|static
name|double
name|acceptanceProbability
parameter_list|(
name|double
name|oldCost
parameter_list|,
name|double
name|newCost
parameter_list|,
name|double
name|temp
parameter_list|)
block|{
return|return
name|newCost
operator|<
name|oldCost
condition|?
literal|1.0
else|:
name|Math
operator|.
name|exp
argument_list|(
operator|-
operator|(
name|newCost
operator|-
name|oldCost
operator|)
operator|/
name|temp
argument_list|)
return|;
block|}
comment|/**      * Calculates the "cost" of a model.  E.g. when run on the training data, how closely do the  predictions      * match the test data      *      * Uses Least Absolute Differences to calculate error.  Note that this is not scale free, but seems      * to work fairly well in practice      *      * @param model     The MovAvgModel we are fitting      * @param train     A training set of data given to the model, which will then generate predictions from      * @param test      A test set of data to compare against the predictions      * @return          A cost, or error, of the model      */
DECL|method|cost
specifier|private
specifier|static
name|double
name|cost
parameter_list|(
name|MovAvgModel
name|model
parameter_list|,
name|EvictingQueue
argument_list|<
name|Double
argument_list|>
name|train
parameter_list|,
name|double
index|[]
name|test
parameter_list|)
block|{
name|double
name|error
init|=
literal|0
decl_stmt|;
name|double
index|[]
name|predictions
init|=
name|model
operator|.
name|predict
argument_list|(
name|train
argument_list|,
name|test
operator|.
name|length
argument_list|)
decl_stmt|;
assert|assert
operator|(
name|predictions
operator|.
name|length
operator|==
name|test
operator|.
name|length
operator|)
assert|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|predictions
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|error
operator|+=
name|Math
operator|.
name|abs
argument_list|(
name|test
index|[
name|i
index|]
operator|-
name|predictions
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
return|return
name|error
return|;
block|}
block|}
end_class

end_unit

