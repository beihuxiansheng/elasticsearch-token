begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to Elastic Search and Shay Banon under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership. Elastic Search licenses this  * file to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *    http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing,  * software distributed under the License is distributed on an  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY  * KIND, either express or implied.  See the License for the  * specific language governing permissions and limitations  * under the License.  */
end_comment

begin_package
DECL|package|org.elasticsearch.gateway.blobstore
package|package
name|org
operator|.
name|elasticsearch
operator|.
name|gateway
operator|.
name|blobstore
package|;
end_package

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|ExceptionsHelper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|node
operator|.
name|DiscoveryNode
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|node
operator|.
name|DiscoveryNodes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|routing
operator|.
name|*
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|routing
operator|.
name|allocation
operator|.
name|NodeAllocation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|routing
operator|.
name|allocation
operator|.
name|NodeAllocations
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|inject
operator|.
name|Inject
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|settings
operator|.
name|Settings
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|unit
operator|.
name|ByteSizeValue
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|unit
operator|.
name|TimeValue
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ConcurrentCollections
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|index
operator|.
name|gateway
operator|.
name|CommitPoint
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|index
operator|.
name|gateway
operator|.
name|blobstore
operator|.
name|BlobStoreIndexGateway
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|index
operator|.
name|service
operator|.
name|InternalIndexService
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|index
operator|.
name|shard
operator|.
name|ShardId
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|index
operator|.
name|store
operator|.
name|IndexStore
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|index
operator|.
name|store
operator|.
name|StoreFileMetaData
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|indices
operator|.
name|IndicesService
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|indices
operator|.
name|store
operator|.
name|TransportNodesListShardStoreMetaData
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|transport
operator|.
name|ConnectTransportException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ConcurrentMap
import|;
end_import

begin_comment
comment|/**  * @author kimchy (shay.banon)  */
end_comment

begin_class
DECL|class|BlobReuseExistingNodeAllocation
specifier|public
class|class
name|BlobReuseExistingNodeAllocation
extends|extends
name|NodeAllocation
block|{
DECL|field|indicesService
specifier|private
specifier|final
name|IndicesService
name|indicesService
decl_stmt|;
DECL|field|transportNodesListShardStoreMetaData
specifier|private
specifier|final
name|TransportNodesListShardStoreMetaData
name|transportNodesListShardStoreMetaData
decl_stmt|;
DECL|field|listTimeout
specifier|private
specifier|final
name|TimeValue
name|listTimeout
decl_stmt|;
DECL|field|cachedCommitPoints
specifier|private
specifier|final
name|ConcurrentMap
argument_list|<
name|ShardId
argument_list|,
name|CommitPoint
argument_list|>
name|cachedCommitPoints
init|=
name|ConcurrentCollections
operator|.
name|newConcurrentMap
argument_list|()
decl_stmt|;
DECL|method|BlobReuseExistingNodeAllocation
annotation|@
name|Inject
specifier|public
name|BlobReuseExistingNodeAllocation
parameter_list|(
name|Settings
name|settings
parameter_list|,
name|IndicesService
name|indicesService
parameter_list|,
name|TransportNodesListShardStoreMetaData
name|transportNodesListShardStoreMetaData
parameter_list|)
block|{
name|super
argument_list|(
name|settings
argument_list|)
expr_stmt|;
name|this
operator|.
name|indicesService
operator|=
name|indicesService
expr_stmt|;
name|this
operator|.
name|transportNodesListShardStoreMetaData
operator|=
name|transportNodesListShardStoreMetaData
expr_stmt|;
name|this
operator|.
name|listTimeout
operator|=
name|componentSettings
operator|.
name|getAsTime
argument_list|(
literal|"list_timeout"
argument_list|,
name|TimeValue
operator|.
name|timeValueSeconds
argument_list|(
literal|60
argument_list|)
argument_list|)
expr_stmt|;
block|}
DECL|method|allocate
annotation|@
name|Override
specifier|public
name|boolean
name|allocate
parameter_list|(
name|NodeAllocations
name|nodeAllocations
parameter_list|,
name|RoutingNodes
name|routingNodes
parameter_list|,
name|DiscoveryNodes
name|nodes
parameter_list|)
block|{
name|boolean
name|changed
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|nodes
operator|.
name|dataNodes
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return
name|changed
return|;
block|}
comment|// clean cached commit points for primaries that are already active
for|for
control|(
name|ShardId
name|shardId
range|:
name|cachedCommitPoints
operator|.
name|keySet
argument_list|()
control|)
block|{
name|IndexRoutingTable
name|indexRoutingTable
init|=
name|routingNodes
operator|.
name|routingTable
argument_list|()
operator|.
name|index
argument_list|(
name|shardId
operator|.
name|index
argument_list|()
operator|.
name|name
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|indexRoutingTable
operator|==
literal|null
condition|)
block|{
name|cachedCommitPoints
operator|.
name|remove
argument_list|(
name|shardId
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|ShardRouting
name|primaryShardRouting
init|=
name|indexRoutingTable
operator|.
name|shard
argument_list|(
name|shardId
operator|.
name|id
argument_list|()
argument_list|)
operator|.
name|primaryShard
argument_list|()
decl_stmt|;
if|if
condition|(
name|primaryShardRouting
operator|.
name|active
argument_list|()
condition|)
block|{
name|cachedCommitPoints
operator|.
name|remove
argument_list|(
name|shardId
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|!
name|routingNodes
operator|.
name|hasUnassigned
argument_list|()
condition|)
block|{
return|return
name|changed
return|;
block|}
name|Iterator
argument_list|<
name|MutableShardRouting
argument_list|>
name|unassignedIterator
init|=
name|routingNodes
operator|.
name|unassigned
argument_list|()
operator|.
name|iterator
argument_list|()
decl_stmt|;
while|while
condition|(
name|unassignedIterator
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|MutableShardRouting
name|shard
init|=
name|unassignedIterator
operator|.
name|next
argument_list|()
decl_stmt|;
name|InternalIndexService
name|indexService
init|=
operator|(
name|InternalIndexService
operator|)
name|indicesService
operator|.
name|indexService
argument_list|(
name|shard
operator|.
name|index
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|indexService
operator|==
literal|null
condition|)
block|{
continue|continue;
block|}
comment|// if the store is not persistent, it makes no sense to test for special allocation
if|if
condition|(
operator|!
name|indexService
operator|.
name|store
argument_list|()
operator|.
name|persistent
argument_list|()
condition|)
block|{
continue|continue;
block|}
name|TransportNodesListShardStoreMetaData
operator|.
name|NodesStoreFilesMetaData
name|nodesStoreFilesMetaData
init|=
name|transportNodesListShardStoreMetaData
operator|.
name|list
argument_list|(
name|shard
operator|.
name|shardId
argument_list|()
argument_list|,
literal|false
argument_list|,
name|nodes
operator|.
name|dataNodes
argument_list|()
operator|.
name|keySet
argument_list|()
argument_list|,
name|listTimeout
argument_list|)
operator|.
name|actionGet
argument_list|()
decl_stmt|;
if|if
condition|(
name|logger
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
if|if
condition|(
name|nodesStoreFilesMetaData
operator|.
name|failures
argument_list|()
operator|.
name|length
operator|>
literal|0
condition|)
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|(
name|shard
operator|+
literal|": failures when trying to list stores on nodes:"
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|nodesStoreFilesMetaData
operator|.
name|failures
argument_list|()
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|Throwable
name|cause
init|=
name|ExceptionsHelper
operator|.
name|unwrapCause
argument_list|(
name|nodesStoreFilesMetaData
operator|.
name|failures
argument_list|()
index|[
name|i
index|]
argument_list|)
decl_stmt|;
if|if
condition|(
name|cause
operator|instanceof
name|ConnectTransportException
condition|)
block|{
continue|continue;
block|}
name|sb
operator|.
name|append
argument_list|(
literal|"\n    -> "
argument_list|)
operator|.
name|append
argument_list|(
name|nodesStoreFilesMetaData
operator|.
name|failures
argument_list|()
index|[
name|i
index|]
operator|.
name|getDetailedMessage
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|logger
operator|.
name|debug
argument_list|(
name|sb
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
name|long
name|lastSizeMatched
init|=
literal|0
decl_stmt|;
name|DiscoveryNode
name|lastDiscoNodeMatched
init|=
literal|null
decl_stmt|;
name|RoutingNode
name|lastNodeMatched
init|=
literal|null
decl_stmt|;
for|for
control|(
name|TransportNodesListShardStoreMetaData
operator|.
name|NodeStoreFilesMetaData
name|nodeStoreFilesMetaData
range|:
name|nodesStoreFilesMetaData
control|)
block|{
name|DiscoveryNode
name|discoNode
init|=
name|nodeStoreFilesMetaData
operator|.
name|node
argument_list|()
decl_stmt|;
name|logger
operator|.
name|trace
argument_list|(
literal|"{}: checking node [{}]"
argument_list|,
name|shard
argument_list|,
name|discoNode
argument_list|)
expr_stmt|;
name|IndexStore
operator|.
name|StoreFilesMetaData
name|storeFilesMetaData
init|=
name|nodeStoreFilesMetaData
operator|.
name|storeFilesMetaData
argument_list|()
decl_stmt|;
if|if
condition|(
name|storeFilesMetaData
operator|==
literal|null
condition|)
block|{
comment|// already allocated on that node...
continue|continue;
block|}
name|RoutingNode
name|node
init|=
name|routingNodes
operator|.
name|node
argument_list|(
name|discoNode
operator|.
name|id
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|node
operator|==
literal|null
condition|)
block|{
continue|continue;
block|}
comment|// check if we can allocate on that node...
comment|// we only check for NO, since if this node is THROTTLING and it has enough "same data"
comment|// then we will try and assign it next time
if|if
condition|(
name|nodeAllocations
operator|.
name|canAllocate
argument_list|(
name|shard
argument_list|,
name|node
argument_list|,
name|routingNodes
argument_list|)
operator|==
name|Decision
operator|.
name|NO
condition|)
block|{
continue|continue;
block|}
comment|// if it is already allocated, we can't assign to it...
if|if
condition|(
name|storeFilesMetaData
operator|.
name|allocated
argument_list|()
condition|)
block|{
continue|continue;
block|}
comment|// if its a primary, it will be recovered from the gateway, find one that is closet to it
if|if
condition|(
name|shard
operator|.
name|primary
argument_list|()
operator|&&
name|indexService
operator|.
name|gateway
argument_list|()
operator|instanceof
name|BlobStoreIndexGateway
condition|)
block|{
name|BlobStoreIndexGateway
name|indexGateway
init|=
operator|(
name|BlobStoreIndexGateway
operator|)
name|indexService
operator|.
name|gateway
argument_list|()
decl_stmt|;
try|try
block|{
name|CommitPoint
name|commitPoint
init|=
name|cachedCommitPoints
operator|.
name|get
argument_list|(
name|shard
operator|.
name|shardId
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|commitPoint
operator|==
literal|null
condition|)
block|{
name|commitPoint
operator|=
name|indexGateway
operator|.
name|findCommitPoint
argument_list|(
name|shard
operator|.
name|id
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|commitPoint
operator|!=
literal|null
condition|)
block|{
name|cachedCommitPoints
operator|.
name|put
argument_list|(
name|shard
operator|.
name|shardId
argument_list|()
argument_list|,
name|commitPoint
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|cachedCommitPoints
operator|.
name|put
argument_list|(
name|shard
operator|.
name|shardId
argument_list|()
argument_list|,
name|CommitPoint
operator|.
name|NULL
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|commitPoint
operator|==
name|CommitPoint
operator|.
name|NULL
condition|)
block|{
name|commitPoint
operator|=
literal|null
expr_stmt|;
block|}
if|if
condition|(
name|commitPoint
operator|==
literal|null
condition|)
block|{
break|break;
block|}
if|if
condition|(
name|logger
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|(
name|shard
operator|+
literal|": checking for pre_allocation (gateway) on node "
operator|+
name|discoNode
operator|+
literal|"\n"
argument_list|)
decl_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|"    gateway_files:\n"
argument_list|)
expr_stmt|;
for|for
control|(
name|CommitPoint
operator|.
name|FileInfo
name|fileInfo
range|:
name|commitPoint
operator|.
name|indexFiles
argument_list|()
control|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|"        ["
argument_list|)
operator|.
name|append
argument_list|(
name|fileInfo
operator|.
name|name
argument_list|()
argument_list|)
operator|.
name|append
argument_list|(
literal|"]/["
argument_list|)
operator|.
name|append
argument_list|(
name|fileInfo
operator|.
name|physicalName
argument_list|()
argument_list|)
operator|.
name|append
argument_list|(
literal|"], size ["
argument_list|)
operator|.
name|append
argument_list|(
operator|new
name|ByteSizeValue
argument_list|(
name|fileInfo
operator|.
name|length
argument_list|()
argument_list|)
argument_list|)
operator|.
name|append
argument_list|(
literal|"]\n"
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|append
argument_list|(
literal|"    node_files:\n"
argument_list|)
expr_stmt|;
for|for
control|(
name|StoreFileMetaData
name|md
range|:
name|storeFilesMetaData
control|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|"        ["
argument_list|)
operator|.
name|append
argument_list|(
name|md
operator|.
name|name
argument_list|()
argument_list|)
operator|.
name|append
argument_list|(
literal|"], size ["
argument_list|)
operator|.
name|append
argument_list|(
operator|new
name|ByteSizeValue
argument_list|(
name|md
operator|.
name|length
argument_list|()
argument_list|)
argument_list|)
operator|.
name|append
argument_list|(
literal|"]\n"
argument_list|)
expr_stmt|;
block|}
name|logger
operator|.
name|trace
argument_list|(
name|sb
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|long
name|sizeMatched
init|=
literal|0
decl_stmt|;
for|for
control|(
name|StoreFileMetaData
name|storeFileMetaData
range|:
name|storeFilesMetaData
control|)
block|{
name|CommitPoint
operator|.
name|FileInfo
name|fileInfo
init|=
name|commitPoint
operator|.
name|findPhysicalIndexFile
argument_list|(
name|storeFileMetaData
operator|.
name|name
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|fileInfo
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|fileInfo
operator|.
name|length
argument_list|()
operator|==
name|storeFileMetaData
operator|.
name|length
argument_list|()
condition|)
block|{
name|logger
operator|.
name|trace
argument_list|(
literal|"{}: [{}] reusing file since it exists on remote node and on gateway with size [{}]"
argument_list|,
name|shard
argument_list|,
name|storeFileMetaData
operator|.
name|name
argument_list|()
argument_list|,
operator|new
name|ByteSizeValue
argument_list|(
name|storeFileMetaData
operator|.
name|length
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|sizeMatched
operator|+=
name|storeFileMetaData
operator|.
name|length
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|logger
operator|.
name|trace
argument_list|(
literal|"{}: [{}] ignore file since it exists on remote node and on gateway but has different size, remote node [{}], gateway [{}]"
argument_list|,
name|shard
argument_list|,
name|storeFileMetaData
operator|.
name|name
argument_list|()
argument_list|,
name|storeFileMetaData
operator|.
name|length
argument_list|()
argument_list|,
name|fileInfo
operator|.
name|length
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|logger
operator|.
name|trace
argument_list|(
literal|"{}: [{}] exists on remote node, does not exists on gateway"
argument_list|,
name|shard
argument_list|,
name|storeFileMetaData
operator|.
name|name
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|sizeMatched
operator|>
name|lastSizeMatched
condition|)
block|{
name|lastSizeMatched
operator|=
name|sizeMatched
expr_stmt|;
name|lastDiscoNodeMatched
operator|=
name|discoNode
expr_stmt|;
name|lastNodeMatched
operator|=
name|node
expr_stmt|;
name|logger
operator|.
name|trace
argument_list|(
literal|"{}: node elected for pre_allocation [{}], total_size_matched [{}]"
argument_list|,
name|shard
argument_list|,
name|discoNode
argument_list|,
operator|new
name|ByteSizeValue
argument_list|(
name|sizeMatched
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|logger
operator|.
name|trace
argument_list|(
literal|"{}: node ignored for pre_allocation [{}], total_size_matched [{}] smaller than last_size_matched [{}]"
argument_list|,
name|shard
argument_list|,
name|discoNode
argument_list|,
operator|new
name|ByteSizeValue
argument_list|(
name|sizeMatched
argument_list|)
argument_list|,
operator|new
name|ByteSizeValue
argument_list|(
name|lastSizeMatched
argument_list|)
argument_list|)
expr_stmt|;
block|}
continue|continue;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
comment|// failed, log and try and allocate based on size
name|logger
operator|.
name|debug
argument_list|(
literal|"Failed to guess allocation of primary based on gateway for "
operator|+
name|shard
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
comment|// if its backup, see if there is a primary that *is* allocated, and try and assign a location that is closest to it
comment|// note, since we replicate operations, this might not be the same (different flush intervals)
if|if
condition|(
operator|!
name|shard
operator|.
name|primary
argument_list|()
condition|)
block|{
name|MutableShardRouting
name|primaryShard
init|=
name|routingNodes
operator|.
name|findPrimaryForReplica
argument_list|(
name|shard
argument_list|)
decl_stmt|;
if|if
condition|(
name|primaryShard
operator|!=
literal|null
operator|&&
name|primaryShard
operator|.
name|active
argument_list|()
condition|)
block|{
name|TransportNodesListShardStoreMetaData
operator|.
name|NodeStoreFilesMetaData
name|primaryNodeStoreFileMetaData
init|=
name|nodesStoreFilesMetaData
operator|.
name|nodesMap
argument_list|()
operator|.
name|get
argument_list|(
name|primaryShard
operator|.
name|currentNodeId
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|primaryNodeStoreFileMetaData
operator|!=
literal|null
operator|&&
name|primaryNodeStoreFileMetaData
operator|.
name|storeFilesMetaData
argument_list|()
operator|!=
literal|null
operator|&&
name|primaryNodeStoreFileMetaData
operator|.
name|storeFilesMetaData
argument_list|()
operator|.
name|allocated
argument_list|()
condition|)
block|{
name|long
name|sizeMatched
init|=
literal|0
decl_stmt|;
name|IndexStore
operator|.
name|StoreFilesMetaData
name|primaryStoreFilesMetaData
init|=
name|primaryNodeStoreFileMetaData
operator|.
name|storeFilesMetaData
argument_list|()
decl_stmt|;
for|for
control|(
name|StoreFileMetaData
name|storeFileMetaData
range|:
name|storeFilesMetaData
control|)
block|{
if|if
condition|(
name|primaryStoreFilesMetaData
operator|.
name|fileExists
argument_list|(
name|storeFileMetaData
operator|.
name|name
argument_list|()
argument_list|)
operator|&&
name|primaryStoreFilesMetaData
operator|.
name|file
argument_list|(
name|storeFileMetaData
operator|.
name|name
argument_list|()
argument_list|)
operator|.
name|length
argument_list|()
operator|==
name|storeFileMetaData
operator|.
name|length
argument_list|()
condition|)
block|{
name|sizeMatched
operator|+=
name|storeFileMetaData
operator|.
name|length
argument_list|()
expr_stmt|;
block|}
block|}
if|if
condition|(
name|sizeMatched
operator|>
name|lastSizeMatched
condition|)
block|{
name|lastSizeMatched
operator|=
name|sizeMatched
expr_stmt|;
name|lastDiscoNodeMatched
operator|=
name|discoNode
expr_stmt|;
name|lastNodeMatched
operator|=
name|node
expr_stmt|;
block|}
continue|continue;
block|}
block|}
block|}
block|}
if|if
condition|(
name|lastNodeMatched
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|nodeAllocations
operator|.
name|canAllocate
argument_list|(
name|shard
argument_list|,
name|lastNodeMatched
argument_list|,
name|routingNodes
argument_list|)
operator|==
name|NodeAllocation
operator|.
name|Decision
operator|.
name|THROTTLE
condition|)
block|{
if|if
condition|(
name|logger
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"[{}][{}]: throttling allocation [{}] to [{}] in order to reuse its unallocated persistent store with total_size [{}]"
argument_list|,
name|shard
operator|.
name|index
argument_list|()
argument_list|,
name|shard
operator|.
name|id
argument_list|()
argument_list|,
name|shard
argument_list|,
name|lastDiscoNodeMatched
argument_list|,
operator|new
name|ByteSizeValue
argument_list|(
name|lastSizeMatched
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// we are throttling this, but we have enough to allocate to this node, ignore it for now
name|unassignedIterator
operator|.
name|remove
argument_list|()
expr_stmt|;
name|routingNodes
operator|.
name|ignoredUnassigned
argument_list|()
operator|.
name|add
argument_list|(
name|shard
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|logger
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"[{}][{}]: allocating [{}] to [{}] in order to reuse its unallocated persistent store with total_size [{}]"
argument_list|,
name|shard
operator|.
name|index
argument_list|()
argument_list|,
name|shard
operator|.
name|id
argument_list|()
argument_list|,
name|shard
argument_list|,
name|lastDiscoNodeMatched
argument_list|,
operator|new
name|ByteSizeValue
argument_list|(
name|lastSizeMatched
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// we found a match
name|changed
operator|=
literal|true
expr_stmt|;
name|lastNodeMatched
operator|.
name|add
argument_list|(
name|shard
argument_list|)
expr_stmt|;
name|unassignedIterator
operator|.
name|remove
argument_list|()
expr_stmt|;
block|}
block|}
block|}
return|return
name|changed
return|;
block|}
DECL|method|canAllocate
annotation|@
name|Override
specifier|public
name|Decision
name|canAllocate
parameter_list|(
name|ShardRouting
name|shardRouting
parameter_list|,
name|RoutingNode
name|node
parameter_list|,
name|RoutingNodes
name|routingNodes
parameter_list|)
block|{
return|return
name|Decision
operator|.
name|YES
return|;
block|}
block|}
end_class

end_unit

