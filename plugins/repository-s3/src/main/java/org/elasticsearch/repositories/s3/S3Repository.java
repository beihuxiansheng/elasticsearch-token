begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to Elasticsearch under one or more contributor  * license agreements. See the NOTICE file distributed with  * this work for additional information regarding copyright  * ownership. Elasticsearch licenses this file to you under  * the Apache License, Version 2.0 (the "License"); you may  * not use this file except in compliance with the License.  * You may obtain a copy of the License at  *  *    http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing,  * software distributed under the License is distributed on an  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY  * KIND, either express or implied.  See the License for the  * specific language governing permissions and limitations  * under the License.  */
end_comment

begin_package
DECL|package|org.elasticsearch.repositories.s3
package|package
name|org
operator|.
name|elasticsearch
operator|.
name|repositories
operator|.
name|s3
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|AmazonS3
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|metadata
operator|.
name|RepositoryMetaData
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|Strings
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|blobstore
operator|.
name|BlobPath
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|blobstore
operator|.
name|BlobStore
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|settings
operator|.
name|SecureSetting
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|settings
operator|.
name|SecureString
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|settings
operator|.
name|Setting
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|settings
operator|.
name|Settings
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|unit
operator|.
name|ByteSizeUnit
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|unit
operator|.
name|ByteSizeValue
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|xcontent
operator|.
name|NamedXContentRegistry
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|monitor
operator|.
name|jvm
operator|.
name|JvmInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|repositories
operator|.
name|RepositoryException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|repositories
operator|.
name|blobstore
operator|.
name|BlobStoreRepository
import|;
end_import

begin_comment
comment|/**  * Shared file system implementation of the BlobStoreRepository  *<p>  * Shared file system repository supports the following settings  *<dl>  *<dt>{@code bucket}</dt><dd>S3 bucket</dd>  *<dt>{@code base_path}</dt><dd>Specifies the path within bucket to repository data. Defaults to root directory.</dd>  *<dt>{@code concurrent_streams}</dt><dd>Number of concurrent read/write stream (per repository on each node). Defaults to 5.</dd>  *<dt>{@code chunk_size}</dt><dd>Large file can be divided into chunks. This parameter specifies the chunk size. Defaults to not chucked.</dd>  *<dt>{@code compress}</dt><dd>If set to true metadata files will be stored compressed. Defaults to false.</dd>  *</dl>  */
end_comment

begin_class
DECL|class|S3Repository
class|class
name|S3Repository
extends|extends
name|BlobStoreRepository
block|{
DECL|field|TYPE
specifier|static
specifier|final
name|String
name|TYPE
init|=
literal|"s3"
decl_stmt|;
comment|/** The access key to authenticate with s3. This setting is insecure because cluster settings are stored in cluster state */
DECL|field|ACCESS_KEY_SETTING
specifier|static
specifier|final
name|Setting
argument_list|<
name|SecureString
argument_list|>
name|ACCESS_KEY_SETTING
init|=
name|SecureSetting
operator|.
name|insecureString
argument_list|(
literal|"access_key"
argument_list|)
decl_stmt|;
comment|/** The secret key to authenticate with s3. This setting is insecure because cluster settings are stored in cluster state */
DECL|field|SECRET_KEY_SETTING
specifier|static
specifier|final
name|Setting
argument_list|<
name|SecureString
argument_list|>
name|SECRET_KEY_SETTING
init|=
name|SecureSetting
operator|.
name|insecureString
argument_list|(
literal|"secret_key"
argument_list|)
decl_stmt|;
comment|/**      * Default is to use 100MB (S3 defaults) for heaps above 2GB and 5% of      * the available memory for smaller heaps.      */
DECL|field|DEFAULT_BUFFER_SIZE
specifier|private
specifier|static
specifier|final
name|ByteSizeValue
name|DEFAULT_BUFFER_SIZE
init|=
operator|new
name|ByteSizeValue
argument_list|(
name|Math
operator|.
name|max
argument_list|(
name|ByteSizeUnit
operator|.
name|MB
operator|.
name|toBytes
argument_list|(
literal|5
argument_list|)
argument_list|,
comment|// minimum value
name|Math
operator|.
name|min
argument_list|(
name|ByteSizeUnit
operator|.
name|MB
operator|.
name|toBytes
argument_list|(
literal|100
argument_list|)
argument_list|,
name|JvmInfo
operator|.
name|jvmInfo
argument_list|()
operator|.
name|getMem
argument_list|()
operator|.
name|getHeapMax
argument_list|()
operator|.
name|getBytes
argument_list|()
operator|/
literal|20
argument_list|)
argument_list|)
argument_list|,
name|ByteSizeUnit
operator|.
name|BYTES
argument_list|)
decl_stmt|;
DECL|field|BUCKET_SETTING
specifier|static
specifier|final
name|Setting
argument_list|<
name|String
argument_list|>
name|BUCKET_SETTING
init|=
name|Setting
operator|.
name|simpleString
argument_list|(
literal|"bucket"
argument_list|)
decl_stmt|;
comment|/**      * When set to true files are encrypted on server side using AES256 algorithm.      * Defaults to false.      */
DECL|field|SERVER_SIDE_ENCRYPTION_SETTING
specifier|static
specifier|final
name|Setting
argument_list|<
name|Boolean
argument_list|>
name|SERVER_SIDE_ENCRYPTION_SETTING
init|=
name|Setting
operator|.
name|boolSetting
argument_list|(
literal|"server_side_encryption"
argument_list|,
literal|false
argument_list|)
decl_stmt|;
comment|/**      * Minimum threshold below which the chunk is uploaded using a single request. Beyond this threshold,      * the S3 repository will use the AWS Multipart Upload API to split the chunk into several parts, each of buffer_size length, and      * to upload each part in its own request. Note that setting a buffer size lower than 5mb is not allowed since it will prevents the      * use of the Multipart API and may result in upload errors. Defaults to the minimum between 100MB and 5% of the heap size.      */
DECL|field|BUFFER_SIZE_SETTING
specifier|static
specifier|final
name|Setting
argument_list|<
name|ByteSizeValue
argument_list|>
name|BUFFER_SIZE_SETTING
init|=
name|Setting
operator|.
name|byteSizeSetting
argument_list|(
literal|"buffer_size"
argument_list|,
name|DEFAULT_BUFFER_SIZE
argument_list|,
operator|new
name|ByteSizeValue
argument_list|(
literal|5
argument_list|,
name|ByteSizeUnit
operator|.
name|MB
argument_list|)
argument_list|,
operator|new
name|ByteSizeValue
argument_list|(
literal|5
argument_list|,
name|ByteSizeUnit
operator|.
name|TB
argument_list|)
argument_list|)
decl_stmt|;
comment|/**      * Big files can be broken down into chunks during snapshotting if needed. Defaults to 1g.      */
DECL|field|CHUNK_SIZE_SETTING
specifier|static
specifier|final
name|Setting
argument_list|<
name|ByteSizeValue
argument_list|>
name|CHUNK_SIZE_SETTING
init|=
name|Setting
operator|.
name|byteSizeSetting
argument_list|(
literal|"chunk_size"
argument_list|,
operator|new
name|ByteSizeValue
argument_list|(
literal|1
argument_list|,
name|ByteSizeUnit
operator|.
name|GB
argument_list|)
argument_list|,
operator|new
name|ByteSizeValue
argument_list|(
literal|5
argument_list|,
name|ByteSizeUnit
operator|.
name|MB
argument_list|)
argument_list|,
operator|new
name|ByteSizeValue
argument_list|(
literal|5
argument_list|,
name|ByteSizeUnit
operator|.
name|TB
argument_list|)
argument_list|)
decl_stmt|;
comment|/**      * When set to true metadata files are stored in compressed format. This setting doesnât affect index      * files that are already compressed by default. Defaults to false.      */
DECL|field|COMPRESS_SETTING
specifier|static
specifier|final
name|Setting
argument_list|<
name|Boolean
argument_list|>
name|COMPRESS_SETTING
init|=
name|Setting
operator|.
name|boolSetting
argument_list|(
literal|"compress"
argument_list|,
literal|false
argument_list|)
decl_stmt|;
comment|/**      * Sets the S3 storage class type for the backup files. Values may be standard, reduced_redundancy,      * standard_ia. Defaults to standard.      */
DECL|field|STORAGE_CLASS_SETTING
specifier|static
specifier|final
name|Setting
argument_list|<
name|String
argument_list|>
name|STORAGE_CLASS_SETTING
init|=
name|Setting
operator|.
name|simpleString
argument_list|(
literal|"storage_class"
argument_list|)
decl_stmt|;
comment|/**      * The S3 repository supports all S3 canned ACLs : private, public-read, public-read-write,      * authenticated-read, log-delivery-write, bucket-owner-read, bucket-owner-full-control. Defaults to private.      */
DECL|field|CANNED_ACL_SETTING
specifier|static
specifier|final
name|Setting
argument_list|<
name|String
argument_list|>
name|CANNED_ACL_SETTING
init|=
name|Setting
operator|.
name|simpleString
argument_list|(
literal|"canned_acl"
argument_list|)
decl_stmt|;
comment|/**      * Specifies the path within bucket to repository data. Defaults to root directory.      */
DECL|field|BASE_PATH_SETTING
specifier|static
specifier|final
name|Setting
argument_list|<
name|String
argument_list|>
name|BASE_PATH_SETTING
init|=
name|Setting
operator|.
name|simpleString
argument_list|(
literal|"base_path"
argument_list|)
decl_stmt|;
DECL|field|blobStore
specifier|private
specifier|final
name|S3BlobStore
name|blobStore
decl_stmt|;
DECL|field|basePath
specifier|private
specifier|final
name|BlobPath
name|basePath
decl_stmt|;
DECL|field|chunkSize
specifier|private
name|ByteSizeValue
name|chunkSize
decl_stmt|;
DECL|field|compress
specifier|private
name|boolean
name|compress
decl_stmt|;
comment|/**      * Constructs an s3 backed repository      */
DECL|method|S3Repository
name|S3Repository
parameter_list|(
name|RepositoryMetaData
name|metadata
parameter_list|,
name|Settings
name|settings
parameter_list|,
name|NamedXContentRegistry
name|namedXContentRegistry
parameter_list|,
name|AwsS3Service
name|s3Service
parameter_list|)
throws|throws
name|IOException
block|{
name|super
argument_list|(
name|metadata
argument_list|,
name|settings
argument_list|,
name|namedXContentRegistry
argument_list|)
expr_stmt|;
name|String
name|bucket
init|=
name|BUCKET_SETTING
operator|.
name|get
argument_list|(
name|metadata
operator|.
name|settings
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|bucket
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|RepositoryException
argument_list|(
name|metadata
operator|.
name|name
argument_list|()
argument_list|,
literal|"No bucket defined for s3 gateway"
argument_list|)
throw|;
block|}
name|boolean
name|serverSideEncryption
init|=
name|SERVER_SIDE_ENCRYPTION_SETTING
operator|.
name|get
argument_list|(
name|metadata
operator|.
name|settings
argument_list|()
argument_list|)
decl_stmt|;
name|ByteSizeValue
name|bufferSize
init|=
name|BUFFER_SIZE_SETTING
operator|.
name|get
argument_list|(
name|metadata
operator|.
name|settings
argument_list|()
argument_list|)
decl_stmt|;
name|this
operator|.
name|chunkSize
operator|=
name|CHUNK_SIZE_SETTING
operator|.
name|get
argument_list|(
name|metadata
operator|.
name|settings
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|compress
operator|=
name|COMPRESS_SETTING
operator|.
name|get
argument_list|(
name|metadata
operator|.
name|settings
argument_list|()
argument_list|)
expr_stmt|;
comment|// We make sure that chunkSize is bigger or equal than/to bufferSize
if|if
condition|(
name|this
operator|.
name|chunkSize
operator|.
name|getBytes
argument_list|()
operator|<
name|bufferSize
operator|.
name|getBytes
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|RepositoryException
argument_list|(
name|metadata
operator|.
name|name
argument_list|()
argument_list|,
name|CHUNK_SIZE_SETTING
operator|.
name|getKey
argument_list|()
operator|+
literal|" ("
operator|+
name|this
operator|.
name|chunkSize
operator|+
literal|") can't be lower than "
operator|+
name|BUFFER_SIZE_SETTING
operator|.
name|getKey
argument_list|()
operator|+
literal|" ("
operator|+
name|bufferSize
operator|+
literal|")."
argument_list|)
throw|;
block|}
comment|// Parse and validate the user's S3 Storage Class setting
name|String
name|storageClass
init|=
name|STORAGE_CLASS_SETTING
operator|.
name|get
argument_list|(
name|metadata
operator|.
name|settings
argument_list|()
argument_list|)
decl_stmt|;
name|String
name|cannedACL
init|=
name|CANNED_ACL_SETTING
operator|.
name|get
argument_list|(
name|metadata
operator|.
name|settings
argument_list|()
argument_list|)
decl_stmt|;
name|logger
operator|.
name|debug
argument_list|(
literal|"using bucket [{}], chunk_size [{}], server_side_encryption [{}], "
operator|+
literal|"buffer_size [{}], cannedACL [{}], storageClass [{}]"
argument_list|,
name|bucket
argument_list|,
name|chunkSize
argument_list|,
name|serverSideEncryption
argument_list|,
name|bufferSize
argument_list|,
name|cannedACL
argument_list|,
name|storageClass
argument_list|)
expr_stmt|;
name|AmazonS3
name|client
init|=
name|s3Service
operator|.
name|client
argument_list|(
name|metadata
operator|.
name|settings
argument_list|()
argument_list|)
decl_stmt|;
name|blobStore
operator|=
operator|new
name|S3BlobStore
argument_list|(
name|settings
argument_list|,
name|client
argument_list|,
name|bucket
argument_list|,
name|serverSideEncryption
argument_list|,
name|bufferSize
argument_list|,
name|cannedACL
argument_list|,
name|storageClass
argument_list|)
expr_stmt|;
name|String
name|basePath
init|=
name|BASE_PATH_SETTING
operator|.
name|get
argument_list|(
name|metadata
operator|.
name|settings
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|Strings
operator|.
name|hasLength
argument_list|(
name|basePath
argument_list|)
condition|)
block|{
name|this
operator|.
name|basePath
operator|=
operator|new
name|BlobPath
argument_list|()
operator|.
name|add
argument_list|(
name|basePath
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|basePath
operator|=
name|BlobPath
operator|.
name|cleanPath
argument_list|()
expr_stmt|;
block|}
block|}
annotation|@
name|Override
DECL|method|blobStore
specifier|protected
name|BlobStore
name|blobStore
parameter_list|()
block|{
return|return
name|blobStore
return|;
block|}
annotation|@
name|Override
DECL|method|basePath
specifier|protected
name|BlobPath
name|basePath
parameter_list|()
block|{
return|return
name|basePath
return|;
block|}
annotation|@
name|Override
DECL|method|isCompress
specifier|protected
name|boolean
name|isCompress
parameter_list|()
block|{
return|return
name|compress
return|;
block|}
annotation|@
name|Override
DECL|method|chunkSize
specifier|protected
name|ByteSizeValue
name|chunkSize
parameter_list|()
block|{
return|return
name|chunkSize
return|;
block|}
block|}
end_class

end_unit

