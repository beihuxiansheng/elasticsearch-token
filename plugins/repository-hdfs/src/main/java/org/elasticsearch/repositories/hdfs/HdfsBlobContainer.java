begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to Elasticsearch under one or more contributor  * license agreements. See the NOTICE file distributed with  * this work for additional information regarding copyright  * ownership. Elasticsearch licenses this file to you under  * the Apache License, Version 2.0 (the "License"); you may  * not use this file except in compliance with the License.  * You may obtain a copy of the License at  *  *    http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing,  * software distributed under the License is distributed on an  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY  * KIND, either express or implied.  See the License for the  * specific language governing permissions and limitations  * under the License.  */
end_comment

begin_package
DECL|package|org.elasticsearch.repositories.hdfs
package|package
name|org
operator|.
name|elasticsearch
operator|.
name|repositories
operator|.
name|hdfs
package|;
end_package

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|CreateFlag
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataOutputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Options
operator|.
name|CreateOpts
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|Nullable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|blobstore
operator|.
name|BlobMetaData
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|blobstore
operator|.
name|BlobPath
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|blobstore
operator|.
name|support
operator|.
name|AbstractBlobContainer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|blobstore
operator|.
name|support
operator|.
name|PlainBlobMetaData
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|repositories
operator|.
name|hdfs
operator|.
name|HdfsBlobStore
operator|.
name|Operation
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FilterInputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|file
operator|.
name|FileAlreadyExistsException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|file
operator|.
name|NoSuchFileException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|security
operator|.
name|AccessController
import|;
end_import

begin_import
import|import
name|java
operator|.
name|security
operator|.
name|PrivilegedActionException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|security
operator|.
name|PrivilegedExceptionAction
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|EnumSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|LinkedHashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_class
DECL|class|HdfsBlobContainer
specifier|final
class|class
name|HdfsBlobContainer
extends|extends
name|AbstractBlobContainer
block|{
DECL|field|store
specifier|private
specifier|final
name|HdfsBlobStore
name|store
decl_stmt|;
DECL|field|path
specifier|private
specifier|final
name|Path
name|path
decl_stmt|;
DECL|field|bufferSize
specifier|private
specifier|final
name|int
name|bufferSize
decl_stmt|;
DECL|method|HdfsBlobContainer
name|HdfsBlobContainer
parameter_list|(
name|BlobPath
name|blobPath
parameter_list|,
name|HdfsBlobStore
name|store
parameter_list|,
name|Path
name|path
parameter_list|,
name|int
name|bufferSize
parameter_list|)
block|{
name|super
argument_list|(
name|blobPath
argument_list|)
expr_stmt|;
name|this
operator|.
name|store
operator|=
name|store
expr_stmt|;
name|this
operator|.
name|path
operator|=
name|path
expr_stmt|;
name|this
operator|.
name|bufferSize
operator|=
name|bufferSize
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|blobExists
specifier|public
name|boolean
name|blobExists
parameter_list|(
name|String
name|blobName
parameter_list|)
block|{
try|try
block|{
return|return
name|store
operator|.
name|execute
argument_list|(
name|fileContext
lambda|->
name|fileContext
operator|.
name|util
argument_list|()
operator|.
name|exists
argument_list|(
operator|new
name|Path
argument_list|(
name|path
argument_list|,
name|blobName
argument_list|)
argument_list|)
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
return|return
literal|false
return|;
block|}
block|}
annotation|@
name|Override
DECL|method|deleteBlob
specifier|public
name|void
name|deleteBlob
parameter_list|(
name|String
name|blobName
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|blobExists
argument_list|(
name|blobName
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|NoSuchFileException
argument_list|(
literal|"Blob ["
operator|+
name|blobName
operator|+
literal|"] does not exist"
argument_list|)
throw|;
block|}
name|store
operator|.
name|execute
argument_list|(
name|fileContext
lambda|->
name|fileContext
operator|.
name|delete
argument_list|(
operator|new
name|Path
argument_list|(
name|path
argument_list|,
name|blobName
argument_list|)
argument_list|,
literal|true
argument_list|)
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|move
specifier|public
name|void
name|move
parameter_list|(
name|String
name|sourceBlobName
parameter_list|,
name|String
name|targetBlobName
parameter_list|)
throws|throws
name|IOException
block|{
name|store
operator|.
name|execute
argument_list|(
operator|(
name|Operation
argument_list|<
name|Void
argument_list|>
operator|)
name|fileContext
lambda|->
block|{
name|fileContext
operator|.
name|rename
argument_list|(
operator|new
name|Path
argument_list|(
name|path
argument_list|,
name|sourceBlobName
argument_list|)
argument_list|,
operator|new
name|Path
argument_list|(
name|path
argument_list|,
name|targetBlobName
argument_list|)
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|readBlob
specifier|public
name|InputStream
name|readBlob
parameter_list|(
name|String
name|blobName
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|blobExists
argument_list|(
name|blobName
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|NoSuchFileException
argument_list|(
literal|"Blob ["
operator|+
name|blobName
operator|+
literal|"] does not exist"
argument_list|)
throw|;
block|}
comment|// FSDataInputStream does buffering internally
comment|// FSDataInputStream can open connections on read() or skip() so we wrap in
comment|// HDFSPrivilegedInputSteam which will ensure that underlying methods will
comment|// be called with the proper privileges.
return|return
name|store
operator|.
name|execute
argument_list|(
name|fileContext
lambda|->
operator|new
name|HDFSPrivilegedInputSteam
argument_list|(
name|fileContext
operator|.
name|open
argument_list|(
operator|new
name|Path
argument_list|(
name|path
argument_list|,
name|blobName
argument_list|)
argument_list|,
name|bufferSize
argument_list|)
argument_list|)
argument_list|)
return|;
block|}
annotation|@
name|Override
DECL|method|writeBlob
specifier|public
name|void
name|writeBlob
parameter_list|(
name|String
name|blobName
parameter_list|,
name|InputStream
name|inputStream
parameter_list|,
name|long
name|blobSize
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|blobExists
argument_list|(
name|blobName
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|FileAlreadyExistsException
argument_list|(
literal|"blob ["
operator|+
name|blobName
operator|+
literal|"] already exists, cannot overwrite"
argument_list|)
throw|;
block|}
name|store
operator|.
name|execute
argument_list|(
operator|(
name|Operation
argument_list|<
name|Void
argument_list|>
operator|)
name|fileContext
lambda|->
block|{
name|Path
name|blob
init|=
operator|new
name|Path
argument_list|(
name|path
argument_list|,
name|blobName
argument_list|)
decl_stmt|;
comment|// we pass CREATE, which means it fails if a blob already exists.
comment|// NOTE: this behavior differs from FSBlobContainer, which passes TRUNCATE_EXISTING
comment|// that should be fixed there, no need to bring truncation into this, give the user an error.
name|EnumSet
argument_list|<
name|CreateFlag
argument_list|>
name|flags
init|=
name|EnumSet
operator|.
name|of
argument_list|(
name|CreateFlag
operator|.
name|CREATE
argument_list|,
name|CreateFlag
operator|.
name|SYNC_BLOCK
argument_list|)
decl_stmt|;
name|CreateOpts
index|[]
name|opts
init|=
block|{
name|CreateOpts
operator|.
name|bufferSize
argument_list|(
name|bufferSize
argument_list|)
block|}
empty_stmt|;
try|try
init|(
name|FSDataOutputStream
name|stream
init|=
name|fileContext
operator|.
name|create
argument_list|(
name|blob
argument_list|,
name|flags
argument_list|,
name|opts
argument_list|)
init|)
block|{
name|int
name|bytesRead
decl_stmt|;
name|byte
index|[]
name|buffer
init|=
operator|new
name|byte
index|[
name|bufferSize
index|]
decl_stmt|;
while|while
condition|(
operator|(
name|bytesRead
operator|=
name|inputStream
operator|.
name|read
argument_list|(
name|buffer
argument_list|)
operator|)
operator|!=
operator|-
literal|1
condition|)
block|{
name|stream
operator|.
name|write
argument_list|(
name|buffer
argument_list|,
literal|0
argument_list|,
name|bytesRead
argument_list|)
expr_stmt|;
comment|//  For safety we also hsync each write as well, because of its docs:
comment|//  SYNC_BLOCK - to force closed blocks to the disk device
comment|// "In addition Syncable.hsync() should be called after each write,
comment|//  if true synchronous behavior is required"
name|stream
operator|.
name|hsync
argument_list|()
expr_stmt|;
block|}
block|}
return|return
literal|null
return|;
block|}
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|listBlobsByPrefix
specifier|public
name|Map
argument_list|<
name|String
argument_list|,
name|BlobMetaData
argument_list|>
name|listBlobsByPrefix
parameter_list|(
annotation|@
name|Nullable
specifier|final
name|String
name|prefix
parameter_list|)
throws|throws
name|IOException
block|{
name|FileStatus
index|[]
name|files
init|=
name|store
operator|.
name|execute
argument_list|(
name|fileContext
lambda|->
operator|(
name|fileContext
operator|.
name|util
argument_list|()
operator|.
name|listStatus
argument_list|(
name|path
argument_list|,
name|path
lambda|->
name|prefix
operator|==
literal|null
operator|||
name|path
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
name|prefix
argument_list|)
argument_list|)
operator|)
argument_list|)
decl_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|BlobMetaData
argument_list|>
name|map
init|=
operator|new
name|LinkedHashMap
argument_list|<
name|String
argument_list|,
name|BlobMetaData
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|FileStatus
name|file
range|:
name|files
control|)
block|{
name|map
operator|.
name|put
argument_list|(
name|file
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|,
operator|new
name|PlainBlobMetaData
argument_list|(
name|file
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|,
name|file
operator|.
name|getLen
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|Collections
operator|.
name|unmodifiableMap
argument_list|(
name|map
argument_list|)
return|;
block|}
annotation|@
name|Override
DECL|method|listBlobs
specifier|public
name|Map
argument_list|<
name|String
argument_list|,
name|BlobMetaData
argument_list|>
name|listBlobs
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|listBlobsByPrefix
argument_list|(
literal|null
argument_list|)
return|;
block|}
comment|/**      * Exists to wrap underlying InputStream methods that might make socket connections in      * doPrivileged blocks. This is due to the way that hdfs client libraries might open      * socket connections when you are reading from an InputStream.      */
DECL|class|HDFSPrivilegedInputSteam
specifier|private
specifier|static
class|class
name|HDFSPrivilegedInputSteam
extends|extends
name|FilterInputStream
block|{
DECL|method|HDFSPrivilegedInputSteam
name|HDFSPrivilegedInputSteam
parameter_list|(
name|InputStream
name|in
parameter_list|)
block|{
name|super
argument_list|(
name|in
argument_list|)
expr_stmt|;
block|}
DECL|method|read
specifier|public
name|int
name|read
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|doPrivilegedOrThrow
argument_list|(
name|in
operator|::
name|read
argument_list|)
return|;
block|}
DECL|method|read
specifier|public
name|int
name|read
parameter_list|(
name|byte
name|b
index|[]
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|doPrivilegedOrThrow
argument_list|(
parameter_list|()
lambda|->
name|in
operator|.
name|read
argument_list|(
name|b
argument_list|)
argument_list|)
return|;
block|}
DECL|method|read
specifier|public
name|int
name|read
parameter_list|(
name|byte
name|b
index|[]
parameter_list|,
name|int
name|off
parameter_list|,
name|int
name|len
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|doPrivilegedOrThrow
argument_list|(
parameter_list|()
lambda|->
name|in
operator|.
name|read
argument_list|(
name|b
argument_list|,
name|off
argument_list|,
name|len
argument_list|)
argument_list|)
return|;
block|}
DECL|method|skip
specifier|public
name|long
name|skip
parameter_list|(
name|long
name|n
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|doPrivilegedOrThrow
argument_list|(
parameter_list|()
lambda|->
name|in
operator|.
name|skip
argument_list|(
name|n
argument_list|)
argument_list|)
return|;
block|}
DECL|method|available
specifier|public
name|int
name|available
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|doPrivilegedOrThrow
argument_list|(
parameter_list|()
lambda|->
name|in
operator|.
name|available
argument_list|()
argument_list|)
return|;
block|}
DECL|method|reset
specifier|public
specifier|synchronized
name|void
name|reset
parameter_list|()
throws|throws
name|IOException
block|{
name|doPrivilegedOrThrow
argument_list|(
parameter_list|()
lambda|->
block|{
name|in
operator|.
name|reset
argument_list|()
expr_stmt|;
return|return
literal|null
return|;
block|}
argument_list|)
expr_stmt|;
block|}
DECL|method|doPrivilegedOrThrow
specifier|private
specifier|static
parameter_list|<
name|T
parameter_list|>
name|T
name|doPrivilegedOrThrow
parameter_list|(
name|PrivilegedExceptionAction
argument_list|<
name|T
argument_list|>
name|action
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
return|return
name|AccessController
operator|.
name|doPrivileged
argument_list|(
name|action
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|PrivilegedActionException
name|e
parameter_list|)
block|{
throw|throw
operator|(
name|IOException
operator|)
name|e
operator|.
name|getCause
argument_list|()
throw|;
block|}
block|}
block|}
block|}
end_class

end_unit

