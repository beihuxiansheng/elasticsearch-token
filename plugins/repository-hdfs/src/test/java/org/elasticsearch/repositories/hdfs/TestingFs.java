begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to Elasticsearch under one or more contributor  * license agreements. See the NOTICE file distributed with  * this work for additional information regarding copyright  * ownership. Elasticsearch licenses this file to you under  * the Apache License, Version 2.0 (the "License"); you may  * not use this file except in compliance with the License.  * You may obtain a copy of the License at  *  *    http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing,  * software distributed under the License is distributed on an  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY  * KIND, either express or implied.  See the License for the  * specific language governing permissions and limitations  * under the License.  */
end_comment

begin_package
DECL|package|org.elasticsearch.repositories.hdfs
package|package
name|org
operator|.
name|elasticsearch
operator|.
name|repositories
operator|.
name|hdfs
package|;
end_package

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|DelegateToFileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|RawLocalFileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|permission
operator|.
name|FsPermission
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|lucene
operator|.
name|util
operator|.
name|LuceneTestCase
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileNotFoundException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URI
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URISyntaxException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|file
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|file
operator|.
name|attribute
operator|.
name|BasicFileAttributes
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|file
operator|.
name|spi
operator|.
name|FileSystemProvider
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|file
operator|.
name|Files
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|file
operator|.
name|NoSuchFileException
import|;
end_import

begin_comment
comment|/**  * Extends LFS to improve some operations to keep the security permissions at  * bay. In particular it never tries to execute!  */
end_comment

begin_class
DECL|class|TestingFs
specifier|public
class|class
name|TestingFs
extends|extends
name|DelegateToFileSystem
block|{
comment|// wrap hadoop rawlocalfilesystem to behave less crazy
DECL|method|wrap
specifier|static
name|RawLocalFileSystem
name|wrap
parameter_list|(
specifier|final
name|Path
name|base
parameter_list|)
block|{
specifier|final
name|FileSystemProvider
name|baseProvider
init|=
name|base
operator|.
name|getFileSystem
argument_list|()
operator|.
name|provider
argument_list|()
decl_stmt|;
return|return
operator|new
name|RawLocalFileSystem
argument_list|()
block|{
specifier|private
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
name|box
parameter_list|(
name|Path
name|path
parameter_list|)
block|{
return|return
operator|new
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
argument_list|(
name|path
operator|.
name|toUri
argument_list|()
argument_list|)
return|;
block|}
specifier|private
name|Path
name|unbox
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
name|path
parameter_list|)
block|{
return|return
name|baseProvider
operator|.
name|getPath
argument_list|(
name|path
operator|.
name|toUri
argument_list|()
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|protected
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
name|getInitialWorkingDirectory
parameter_list|()
block|{
return|return
name|box
argument_list|(
name|base
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|setPermission
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
name|path
parameter_list|,
name|FsPermission
name|permission
parameter_list|)
block|{
comment|// no execution, thank you very much!
block|}
comment|// pretend we don't support symlinks (which causes hadoop to want to do crazy things),
comment|// returning the boolean does not seem to really help, link-related operations are still called.
annotation|@
name|Override
specifier|public
name|boolean
name|supportsSymlinks
parameter_list|()
block|{
return|return
literal|false
return|;
block|}
annotation|@
name|Override
specifier|public
name|FileStatus
name|getFileLinkStatus
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
name|path
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|getFileStatus
argument_list|(
name|path
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
name|getLinkTarget
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
name|path
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|path
return|;
block|}
annotation|@
name|Override
specifier|public
name|FileStatus
name|getFileStatus
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
name|path
parameter_list|)
throws|throws
name|IOException
block|{
name|BasicFileAttributes
name|attributes
decl_stmt|;
try|try
block|{
name|attributes
operator|=
name|Files
operator|.
name|readAttributes
argument_list|(
name|unbox
argument_list|(
name|path
argument_list|)
argument_list|,
name|BasicFileAttributes
operator|.
name|class
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NoSuchFileException
name|e
parameter_list|)
block|{
comment|// unfortunately, specific exceptions are not guaranteed. don't wrap hadoop over a zip filesystem or something.
name|FileNotFoundException
name|fnfe
init|=
operator|new
name|FileNotFoundException
argument_list|(
literal|"File "
operator|+
name|path
operator|+
literal|" does not exist"
argument_list|)
decl_stmt|;
name|fnfe
operator|.
name|initCause
argument_list|(
name|e
argument_list|)
expr_stmt|;
throw|throw
name|fnfe
throw|;
block|}
comment|// we set similar values to raw local filesystem, except we are never a symlink
name|long
name|length
init|=
name|attributes
operator|.
name|size
argument_list|()
decl_stmt|;
name|boolean
name|isDir
init|=
name|attributes
operator|.
name|isDirectory
argument_list|()
decl_stmt|;
name|int
name|blockReplication
init|=
literal|1
decl_stmt|;
name|long
name|blockSize
init|=
name|getDefaultBlockSize
argument_list|(
name|path
argument_list|)
decl_stmt|;
name|long
name|modificationTime
init|=
name|attributes
operator|.
name|creationTime
argument_list|()
operator|.
name|toMillis
argument_list|()
decl_stmt|;
return|return
operator|new
name|FileStatus
argument_list|(
name|length
argument_list|,
name|isDir
argument_list|,
name|blockReplication
argument_list|,
name|blockSize
argument_list|,
name|modificationTime
argument_list|,
name|path
argument_list|)
return|;
block|}
block|}
return|;
block|}
DECL|method|TestingFs
specifier|public
name|TestingFs
parameter_list|(
name|URI
name|uri
parameter_list|,
name|Configuration
name|configuration
parameter_list|)
throws|throws
name|URISyntaxException
throws|,
name|IOException
block|{
name|super
argument_list|(
name|URI
operator|.
name|create
argument_list|(
literal|"file:///"
argument_list|)
argument_list|,
name|wrap
argument_list|(
name|LuceneTestCase
operator|.
name|createTempDir
argument_list|()
argument_list|)
argument_list|,
name|configuration
argument_list|,
literal|"file"
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|checkPath
specifier|public
name|void
name|checkPath
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
name|path
parameter_list|)
block|{
comment|// we do evil stuff, we admit it.
block|}
block|}
end_class

end_unit

