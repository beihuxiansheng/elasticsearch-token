begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to Elasticsearch under one or more contributor  * license agreements. See the NOTICE file distributed with  * this work for additional information regarding copyright  * ownership. Elasticsearch licenses this file to you under  * the Apache License, Version 2.0 (the "License"); you may  * not use this file except in compliance with the License.  * You may obtain a copy of the License at  *  *    http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing,  * software distributed under the License is distributed on an  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY  * KIND, either express or implied.  See the License for the  * specific language governing permissions and limitations  * under the License.  */
end_comment

begin_package
DECL|package|org.elasticsearch.gateway
package|package
name|org
operator|.
name|elasticsearch
operator|.
name|gateway
package|;
end_package

begin_import
import|import
name|com
operator|.
name|carrotsearch
operator|.
name|hppc
operator|.
name|ObjectLongOpenHashMap
import|;
end_import

begin_import
import|import
name|com
operator|.
name|carrotsearch
operator|.
name|hppc
operator|.
name|ObjectOpenHashSet
import|;
end_import

begin_import
import|import
name|com
operator|.
name|carrotsearch
operator|.
name|hppc
operator|.
name|cursors
operator|.
name|ObjectCursor
import|;
end_import

begin_import
import|import
name|com
operator|.
name|carrotsearch
operator|.
name|hppc
operator|.
name|predicates
operator|.
name|ObjectPredicate
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Maps
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Sets
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|ExceptionsHelper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|action
operator|.
name|FailedNodeException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|metadata
operator|.
name|IndexMetaData
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|metadata
operator|.
name|MetaData
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|node
operator|.
name|DiscoveryNode
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|node
operator|.
name|DiscoveryNodes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|routing
operator|.
name|MutableShardRouting
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|routing
operator|.
name|RoutingNode
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|routing
operator|.
name|RoutingNodes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|routing
operator|.
name|ShardRouting
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|routing
operator|.
name|allocation
operator|.
name|FailedRerouteAllocation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|routing
operator|.
name|allocation
operator|.
name|RoutingAllocation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|routing
operator|.
name|allocation
operator|.
name|StartedRerouteAllocation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|cluster
operator|.
name|routing
operator|.
name|allocation
operator|.
name|decider
operator|.
name|Decision
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|component
operator|.
name|AbstractComponent
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|inject
operator|.
name|Inject
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|settings
operator|.
name|Settings
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|unit
operator|.
name|ByteSizeValue
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|unit
operator|.
name|TimeValue
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|common
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ConcurrentCollections
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|index
operator|.
name|shard
operator|.
name|ShardId
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|index
operator|.
name|store
operator|.
name|StoreFileMetaData
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|indices
operator|.
name|store
operator|.
name|TransportNodesListShardStoreMetaData
import|;
end_import

begin_import
import|import
name|org
operator|.
name|elasticsearch
operator|.
name|transport
operator|.
name|ConnectTransportException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ConcurrentMap
import|;
end_import

begin_comment
comment|/**  *  */
end_comment

begin_class
DECL|class|GatewayAllocator
specifier|public
class|class
name|GatewayAllocator
extends|extends
name|AbstractComponent
block|{
DECL|field|INDEX_RECOVERY_INITIAL_SHARDS
specifier|public
specifier|static
specifier|final
name|String
name|INDEX_RECOVERY_INITIAL_SHARDS
init|=
literal|"index.recovery.initial_shards"
decl_stmt|;
DECL|field|listGatewayStartedShards
specifier|private
specifier|final
name|TransportNodesListGatewayStartedShards
name|listGatewayStartedShards
decl_stmt|;
DECL|field|listShardStoreMetaData
specifier|private
specifier|final
name|TransportNodesListShardStoreMetaData
name|listShardStoreMetaData
decl_stmt|;
DECL|field|cachedStores
specifier|private
specifier|final
name|ConcurrentMap
argument_list|<
name|ShardId
argument_list|,
name|Map
argument_list|<
name|DiscoveryNode
argument_list|,
name|TransportNodesListShardStoreMetaData
operator|.
name|StoreFilesMetaData
argument_list|>
argument_list|>
name|cachedStores
init|=
name|ConcurrentCollections
operator|.
name|newConcurrentMap
argument_list|()
decl_stmt|;
DECL|field|cachedShardsState
specifier|private
specifier|final
name|ConcurrentMap
argument_list|<
name|ShardId
argument_list|,
name|ObjectLongOpenHashMap
argument_list|<
name|DiscoveryNode
argument_list|>
argument_list|>
name|cachedShardsState
init|=
name|ConcurrentCollections
operator|.
name|newConcurrentMap
argument_list|()
decl_stmt|;
DECL|field|listTimeout
specifier|private
specifier|final
name|TimeValue
name|listTimeout
decl_stmt|;
DECL|field|initialShards
specifier|private
specifier|final
name|String
name|initialShards
decl_stmt|;
annotation|@
name|Inject
DECL|method|GatewayAllocator
specifier|public
name|GatewayAllocator
parameter_list|(
name|Settings
name|settings
parameter_list|,
name|TransportNodesListGatewayStartedShards
name|listGatewayStartedShards
parameter_list|,
name|TransportNodesListShardStoreMetaData
name|listShardStoreMetaData
parameter_list|)
block|{
name|super
argument_list|(
name|settings
argument_list|)
expr_stmt|;
name|this
operator|.
name|listGatewayStartedShards
operator|=
name|listGatewayStartedShards
expr_stmt|;
name|this
operator|.
name|listShardStoreMetaData
operator|=
name|listShardStoreMetaData
expr_stmt|;
name|this
operator|.
name|listTimeout
operator|=
name|settings
operator|.
name|getAsTime
argument_list|(
literal|"gateway.list_timeout"
argument_list|,
name|settings
operator|.
name|getAsTime
argument_list|(
literal|"gateway.local.list_timeout"
argument_list|,
name|TimeValue
operator|.
name|timeValueSeconds
argument_list|(
literal|30
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|this
operator|.
name|initialShards
operator|=
name|settings
operator|.
name|get
argument_list|(
literal|"gateway.initial_shards"
argument_list|,
name|settings
operator|.
name|get
argument_list|(
literal|"gateway.local.initial_shards"
argument_list|,
literal|"quorum"
argument_list|)
argument_list|)
expr_stmt|;
name|logger
operator|.
name|debug
argument_list|(
literal|"using initial_shards [{}], list_timeout [{}]"
argument_list|,
name|initialShards
argument_list|,
name|listTimeout
argument_list|)
expr_stmt|;
block|}
DECL|method|applyStartedShards
specifier|public
name|void
name|applyStartedShards
parameter_list|(
name|StartedRerouteAllocation
name|allocation
parameter_list|)
block|{
for|for
control|(
name|ShardRouting
name|shardRouting
range|:
name|allocation
operator|.
name|startedShards
argument_list|()
control|)
block|{
name|cachedStores
operator|.
name|remove
argument_list|(
name|shardRouting
operator|.
name|shardId
argument_list|()
argument_list|)
expr_stmt|;
name|cachedShardsState
operator|.
name|remove
argument_list|(
name|shardRouting
operator|.
name|shardId
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|applyFailedShards
specifier|public
name|void
name|applyFailedShards
parameter_list|(
name|FailedRerouteAllocation
name|allocation
parameter_list|)
block|{
for|for
control|(
name|ShardRouting
name|failedShard
range|:
name|allocation
operator|.
name|failedShards
argument_list|()
control|)
block|{
name|cachedStores
operator|.
name|remove
argument_list|(
name|failedShard
operator|.
name|shardId
argument_list|()
argument_list|)
expr_stmt|;
name|cachedShardsState
operator|.
name|remove
argument_list|(
name|failedShard
operator|.
name|shardId
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|allocateUnassigned
specifier|public
name|boolean
name|allocateUnassigned
parameter_list|(
name|RoutingAllocation
name|allocation
parameter_list|)
block|{
name|boolean
name|changed
init|=
literal|false
decl_stmt|;
name|DiscoveryNodes
name|nodes
init|=
name|allocation
operator|.
name|nodes
argument_list|()
decl_stmt|;
name|RoutingNodes
name|routingNodes
init|=
name|allocation
operator|.
name|routingNodes
argument_list|()
decl_stmt|;
comment|// First, handle primaries, they must find a place to be allocated on here
name|MetaData
name|metaData
init|=
name|routingNodes
operator|.
name|metaData
argument_list|()
decl_stmt|;
name|Iterator
argument_list|<
name|MutableShardRouting
argument_list|>
name|unassignedIterator
init|=
name|routingNodes
operator|.
name|unassigned
argument_list|()
operator|.
name|iterator
argument_list|()
decl_stmt|;
while|while
condition|(
name|unassignedIterator
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|MutableShardRouting
name|shard
init|=
name|unassignedIterator
operator|.
name|next
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|shard
operator|.
name|primary
argument_list|()
condition|)
block|{
continue|continue;
block|}
comment|// this is an API allocation, ignore since we know there is no data...
if|if
condition|(
operator|!
name|routingNodes
operator|.
name|routingTable
argument_list|()
operator|.
name|index
argument_list|(
name|shard
operator|.
name|index
argument_list|()
argument_list|)
operator|.
name|shard
argument_list|(
name|shard
operator|.
name|id
argument_list|()
argument_list|)
operator|.
name|primaryAllocatedPostApi
argument_list|()
condition|)
block|{
continue|continue;
block|}
name|ObjectLongOpenHashMap
argument_list|<
name|DiscoveryNode
argument_list|>
name|nodesState
init|=
name|buildShardStates
argument_list|(
name|nodes
argument_list|,
name|shard
argument_list|,
name|metaData
operator|.
name|index
argument_list|(
name|shard
operator|.
name|index
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
name|int
name|numberOfAllocationsFound
init|=
literal|0
decl_stmt|;
name|long
name|highestVersion
init|=
operator|-
literal|1
decl_stmt|;
name|Set
argument_list|<
name|DiscoveryNode
argument_list|>
name|nodesWithHighestVersion
init|=
name|Sets
operator|.
name|newHashSet
argument_list|()
decl_stmt|;
specifier|final
name|boolean
index|[]
name|states
init|=
name|nodesState
operator|.
name|allocated
decl_stmt|;
specifier|final
name|Object
index|[]
name|keys
init|=
name|nodesState
operator|.
name|keys
decl_stmt|;
specifier|final
name|long
index|[]
name|values
init|=
name|nodesState
operator|.
name|values
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|states
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
operator|!
name|states
index|[
name|i
index|]
condition|)
block|{
continue|continue;
block|}
name|DiscoveryNode
name|node
init|=
operator|(
name|DiscoveryNode
operator|)
name|keys
index|[
name|i
index|]
decl_stmt|;
name|long
name|version
init|=
name|values
index|[
name|i
index|]
decl_stmt|;
comment|// since we don't check in NO allocation, we need to double check here
if|if
condition|(
name|allocation
operator|.
name|shouldIgnoreShardForNode
argument_list|(
name|shard
operator|.
name|shardId
argument_list|()
argument_list|,
name|node
operator|.
name|id
argument_list|()
argument_list|)
condition|)
block|{
continue|continue;
block|}
if|if
condition|(
name|version
operator|!=
operator|-
literal|1
condition|)
block|{
name|numberOfAllocationsFound
operator|++
expr_stmt|;
if|if
condition|(
name|highestVersion
operator|==
operator|-
literal|1
condition|)
block|{
name|nodesWithHighestVersion
operator|.
name|add
argument_list|(
name|node
argument_list|)
expr_stmt|;
name|highestVersion
operator|=
name|version
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|version
operator|>
name|highestVersion
condition|)
block|{
name|nodesWithHighestVersion
operator|.
name|clear
argument_list|()
expr_stmt|;
name|nodesWithHighestVersion
operator|.
name|add
argument_list|(
name|node
argument_list|)
expr_stmt|;
name|highestVersion
operator|=
name|version
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|version
operator|==
name|highestVersion
condition|)
block|{
name|nodesWithHighestVersion
operator|.
name|add
argument_list|(
name|node
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
comment|// check if the counts meets the minimum set
name|int
name|requiredAllocation
init|=
literal|1
decl_stmt|;
comment|// if we restore from a repository one copy is more then enough
if|if
condition|(
name|shard
operator|.
name|restoreSource
argument_list|()
operator|==
literal|null
condition|)
block|{
try|try
block|{
name|IndexMetaData
name|indexMetaData
init|=
name|routingNodes
operator|.
name|metaData
argument_list|()
operator|.
name|index
argument_list|(
name|shard
operator|.
name|index
argument_list|()
argument_list|)
decl_stmt|;
name|String
name|initialShards
init|=
name|indexMetaData
operator|.
name|settings
argument_list|()
operator|.
name|get
argument_list|(
name|INDEX_RECOVERY_INITIAL_SHARDS
argument_list|,
name|settings
operator|.
name|get
argument_list|(
name|INDEX_RECOVERY_INITIAL_SHARDS
argument_list|,
name|this
operator|.
name|initialShards
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
literal|"quorum"
operator|.
name|equals
argument_list|(
name|initialShards
argument_list|)
condition|)
block|{
if|if
condition|(
name|indexMetaData
operator|.
name|numberOfReplicas
argument_list|()
operator|>
literal|1
condition|)
block|{
name|requiredAllocation
operator|=
operator|(
operator|(
literal|1
operator|+
name|indexMetaData
operator|.
name|numberOfReplicas
argument_list|()
operator|)
operator|/
literal|2
operator|)
operator|+
literal|1
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
literal|"quorum-1"
operator|.
name|equals
argument_list|(
name|initialShards
argument_list|)
operator|||
literal|"half"
operator|.
name|equals
argument_list|(
name|initialShards
argument_list|)
condition|)
block|{
if|if
condition|(
name|indexMetaData
operator|.
name|numberOfReplicas
argument_list|()
operator|>
literal|2
condition|)
block|{
name|requiredAllocation
operator|=
operator|(
operator|(
literal|1
operator|+
name|indexMetaData
operator|.
name|numberOfReplicas
argument_list|()
operator|)
operator|/
literal|2
operator|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
literal|"one"
operator|.
name|equals
argument_list|(
name|initialShards
argument_list|)
condition|)
block|{
name|requiredAllocation
operator|=
literal|1
expr_stmt|;
block|}
elseif|else
if|if
condition|(
literal|"full"
operator|.
name|equals
argument_list|(
name|initialShards
argument_list|)
operator|||
literal|"all"
operator|.
name|equals
argument_list|(
name|initialShards
argument_list|)
condition|)
block|{
name|requiredAllocation
operator|=
name|indexMetaData
operator|.
name|numberOfReplicas
argument_list|()
operator|+
literal|1
expr_stmt|;
block|}
elseif|else
if|if
condition|(
literal|"full-1"
operator|.
name|equals
argument_list|(
name|initialShards
argument_list|)
operator|||
literal|"all-1"
operator|.
name|equals
argument_list|(
name|initialShards
argument_list|)
condition|)
block|{
if|if
condition|(
name|indexMetaData
operator|.
name|numberOfReplicas
argument_list|()
operator|>
literal|1
condition|)
block|{
name|requiredAllocation
operator|=
name|indexMetaData
operator|.
name|numberOfReplicas
argument_list|()
expr_stmt|;
block|}
block|}
else|else
block|{
name|requiredAllocation
operator|=
name|Integer
operator|.
name|parseInt
argument_list|(
name|initialShards
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|logger
operator|.
name|warn
argument_list|(
literal|"[{}][{}] failed to derived initial_shards from value {}, ignore allocation for {}"
argument_list|,
name|shard
operator|.
name|index
argument_list|()
argument_list|,
name|shard
operator|.
name|id
argument_list|()
argument_list|,
name|initialShards
argument_list|,
name|shard
argument_list|)
expr_stmt|;
block|}
block|}
comment|// not enough found for this shard, continue...
if|if
condition|(
name|numberOfAllocationsFound
operator|<
name|requiredAllocation
condition|)
block|{
comment|// if we are restoring this shard we still can allocate
if|if
condition|(
name|shard
operator|.
name|restoreSource
argument_list|()
operator|==
literal|null
condition|)
block|{
comment|// we can't really allocate, so ignore it and continue
name|unassignedIterator
operator|.
name|remove
argument_list|()
expr_stmt|;
name|routingNodes
operator|.
name|ignoredUnassigned
argument_list|()
operator|.
name|add
argument_list|(
name|shard
argument_list|)
expr_stmt|;
if|if
condition|(
name|logger
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"[{}][{}]: not allocating, number_of_allocated_shards_found [{}], required_number [{}]"
argument_list|,
name|shard
operator|.
name|index
argument_list|()
argument_list|,
name|shard
operator|.
name|id
argument_list|()
argument_list|,
name|numberOfAllocationsFound
argument_list|,
name|requiredAllocation
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|logger
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"[{}][{}]: missing local data, will restore from [{}]"
argument_list|,
name|shard
operator|.
name|index
argument_list|()
argument_list|,
name|shard
operator|.
name|id
argument_list|()
argument_list|,
name|shard
operator|.
name|restoreSource
argument_list|()
argument_list|)
expr_stmt|;
block|}
continue|continue;
block|}
name|Set
argument_list|<
name|DiscoveryNode
argument_list|>
name|throttledNodes
init|=
name|Sets
operator|.
name|newHashSet
argument_list|()
decl_stmt|;
name|Set
argument_list|<
name|DiscoveryNode
argument_list|>
name|noNodes
init|=
name|Sets
operator|.
name|newHashSet
argument_list|()
decl_stmt|;
for|for
control|(
name|DiscoveryNode
name|discoNode
range|:
name|nodesWithHighestVersion
control|)
block|{
name|RoutingNode
name|node
init|=
name|routingNodes
operator|.
name|node
argument_list|(
name|discoNode
operator|.
name|id
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|node
operator|==
literal|null
condition|)
block|{
continue|continue;
block|}
name|Decision
name|decision
init|=
name|allocation
operator|.
name|deciders
argument_list|()
operator|.
name|canAllocate
argument_list|(
name|shard
argument_list|,
name|node
argument_list|,
name|allocation
argument_list|)
decl_stmt|;
if|if
condition|(
name|decision
operator|.
name|type
argument_list|()
operator|==
name|Decision
operator|.
name|Type
operator|.
name|THROTTLE
condition|)
block|{
name|throttledNodes
operator|.
name|add
argument_list|(
name|discoNode
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|decision
operator|.
name|type
argument_list|()
operator|==
name|Decision
operator|.
name|Type
operator|.
name|NO
condition|)
block|{
name|noNodes
operator|.
name|add
argument_list|(
name|discoNode
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|logger
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"[{}][{}]: allocating [{}] to [{}] on primary allocation"
argument_list|,
name|shard
operator|.
name|index
argument_list|()
argument_list|,
name|shard
operator|.
name|id
argument_list|()
argument_list|,
name|shard
argument_list|,
name|discoNode
argument_list|)
expr_stmt|;
block|}
comment|// we found a match
name|changed
operator|=
literal|true
expr_stmt|;
comment|// make sure we create one with the version from the recovered state
name|allocation
operator|.
name|routingNodes
argument_list|()
operator|.
name|assign
argument_list|(
operator|new
name|MutableShardRouting
argument_list|(
name|shard
argument_list|,
name|highestVersion
argument_list|)
argument_list|,
name|node
operator|.
name|nodeId
argument_list|()
argument_list|)
expr_stmt|;
name|unassignedIterator
operator|.
name|remove
argument_list|()
expr_stmt|;
comment|// found a node, so no throttling, no "no", and break out of the loop
name|throttledNodes
operator|.
name|clear
argument_list|()
expr_stmt|;
name|noNodes
operator|.
name|clear
argument_list|()
expr_stmt|;
break|break;
block|}
block|}
if|if
condition|(
name|throttledNodes
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// if we have a node that we "can't" allocate to, force allocation, since this is our master data!
if|if
condition|(
operator|!
name|noNodes
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|DiscoveryNode
name|discoNode
init|=
name|noNodes
operator|.
name|iterator
argument_list|()
operator|.
name|next
argument_list|()
decl_stmt|;
name|RoutingNode
name|node
init|=
name|routingNodes
operator|.
name|node
argument_list|(
name|discoNode
operator|.
name|id
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|logger
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"[{}][{}]: forcing allocating [{}] to [{}] on primary allocation"
argument_list|,
name|shard
operator|.
name|index
argument_list|()
argument_list|,
name|shard
operator|.
name|id
argument_list|()
argument_list|,
name|shard
argument_list|,
name|discoNode
argument_list|)
expr_stmt|;
block|}
comment|// we found a match
name|changed
operator|=
literal|true
expr_stmt|;
comment|// make sure we create one with the version from the recovered state
name|allocation
operator|.
name|routingNodes
argument_list|()
operator|.
name|assign
argument_list|(
operator|new
name|MutableShardRouting
argument_list|(
name|shard
argument_list|,
name|highestVersion
argument_list|)
argument_list|,
name|node
operator|.
name|nodeId
argument_list|()
argument_list|)
expr_stmt|;
name|unassignedIterator
operator|.
name|remove
argument_list|()
expr_stmt|;
block|}
block|}
else|else
block|{
if|if
condition|(
name|logger
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"[{}][{}]: throttling allocation [{}] to [{}] on primary allocation"
argument_list|,
name|shard
operator|.
name|index
argument_list|()
argument_list|,
name|shard
operator|.
name|id
argument_list|()
argument_list|,
name|shard
argument_list|,
name|throttledNodes
argument_list|)
expr_stmt|;
block|}
comment|// we are throttling this, but we have enough to allocate to this node, ignore it for now
name|unassignedIterator
operator|.
name|remove
argument_list|()
expr_stmt|;
name|routingNodes
operator|.
name|ignoredUnassigned
argument_list|()
operator|.
name|add
argument_list|(
name|shard
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|!
name|routingNodes
operator|.
name|hasUnassigned
argument_list|()
condition|)
block|{
return|return
name|changed
return|;
block|}
comment|// Now, handle replicas, try to assign them to nodes that are similar to the one the primary was allocated on
name|unassignedIterator
operator|=
name|routingNodes
operator|.
name|unassigned
argument_list|()
operator|.
name|iterator
argument_list|()
expr_stmt|;
while|while
condition|(
name|unassignedIterator
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|MutableShardRouting
name|shard
init|=
name|unassignedIterator
operator|.
name|next
argument_list|()
decl_stmt|;
comment|// pre-check if it can be allocated to any node that currently exists, so we won't list the store for it for nothing
name|boolean
name|canBeAllocatedToAtLeastOneNode
init|=
literal|false
decl_stmt|;
for|for
control|(
name|ObjectCursor
argument_list|<
name|DiscoveryNode
argument_list|>
name|cursor
range|:
name|nodes
operator|.
name|dataNodes
argument_list|()
operator|.
name|values
argument_list|()
control|)
block|{
name|RoutingNode
name|node
init|=
name|routingNodes
operator|.
name|node
argument_list|(
name|cursor
operator|.
name|value
operator|.
name|id
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|node
operator|==
literal|null
condition|)
block|{
continue|continue;
block|}
comment|// if we can't allocate it on a node, ignore it, for example, this handles
comment|// cases for only allocating a replica after a primary
name|Decision
name|decision
init|=
name|allocation
operator|.
name|deciders
argument_list|()
operator|.
name|canAllocate
argument_list|(
name|shard
argument_list|,
name|node
argument_list|,
name|allocation
argument_list|)
decl_stmt|;
if|if
condition|(
name|decision
operator|.
name|type
argument_list|()
operator|==
name|Decision
operator|.
name|Type
operator|.
name|YES
condition|)
block|{
name|canBeAllocatedToAtLeastOneNode
operator|=
literal|true
expr_stmt|;
break|break;
block|}
block|}
if|if
condition|(
operator|!
name|canBeAllocatedToAtLeastOneNode
condition|)
block|{
continue|continue;
block|}
name|Map
argument_list|<
name|DiscoveryNode
argument_list|,
name|TransportNodesListShardStoreMetaData
operator|.
name|StoreFilesMetaData
argument_list|>
name|shardStores
init|=
name|buildShardStores
argument_list|(
name|nodes
argument_list|,
name|shard
argument_list|)
decl_stmt|;
name|long
name|lastSizeMatched
init|=
literal|0
decl_stmt|;
name|DiscoveryNode
name|lastDiscoNodeMatched
init|=
literal|null
decl_stmt|;
name|RoutingNode
name|lastNodeMatched
init|=
literal|null
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|DiscoveryNode
argument_list|,
name|TransportNodesListShardStoreMetaData
operator|.
name|StoreFilesMetaData
argument_list|>
name|nodeStoreEntry
range|:
name|shardStores
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|DiscoveryNode
name|discoNode
init|=
name|nodeStoreEntry
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|TransportNodesListShardStoreMetaData
operator|.
name|StoreFilesMetaData
name|storeFilesMetaData
init|=
name|nodeStoreEntry
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|logger
operator|.
name|trace
argument_list|(
literal|"{}: checking node [{}]"
argument_list|,
name|shard
argument_list|,
name|discoNode
argument_list|)
expr_stmt|;
if|if
condition|(
name|storeFilesMetaData
operator|==
literal|null
condition|)
block|{
comment|// already allocated on that node...
continue|continue;
block|}
name|RoutingNode
name|node
init|=
name|routingNodes
operator|.
name|node
argument_list|(
name|discoNode
operator|.
name|id
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|node
operator|==
literal|null
condition|)
block|{
continue|continue;
block|}
comment|// check if we can allocate on that node...
comment|// we only check for NO, since if this node is THROTTLING and it has enough "same data"
comment|// then we will try and assign it next time
name|Decision
name|decision
init|=
name|allocation
operator|.
name|deciders
argument_list|()
operator|.
name|canAllocate
argument_list|(
name|shard
argument_list|,
name|node
argument_list|,
name|allocation
argument_list|)
decl_stmt|;
if|if
condition|(
name|decision
operator|.
name|type
argument_list|()
operator|==
name|Decision
operator|.
name|Type
operator|.
name|NO
condition|)
block|{
continue|continue;
block|}
comment|// if it is already allocated, we can't assign to it...
if|if
condition|(
name|storeFilesMetaData
operator|.
name|allocated
argument_list|()
condition|)
block|{
continue|continue;
block|}
if|if
condition|(
operator|!
name|shard
operator|.
name|primary
argument_list|()
condition|)
block|{
name|MutableShardRouting
name|primaryShard
init|=
name|routingNodes
operator|.
name|activePrimary
argument_list|(
name|shard
argument_list|)
decl_stmt|;
if|if
condition|(
name|primaryShard
operator|!=
literal|null
condition|)
block|{
assert|assert
name|primaryShard
operator|.
name|active
argument_list|()
assert|;
name|DiscoveryNode
name|primaryNode
init|=
name|nodes
operator|.
name|get
argument_list|(
name|primaryShard
operator|.
name|currentNodeId
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|primaryNode
operator|!=
literal|null
condition|)
block|{
name|TransportNodesListShardStoreMetaData
operator|.
name|StoreFilesMetaData
name|primaryNodeStore
init|=
name|shardStores
operator|.
name|get
argument_list|(
name|primaryNode
argument_list|)
decl_stmt|;
if|if
condition|(
name|primaryNodeStore
operator|!=
literal|null
operator|&&
name|primaryNodeStore
operator|.
name|allocated
argument_list|()
condition|)
block|{
name|long
name|sizeMatched
init|=
literal|0
decl_stmt|;
for|for
control|(
name|StoreFileMetaData
name|storeFileMetaData
range|:
name|storeFilesMetaData
control|)
block|{
if|if
condition|(
name|primaryNodeStore
operator|.
name|fileExists
argument_list|(
name|storeFileMetaData
operator|.
name|name
argument_list|()
argument_list|)
operator|&&
name|primaryNodeStore
operator|.
name|file
argument_list|(
name|storeFileMetaData
operator|.
name|name
argument_list|()
argument_list|)
operator|.
name|isSame
argument_list|(
name|storeFileMetaData
argument_list|)
condition|)
block|{
name|sizeMatched
operator|+=
name|storeFileMetaData
operator|.
name|length
argument_list|()
expr_stmt|;
block|}
block|}
name|logger
operator|.
name|trace
argument_list|(
literal|"{}: node [{}] has [{}/{}] bytes of re-usable data"
argument_list|,
name|shard
argument_list|,
name|discoNode
operator|.
name|name
argument_list|()
argument_list|,
operator|new
name|ByteSizeValue
argument_list|(
name|sizeMatched
argument_list|)
argument_list|,
name|sizeMatched
argument_list|)
expr_stmt|;
if|if
condition|(
name|sizeMatched
operator|>
name|lastSizeMatched
condition|)
block|{
name|lastSizeMatched
operator|=
name|sizeMatched
expr_stmt|;
name|lastDiscoNodeMatched
operator|=
name|discoNode
expr_stmt|;
name|lastNodeMatched
operator|=
name|node
expr_stmt|;
block|}
block|}
block|}
block|}
block|}
block|}
if|if
condition|(
name|lastNodeMatched
operator|!=
literal|null
condition|)
block|{
comment|// we only check on THROTTLE since we checked before before on NO
name|Decision
name|decision
init|=
name|allocation
operator|.
name|deciders
argument_list|()
operator|.
name|canAllocate
argument_list|(
name|shard
argument_list|,
name|lastNodeMatched
argument_list|,
name|allocation
argument_list|)
decl_stmt|;
if|if
condition|(
name|decision
operator|.
name|type
argument_list|()
operator|==
name|Decision
operator|.
name|Type
operator|.
name|THROTTLE
condition|)
block|{
if|if
condition|(
name|logger
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"[{}][{}]: throttling allocation [{}] to [{}] in order to reuse its unallocated persistent store with total_size [{}]"
argument_list|,
name|shard
operator|.
name|index
argument_list|()
argument_list|,
name|shard
operator|.
name|id
argument_list|()
argument_list|,
name|shard
argument_list|,
name|lastDiscoNodeMatched
argument_list|,
operator|new
name|ByteSizeValue
argument_list|(
name|lastSizeMatched
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// we are throttling this, but we have enough to allocate to this node, ignore it for now
name|unassignedIterator
operator|.
name|remove
argument_list|()
expr_stmt|;
name|routingNodes
operator|.
name|ignoredUnassigned
argument_list|()
operator|.
name|add
argument_list|(
name|shard
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|logger
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|logger
operator|.
name|debug
argument_list|(
literal|"[{}][{}]: allocating [{}] to [{}] in order to reuse its unallocated persistent store with total_size [{}]"
argument_list|,
name|shard
operator|.
name|index
argument_list|()
argument_list|,
name|shard
operator|.
name|id
argument_list|()
argument_list|,
name|shard
argument_list|,
name|lastDiscoNodeMatched
argument_list|,
operator|new
name|ByteSizeValue
argument_list|(
name|lastSizeMatched
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// we found a match
name|changed
operator|=
literal|true
expr_stmt|;
name|allocation
operator|.
name|routingNodes
argument_list|()
operator|.
name|assign
argument_list|(
name|shard
argument_list|,
name|lastNodeMatched
operator|.
name|nodeId
argument_list|()
argument_list|)
expr_stmt|;
name|unassignedIterator
operator|.
name|remove
argument_list|()
expr_stmt|;
block|}
block|}
block|}
return|return
name|changed
return|;
block|}
comment|/**      * Build a map of DiscoveryNodes to shard state number for the given shard.      * A state of -1 means the shard does not exist on the node, where any      * shard state>= 0 is the state version of the shard on that node's disk.      *      * A shard on shared storage will return at least shard state 0 for all      * nodes, indicating that the shard can be allocated to any node.      */
DECL|method|buildShardStates
specifier|private
name|ObjectLongOpenHashMap
argument_list|<
name|DiscoveryNode
argument_list|>
name|buildShardStates
parameter_list|(
specifier|final
name|DiscoveryNodes
name|nodes
parameter_list|,
name|MutableShardRouting
name|shard
parameter_list|,
name|IndexMetaData
name|indexMetaData
parameter_list|)
block|{
name|ObjectLongOpenHashMap
argument_list|<
name|DiscoveryNode
argument_list|>
name|shardStates
init|=
name|cachedShardsState
operator|.
name|get
argument_list|(
name|shard
operator|.
name|shardId
argument_list|()
argument_list|)
decl_stmt|;
name|ObjectOpenHashSet
argument_list|<
name|String
argument_list|>
name|nodeIds
decl_stmt|;
if|if
condition|(
name|shardStates
operator|==
literal|null
condition|)
block|{
name|shardStates
operator|=
operator|new
name|ObjectLongOpenHashMap
argument_list|<>
argument_list|()
expr_stmt|;
name|cachedShardsState
operator|.
name|put
argument_list|(
name|shard
operator|.
name|shardId
argument_list|()
argument_list|,
name|shardStates
argument_list|)
expr_stmt|;
name|nodeIds
operator|=
name|ObjectOpenHashSet
operator|.
name|from
argument_list|(
name|nodes
operator|.
name|dataNodes
argument_list|()
operator|.
name|keys
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// clean nodes that have failed
name|shardStates
operator|.
name|keys
argument_list|()
operator|.
name|removeAll
argument_list|(
operator|new
name|ObjectPredicate
argument_list|<
name|DiscoveryNode
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|apply
parameter_list|(
name|DiscoveryNode
name|node
parameter_list|)
block|{
return|return
operator|!
name|nodes
operator|.
name|nodeExists
argument_list|(
name|node
operator|.
name|id
argument_list|()
argument_list|)
return|;
block|}
block|}
argument_list|)
expr_stmt|;
name|nodeIds
operator|=
name|ObjectOpenHashSet
operator|.
name|newInstance
argument_list|()
expr_stmt|;
comment|// we have stored cached from before, see if the nodes changed, if they have, go fetch again
for|for
control|(
name|ObjectCursor
argument_list|<
name|DiscoveryNode
argument_list|>
name|cursor
range|:
name|nodes
operator|.
name|dataNodes
argument_list|()
operator|.
name|values
argument_list|()
control|)
block|{
name|DiscoveryNode
name|node
init|=
name|cursor
operator|.
name|value
decl_stmt|;
if|if
condition|(
operator|!
name|shardStates
operator|.
name|containsKey
argument_list|(
name|node
argument_list|)
condition|)
block|{
name|nodeIds
operator|.
name|add
argument_list|(
name|node
operator|.
name|id
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|nodeIds
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return
name|shardStates
return|;
block|}
name|String
index|[]
name|nodesIdsArray
init|=
name|nodeIds
operator|.
name|toArray
argument_list|(
name|String
operator|.
name|class
argument_list|)
decl_stmt|;
name|TransportNodesListGatewayStartedShards
operator|.
name|NodesGatewayStartedShards
name|response
init|=
name|listGatewayStartedShards
operator|.
name|list
argument_list|(
name|shard
operator|.
name|shardId
argument_list|()
argument_list|,
name|indexMetaData
operator|.
name|getUUID
argument_list|()
argument_list|,
name|nodesIdsArray
argument_list|,
name|listTimeout
argument_list|)
operator|.
name|actionGet
argument_list|()
decl_stmt|;
name|logListActionFailures
argument_list|(
name|shard
argument_list|,
literal|"state"
argument_list|,
name|response
operator|.
name|failures
argument_list|()
argument_list|)
expr_stmt|;
for|for
control|(
name|TransportNodesListGatewayStartedShards
operator|.
name|NodeGatewayStartedShards
name|nodeShardState
range|:
name|response
control|)
block|{
name|long
name|version
init|=
name|nodeShardState
operator|.
name|version
argument_list|()
decl_stmt|;
name|Settings
name|idxSettings
init|=
name|indexMetaData
operator|.
name|settings
argument_list|()
decl_stmt|;
if|if
condition|(
name|IndexMetaData
operator|.
name|isOnSharedFilesystem
argument_list|(
name|idxSettings
argument_list|)
operator|&&
name|idxSettings
operator|.
name|getAsBoolean
argument_list|(
name|IndexMetaData
operator|.
name|SETTING_SHARED_FS_ALLOW_RECOVERY_ON_ANY_NODE
argument_list|,
literal|false
argument_list|)
condition|)
block|{
comment|// Shared filesystems use 0 as a minimum shard state, which
comment|// means that the shard can be allocated to any node
name|version
operator|=
name|Math
operator|.
name|max
argument_list|(
literal|0
argument_list|,
name|version
argument_list|)
expr_stmt|;
block|}
comment|// -1 version means it does not exists, which is what the API returns, and what we expect to
name|logger
operator|.
name|trace
argument_list|(
literal|"[{}] on node [{}] has version [{}] of shard"
argument_list|,
name|shard
argument_list|,
name|nodeShardState
operator|.
name|getNode
argument_list|()
argument_list|,
name|version
argument_list|)
expr_stmt|;
name|shardStates
operator|.
name|put
argument_list|(
name|nodeShardState
operator|.
name|getNode
argument_list|()
argument_list|,
name|version
argument_list|)
expr_stmt|;
block|}
return|return
name|shardStates
return|;
block|}
DECL|method|logListActionFailures
specifier|private
name|void
name|logListActionFailures
parameter_list|(
name|MutableShardRouting
name|shard
parameter_list|,
name|String
name|actionType
parameter_list|,
name|FailedNodeException
index|[]
name|failures
parameter_list|)
block|{
for|for
control|(
specifier|final
name|FailedNodeException
name|failure
range|:
name|failures
control|)
block|{
name|Throwable
name|cause
init|=
name|ExceptionsHelper
operator|.
name|unwrapCause
argument_list|(
name|failure
argument_list|)
decl_stmt|;
if|if
condition|(
name|cause
operator|instanceof
name|ConnectTransportException
condition|)
block|{
continue|continue;
block|}
comment|// we log warn here. debug logs with full stack traces will be logged if debug logging is turned on for TransportNodeListGatewayStartedShards
name|logger
operator|.
name|warn
argument_list|(
literal|"{}: failed to list shard {} on node [{}]"
argument_list|,
name|failure
argument_list|,
name|shard
operator|.
name|shardId
argument_list|()
argument_list|,
name|actionType
argument_list|,
name|failure
operator|.
name|nodeId
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|buildShardStores
specifier|private
name|Map
argument_list|<
name|DiscoveryNode
argument_list|,
name|TransportNodesListShardStoreMetaData
operator|.
name|StoreFilesMetaData
argument_list|>
name|buildShardStores
parameter_list|(
name|DiscoveryNodes
name|nodes
parameter_list|,
name|MutableShardRouting
name|shard
parameter_list|)
block|{
name|Map
argument_list|<
name|DiscoveryNode
argument_list|,
name|TransportNodesListShardStoreMetaData
operator|.
name|StoreFilesMetaData
argument_list|>
name|shardStores
init|=
name|cachedStores
operator|.
name|get
argument_list|(
name|shard
operator|.
name|shardId
argument_list|()
argument_list|)
decl_stmt|;
name|ObjectOpenHashSet
argument_list|<
name|String
argument_list|>
name|nodesIds
decl_stmt|;
if|if
condition|(
name|shardStores
operator|==
literal|null
condition|)
block|{
name|shardStores
operator|=
name|Maps
operator|.
name|newHashMap
argument_list|()
expr_stmt|;
name|cachedStores
operator|.
name|put
argument_list|(
name|shard
operator|.
name|shardId
argument_list|()
argument_list|,
name|shardStores
argument_list|)
expr_stmt|;
name|nodesIds
operator|=
name|ObjectOpenHashSet
operator|.
name|from
argument_list|(
name|nodes
operator|.
name|dataNodes
argument_list|()
operator|.
name|keys
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|nodesIds
operator|=
name|ObjectOpenHashSet
operator|.
name|newInstance
argument_list|()
expr_stmt|;
comment|// clean nodes that have failed
for|for
control|(
name|Iterator
argument_list|<
name|DiscoveryNode
argument_list|>
name|it
init|=
name|shardStores
operator|.
name|keySet
argument_list|()
operator|.
name|iterator
argument_list|()
init|;
name|it
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
name|DiscoveryNode
name|node
init|=
name|it
operator|.
name|next
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|nodes
operator|.
name|nodeExists
argument_list|(
name|node
operator|.
name|id
argument_list|()
argument_list|)
condition|)
block|{
name|it
operator|.
name|remove
argument_list|()
expr_stmt|;
block|}
block|}
for|for
control|(
name|ObjectCursor
argument_list|<
name|DiscoveryNode
argument_list|>
name|cursor
range|:
name|nodes
operator|.
name|dataNodes
argument_list|()
operator|.
name|values
argument_list|()
control|)
block|{
name|DiscoveryNode
name|node
init|=
name|cursor
operator|.
name|value
decl_stmt|;
if|if
condition|(
operator|!
name|shardStores
operator|.
name|containsKey
argument_list|(
name|node
argument_list|)
condition|)
block|{
name|nodesIds
operator|.
name|add
argument_list|(
name|node
operator|.
name|id
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
operator|!
name|nodesIds
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|String
index|[]
name|nodesIdsArray
init|=
name|nodesIds
operator|.
name|toArray
argument_list|(
name|String
operator|.
name|class
argument_list|)
decl_stmt|;
name|TransportNodesListShardStoreMetaData
operator|.
name|NodesStoreFilesMetaData
name|nodesStoreFilesMetaData
init|=
name|listShardStoreMetaData
operator|.
name|list
argument_list|(
name|shard
operator|.
name|shardId
argument_list|()
argument_list|,
literal|false
argument_list|,
name|nodesIdsArray
argument_list|,
name|listTimeout
argument_list|)
operator|.
name|actionGet
argument_list|()
decl_stmt|;
name|logListActionFailures
argument_list|(
name|shard
argument_list|,
literal|"stores"
argument_list|,
name|nodesStoreFilesMetaData
operator|.
name|failures
argument_list|()
argument_list|)
expr_stmt|;
for|for
control|(
name|TransportNodesListShardStoreMetaData
operator|.
name|NodeStoreFilesMetaData
name|nodeStoreFilesMetaData
range|:
name|nodesStoreFilesMetaData
control|)
block|{
if|if
condition|(
name|nodeStoreFilesMetaData
operator|.
name|storeFilesMetaData
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|shardStores
operator|.
name|put
argument_list|(
name|nodeStoreFilesMetaData
operator|.
name|getNode
argument_list|()
argument_list|,
name|nodeStoreFilesMetaData
operator|.
name|storeFilesMetaData
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|shardStores
return|;
block|}
block|}
end_class

end_unit

